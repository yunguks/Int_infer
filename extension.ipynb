{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.cpp_extension import load\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch integer data flow 는 gpu에서 사용 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_data = torch.randint(0,255,(1,3,24,24), dtype=torch.uint8)\n",
    "# weight = torch.randint(0,255,(1,3,3,3), dtype=torch.uint8)\n",
    "\n",
    "# # b = torch.nn.functional.conv2d(int_data.cuda(), weight=weight.cuda(),stride=1)\n",
    "# b = torch.nn.functional.conv2d(int_data, weight=weight,stride=1,bias=None, padding=1, dtype=torch.uint8)\n",
    "# print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int8 torch.int8\n",
      "tensor([[ 68, 126,  65, -78]], device='cuda:0', dtype=torch.int8)\n",
      "tensor([[  -7,  -46,  -17,   62],\n",
      "        [ -87,   77,   77,  -17],\n",
      "        [ -56,   77,   81, -115],\n",
      "        [ 117,  -51,   55,   97],\n",
      "        [ -63,  -23,  -63,  119],\n",
      "        [ 126,  -25,   84,  115],\n",
      "        [  82,   59,  114,  -42],\n",
      "        [  83,   52, -127,  102],\n",
      "        [-110,   72,  -94,   11],\n",
      "        [-113,  100,   67, -110],\n",
      "        [  28,    1,  -89,   45],\n",
      "        [ -50,  -90,    1,    3]], device='cuda:0', dtype=torch.int8)\n",
      "tensor([[-12213,  10117,  20129,  -2461, -20559,   1908,  23696,  -4015,  -5376,\n",
      "          17851,  -7265, -14909]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import int8mm_cuda\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "class Intmm(Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Intmm,self).__init__()\n",
    "        self.weight = torch.randint(-127,127,(out_channels, in_channels), dtype=torch.int8).cuda()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # weight [OUT, IN} - > [IN, OUT]\n",
    "        # input [BATCH, IN]\n",
    "        return int8mm_cuda.int8_mm(x,self.weight.transpose(1,0).contiguous())\n",
    "\n",
    "mm = Intmm(4,12)\n",
    "x = torch.randint(-127,127,(1,4), dtype=torch.int8).cuda()\n",
    "print(x.dtype, mm.weight.dtype)\n",
    "with torch.no_grad():\n",
    "    y = mm(x)\n",
    "print(x)\n",
    "print(mm.weight)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  -7,  -87,  -56,  117,  -63,  126,   82,   83, -110, -113,   28,  -50],\n",
      "        [ -46,   77,   77,  -51,  -23,  -25,   59,   52,   72,  100,    1,  -90],\n",
      "        [ -17,   77,   81,   55,  -63,   84,  114, -127,  -94,   67,  -89,    1],\n",
      "        [  62,  -17, -115,   97,  119,  115,  -42,  102,   11, -110,   45,    3]],\n",
      "       device='cuda:0', dtype=torch.int8)\n",
      "\n",
      "x data - [[ 68 126  65 -78]]\n",
      "\n",
      "mm data - [[  -7  -46  -17   62]\n",
      " [ -87   77   77  -17]\n",
      " [ -56   77   81 -115]\n",
      " [ 117  -51   55   97]\n",
      " [ -63  -23  -63  119]\n",
      " [ 126  -25   84  115]\n",
      " [  82   59  114  -42]\n",
      " [  83   52 -127  102]\n",
      " [-110   72  -94   11]\n",
      " [-113  100   67 -110]\n",
      " [  28    1  -89   45]\n",
      " [ -50  -90    1    3]]\n",
      "mm Trans - [[  -7  -87  -56  117  -63  126   82   83 -110 -113   28  -50]\n",
      " [ -46   77   77  -51  -23  -25   59   52   72  100    1  -90]\n",
      " [ -17   77   81   55  -63   84  114 -127  -94   67  -89    1]\n",
      " [  62  -17 -115   97  119  115  -42  102   11 -110   45    3]]\n",
      "\n",
      "y - [[  75 -123  -95   99  -79  116 -112   81    0  -69  -97  -61]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "print(mm.weight.transpose(1,0),end=\"\\n\\n\")\n",
    "x_data = x.detach().cpu().numpy()\n",
    "mm_data = mm.weight.detach().cpu().numpy()\n",
    "print(f\"x data - {x_data}\\n\")\n",
    "print(f\"mm data - {mm_data}\\nmm Trans - {mm_data.T}\\n\")\n",
    "y = x_data @ mm_data.T\n",
    "print(f\"y - {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch conv layer parmeter shape 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([12, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.vgg.vgg16(pretrained=True)\n",
    "print(model.features[0].weight.shape)\n",
    "c = torch.nn.Conv2d(4,12,3,1,1)\n",
    "print(c.weight.shape) # NCHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 16])\n"
     ]
    }
   ],
   "source": [
    "import cutlassconv\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "class IntConv2d(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride =1, padding =1):\n",
    "        super(IntConv2d,self).__init__()\n",
    "        self.weight = torch.randint(0,127,(out_channels, kernel_size, kernel_size, in_channels), dtype=torch.int8).cuda()\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self,x):\n",
    "        # trans_weight = torch.flip(self.weight,[1,2]).transpose(0,3).contiguous()\n",
    "        # trans_weight = self.weight.permute(0,2,3,1).contiguous()\n",
    "        trans_weight = self.weight\n",
    "        return cutlassconv.int8_conv(x,trans_weight)\n",
    "## cutlass는 16의 배수만\n",
    "input_channel= 16\n",
    "conv = IntConv2d(input_channel,32,3,1,1)\n",
    "print(conv.weight.shape)\n",
    "x = torch.randint(0,127,(1,32,32,input_channel), dtype=torch.int8).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y = conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x data - torch.Size([1, 32, 32, 16]) \n",
      "[[[[ 23  80  65 ...   8 112  62]\n",
      "   [ 15 121 103 ... 106  97 126]\n",
      "   [ 12 110  61 ...  91  60  61]\n",
      "   ...\n",
      "   [ 92 122  16 ...  38  51   2]\n",
      "   [ 32  46  31 ...  97  63 113]\n",
      "   [  2   7 103 ...  50  92  69]]\n",
      "\n",
      "  [[ 24  72  59 ... 116   1  91]\n",
      "   [ 94  52  15 ...  24  59  46]\n",
      "   [ 81  25 102 ...  22 118  47]\n",
      "   ...\n",
      "   [ 55 111  17 ...  33 121 108]\n",
      "   [119 108  23 ...  19  36 122]\n",
      "   [112  84 120 ...  85  10  98]]\n",
      "\n",
      "  [[ 58  36 106 ...  85 101 118]\n",
      "   [119  83  57 ...  86  36  47]\n",
      "   [ 79 121 107 ...  22  76 125]\n",
      "   ...\n",
      "   [120  32   5 ... 116  26  46]\n",
      "   [ 49 114 124 ... 114  81 106]\n",
      "   [123   8 116 ...  51  21  81]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 89  96  32 ...  56  13  73]\n",
      "   [ 74  74  68 ...   3  98  56]\n",
      "   [ 12  47 118 ...  42  20   2]\n",
      "   ...\n",
      "   [114  57  86 ...   0  71  22]\n",
      "   [ 19  13 122 ... 107  38  27]\n",
      "   [107  10  83 ...  46  10  50]]\n",
      "\n",
      "  [[117   6  26 ...  81  84  52]\n",
      "   [ 64  92  40 ...  92  45   1]\n",
      "   [ 23  11  80 ... 114  81  16]\n",
      "   ...\n",
      "   [ 83  67  26 ... 107  38   6]\n",
      "   [100  38  32 ...  85  36   1]\n",
      "   [ 57 120  79 ... 114  35  96]]\n",
      "\n",
      "  [[ 89 105  57 ...  69 121  19]\n",
      "   [ 59  83 105 ... 116  72 113]\n",
      "   [ 70  91   3 ...  99  31   6]\n",
      "   ...\n",
      "   [111  63   4 ...  21 103  22]\n",
      "   [ 88 119  98 ... 119  61 101]\n",
      "   [ 15 107  20 ...  84   3  62]]]]\n",
      "\n",
      "conv data - (32, 3, 3, 16)\n",
      "[[[[124  20  46 ...  53  99  28]\n",
      "   [ 34  30  43 ...  18  28  45]\n",
      "   [ 31  85  82 ... 103  54  12]]\n",
      "\n",
      "  [[ 67  84  37 ...  27 123 119]\n",
      "   [ 60  97  68 ...  10  56 106]\n",
      "   [ 97 123  13 ... 107   4   7]]\n",
      "\n",
      "  [[ 71  43  72 ...   1  51  40]\n",
      "   [  3  15 124 ...  17  64  87]\n",
      "   [ 16 113   0 ...  23  13  36]]]\n",
      "\n",
      "\n",
      " [[[ 45  52  23 ...  12  22  90]\n",
      "   [ 67  76 123 ...  63  89   7]\n",
      "   [ 69  74  17 ... 115  13  72]]\n",
      "\n",
      "  [[ 49  39  45 ...  50  20  49]\n",
      "   [ 40 110  25 ...  65  21  36]\n",
      "   [123 110 118 ...  68 117 111]]\n",
      "\n",
      "  [[  1  88  71 ... 121 125  82]\n",
      "   [ 33  42 109 ...   0  55  58]\n",
      "   [ 45  51  32 ...  73  74 104]]]\n",
      "\n",
      "\n",
      " [[[ 49  56  60 ... 106  13 106]\n",
      "   [ 51  27   6 ...  83 114  95]\n",
      "   [ 20 103  60 ...   9  50   6]]\n",
      "\n",
      "  [[101  46  11 ...  93   9  10]\n",
      "   [ 25 100  85 ...  63   4  77]\n",
      "   [ 84 123  40 ... 122 117 113]]\n",
      "\n",
      "  [[  6  42  39 ...  78  27 121]\n",
      "   [ 51 100   3 ...  54  33  73]\n",
      "   [ 77  33 119 ...  52 118 111]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 16   5  81 ...  30  66  29]\n",
      "   [ 27   3  90 ...  10 109 110]\n",
      "   [ 28  56  50 ...   0  42  31]]\n",
      "\n",
      "  [[ 29  89  17 ...  68  78  20]\n",
      "   [ 66  34  25 ...  68  78  60]\n",
      "   [126 126  22 ...  65  51 115]]\n",
      "\n",
      "  [[ 59 105 124 ...  24  26  43]\n",
      "   [ 55  51 115 ...  86  33 103]\n",
      "   [ 32   7  87 ...  73   6 118]]]\n",
      "\n",
      "\n",
      " [[[ 67  66 114 ... 110   9  38]\n",
      "   [ 11  84  82 ...  53 126  32]\n",
      "   [ 57 106 104 ...  54  37   1]]\n",
      "\n",
      "  [[116   1  61 ...  30  68 110]\n",
      "   [ 46  10  72 ...  40   7 105]\n",
      "   [ 10  24  29 ...  31  17 124]]\n",
      "\n",
      "  [[102 101  37 ...  94  11 105]\n",
      "   [ 98  13  21 ... 126 109  61]\n",
      "   [ 74  26 121 ...  58   5  23]]]\n",
      "\n",
      "\n",
      " [[[105 125 117 ...  66  13 111]\n",
      "   [ 36  57  44 ...   6  56  51]\n",
      "   [115  39  67 ...  48  88  39]]\n",
      "\n",
      "  [[ 76 125  31 ...  69 117  31]\n",
      "   [122  55  42 ...  36  37  85]\n",
      "   [ 96   4 112 ...  62  83  80]]\n",
      "\n",
      "  [[107  32 103 ...   6  98  57]\n",
      "   [ 65  38  33 ... 102 115  88]\n",
      "   [110  85  24 ... 118 101  82]]]]\n",
      "\n",
      "y data - torch.Size([1, 32, 32, 32])\n",
      "tensor([[[[224664, 270483, 236537,  ..., 236869, 208979, 231445],\n",
      "          [335290, 402380, 354703,  ..., 352206, 349185, 322104],\n",
      "          [368991, 407266, 360023,  ..., 371334, 359740, 360968],\n",
      "          ...,\n",
      "          [375548, 431900, 389863,  ..., 391910, 372511, 386946],\n",
      "          [336139, 449375, 388893,  ..., 389007, 392989, 406294],\n",
      "          [264297, 276411, 202354,  ..., 274765, 286050, 243849]],\n",
      "\n",
      "         [[347635, 365086, 343265,  ..., 354936, 371208, 341863],\n",
      "          [535871, 596151, 557449,  ..., 564382, 527837, 550842],\n",
      "          [551738, 576937, 551270,  ..., 562084, 576708, 570798],\n",
      "          ...,\n",
      "          [545177, 609547, 535938,  ..., 578020, 565360, 517274],\n",
      "          [593553, 599778, 563216,  ..., 611461, 604665, 588517],\n",
      "          [409301, 426913, 360219,  ..., 404233, 417317, 400139]],\n",
      "\n",
      "         [[346461, 351580, 348788,  ..., 339913, 317678, 347903],\n",
      "          [523814, 587196, 573557,  ..., 562837, 558774, 573178],\n",
      "          [557924, 572867, 511682,  ..., 540104, 544267, 508344],\n",
      "          ...,\n",
      "          [552028, 583890, 542162,  ..., 571952, 544000, 582302],\n",
      "          [592510, 625035, 579812,  ..., 598501, 601249, 569945],\n",
      "          [417923, 438885, 365901,  ..., 398184, 416682, 412918]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[366124, 367932, 361005,  ..., 362228, 376795, 358898],\n",
      "          [512853, 566876, 532325,  ..., 543139, 520857, 489938],\n",
      "          [493001, 527365, 483663,  ..., 499094, 515108, 480829],\n",
      "          ...,\n",
      "          [494087, 521409, 496611,  ..., 502546, 538522, 527205],\n",
      "          [536081, 575016, 518414,  ..., 542400, 542680, 499942],\n",
      "          [331818, 342031, 304702,  ..., 347532, 348691, 361238]],\n",
      "\n",
      "         [[364157, 362315, 374019,  ..., 393425, 366022, 373635],\n",
      "          [551511, 572247, 532818,  ..., 567780, 536518, 543399],\n",
      "          [552219, 582445, 545566,  ..., 541668, 554701, 558584],\n",
      "          ...,\n",
      "          [533615, 575956, 505925,  ..., 513839, 533978, 526164],\n",
      "          [575047, 586374, 548986,  ..., 594406, 521637, 549818],\n",
      "          [365276, 333744, 313424,  ..., 347208, 372104, 338305]],\n",
      "\n",
      "         [[263611, 270373, 276520,  ..., 262023, 244917, 237678],\n",
      "          [406952, 340033, 372190,  ..., 368323, 367631, 323071],\n",
      "          [385917, 388017, 405191,  ..., 373185, 376744, 334321],\n",
      "          ...,\n",
      "          [354831, 367232, 366060,  ..., 349346, 336947, 337348],\n",
      "          [395931, 360557, 376603,  ..., 363267, 357382, 345556],\n",
      "          [247241, 232439, 213239,  ..., 231710, 221678, 213213]]]],\n",
      "       device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "conv_data = conv.weight.detach().cpu().numpy()\n",
    "x_data = x.detach().cpu().numpy()\n",
    "y_data = y.detach().cpu().numpy()\n",
    "print(f\"x data - {x.shape} \\n{x_data}\\n\")\n",
    "print(f\"conv data - {conv_data.shape}\\n{conv_data}\\n\")\n",
    "print(f\"y data - {y.shape}\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import int8conv_cuda\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "class IntConv2d(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride =1, padding =1):\n",
    "        super(IntConv2d,self).__init__()\n",
    "        self.weight = torch.randint(0,127,(out_channels, kernel_size, kernel_size, in_channels), dtype=torch.int8).cuda()\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self,x):\n",
    "        # trans_weight = torch.flip(self.weight,[1,2]).transpose(0,3).contiguous()\n",
    "        # trans_weight = self.weight.permute(0,2,3,1).contiguous()\n",
    "        trans_weight = self.weight\n",
    "\n",
    "        return int8conv_cuda.cu_int8_conv(x,trans_weight,self.stride, self.padding,1)\n",
    "    \n",
    "# cudnn은 4의 배수만\n",
    "input_channel= 4\n",
    "conv = IntConv2d(input_channel,32,3,1,1)\n",
    "print(conv.weight.shape)\n",
    "x = torch.randint(0,127,(1,32,32,input_channel), dtype=torch.int8).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = conv(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x data - torch.Size([1, 32, 32, 4]) \n",
      "[[[[120 109  31  86]\n",
      "   [125  39 113  78]\n",
      "   [ 58  96  35 102]\n",
      "   ...\n",
      "   [117  81  63  24]\n",
      "   [ 24  36 116  32]\n",
      "   [ 94  47  38  54]]\n",
      "\n",
      "  [[118  48  75  75]\n",
      "   [ 99  91  47   6]\n",
      "   [ 85 105  14  15]\n",
      "   ...\n",
      "   [ 54  13 118  47]\n",
      "   [ 97  94  87   6]\n",
      "   [ 12  37  61   1]]\n",
      "\n",
      "  [[ 34  64  24  98]\n",
      "   [ 13 103   4 109]\n",
      "   [ 51 123  24  35]\n",
      "   ...\n",
      "   [ 64   7   1  74]\n",
      "   [102  63  52  41]\n",
      "   [ 45  53  50  83]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 60  36 100  60]\n",
      "   [ 70  84  15  23]\n",
      "   [106 110  77  79]\n",
      "   ...\n",
      "   [ 96   1  86  76]\n",
      "   [ 93 121  43 111]\n",
      "   [ 13  50  43  97]]\n",
      "\n",
      "  [[ 49 103 108 116]\n",
      "   [ 72  31  20  74]\n",
      "   [ 47   7  60  72]\n",
      "   ...\n",
      "   [ 92   3   9  88]\n",
      "   [123 102   4  41]\n",
      "   [ 12 124  51  97]]\n",
      "\n",
      "  [[121   0   8 120]\n",
      "   [117  76  44  87]\n",
      "   [ 67  13  52  70]\n",
      "   ...\n",
      "   [ 51 102   0 114]\n",
      "   [ 16  48  72   7]\n",
      "   [ 90  91  81  61]]]]\n",
      "\n",
      "conv data - (32, 3, 3, 4)\n",
      "[[[[ 84  31  82  18]\n",
      "   [ 37  12 123  71]\n",
      "   [ 75  75  87 104]]\n",
      "\n",
      "  [[ 77 119  27 115]\n",
      "   [ 22  81  74 118]\n",
      "   [ 15 109  45  83]]\n",
      "\n",
      "  [[ 79  67 116  50]\n",
      "   [ 86  54  39  27]\n",
      "   [ 53  65 123 124]]]\n",
      "\n",
      "\n",
      " [[[ 97  58  64  37]\n",
      "   [116  93  12  70]\n",
      "   [116  39 125 116]]\n",
      "\n",
      "  [[ 60  37  77 110]\n",
      "   [ 56  83  95  19]\n",
      "   [ 20  81  46  99]]\n",
      "\n",
      "  [[ 59  53  18  92]\n",
      "   [ 80  38   3  90]\n",
      "   [ 80  67  83  83]]]\n",
      "\n",
      "\n",
      " [[[ 36 126 112 106]\n",
      "   [102 120  65 100]\n",
      "   [ 20  75  36  48]]\n",
      "\n",
      "  [[100  87  15  75]\n",
      "   [ 10  63  94  13]\n",
      "   [ 23  11   6 120]]\n",
      "\n",
      "  [[ 38 100  14  20]\n",
      "   [ 47  65 122 121]\n",
      "   [ 75  35  99   8]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 28  57  18 122]\n",
      "   [119  40  82  61]\n",
      "   [ 56 114  63  20]]\n",
      "\n",
      "  [[ 50  13  73  98]\n",
      "   [ 55 111  59 114]\n",
      "   [ 67  90  76  32]]\n",
      "\n",
      "  [[105  54  83 110]\n",
      "   [ 93  45  72  10]\n",
      "   [ 83  80  35   4]]]\n",
      "\n",
      "\n",
      " [[[ 26  35  90 108]\n",
      "   [ 41 118 103  74]\n",
      "   [  9   8  57  87]]\n",
      "\n",
      "  [[ 39  20  24  49]\n",
      "   [ 87  53  72  17]\n",
      "   [120  54 113  74]]\n",
      "\n",
      "  [[ 20  74  79  41]\n",
      "   [ 14   7  23  80]\n",
      "   [ 27  66  72 107]]]\n",
      "\n",
      "\n",
      " [[[ 73  19  37   2]\n",
      "   [ 25  98   5  55]\n",
      "   [ 25  87  21  22]]\n",
      "\n",
      "  [[ 50 121  39  66]\n",
      "   [ 82  29 107  32]\n",
      "   [105  51 123  15]]\n",
      "\n",
      "  [[ 33 111  27 100]\n",
      "   [ 15 121  18 120]\n",
      "   [126 108  89  78]]]]\n",
      "\n",
      "y data - torch.Size([1, 32, 32, 32])\n",
      "tensor([[[[ 76973.,  75580.,  67643.,  ...,  89751.,  77976.,  94134.],\n",
      "          [133111., 112235.,  98999.,  ..., 125529.,  88203., 126138.],\n",
      "          [132809., 111180.,  95372.,  ..., 118679.,  95162., 115819.],\n",
      "          ...,\n",
      "          [106602.,  98184.,  93949.,  ..., 111912.,  89328., 114706.],\n",
      "          [100454.,  77290.,  80902.,  ...,  91812.,  68924.,  91132.],\n",
      "          [ 57792.,  44487.,  42803.,  ...,  62382.,  38256.,  49516.]],\n",
      "\n",
      "         [[112165., 132256.,  92073.,  ..., 108578., 112453., 113640.],\n",
      "          [163487., 174481., 158429.,  ..., 166633., 140844., 157581.],\n",
      "          [176524., 185544., 169228.,  ..., 152099., 148553., 172586.],\n",
      "          ...,\n",
      "          [142994., 148837., 126637.,  ..., 139179., 128060., 141034.],\n",
      "          [140447., 143777., 114698.,  ..., 130141., 107916., 117818.],\n",
      "          [ 86641.,  86048., 106140.,  ...,  83621.,  69831.,  79348.]],\n",
      "\n",
      "         [[112883., 107844.,  99059.,  ..., 105671.,  74187.,  84682.],\n",
      "          [156658., 143087., 139201.,  ..., 155573., 110821., 127090.],\n",
      "          [150752., 156733., 136192.,  ..., 139053., 129290., 142505.],\n",
      "          ...,\n",
      "          [165831., 144394., 144131.,  ..., 163411., 126182., 142476.],\n",
      "          [161769., 148496., 153236.,  ..., 149514., 138035., 142020.],\n",
      "          [108608.,  92148., 105512.,  ...,  97588.,  75202.,  86141.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 99261., 102459.,  94681.,  ...,  92853.,  84969., 101186.],\n",
      "          [161389., 160564., 135005.,  ..., 153827., 145202., 138872.],\n",
      "          [156515., 146266., 139475.,  ..., 137230., 122683., 128965.],\n",
      "          ...,\n",
      "          [154897., 164133., 125434.,  ..., 151269., 126790., 142258.],\n",
      "          [166497., 164041., 133319.,  ..., 160164., 126923., 131336.],\n",
      "          [114919.,  95253., 125713.,  ..., 103605.,  80427., 102129.]],\n",
      "\n",
      "         [[118360., 113430.,  99590.,  ..., 111275.,  95256., 103702.],\n",
      "          [164554., 173648., 146171.,  ..., 156392., 120418., 145951.],\n",
      "          [149484., 149028., 139302.,  ..., 152114., 131217., 138121.],\n",
      "          ...,\n",
      "          [160962., 154066., 134369.,  ..., 163976., 129515., 137967.],\n",
      "          [162820., 170784., 154095.,  ..., 156841., 143778., 145518.],\n",
      "          [112946.,  91805., 127257.,  ..., 107009.,  80917.,  85810.]],\n",
      "\n",
      "         [[ 78384.,  74273.,  61768.,  ...,  77803.,  85042.,  62280.],\n",
      "          [101918., 111647., 108820.,  ..., 105581., 100879.,  72114.],\n",
      "          [111471., 103050.,  87001.,  ...,  98936.,  74364.,  73111.],\n",
      "          ...,\n",
      "          [108170., 102841.,  91040.,  ..., 110386.,  74336.,  75689.],\n",
      "          [103592., 113620., 102648.,  ..., 103782.,  94017.,  94938.],\n",
      "          [ 61888.,  70443.,  73614.,  ...,  64969.,  62288.,  59705.]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "conv_data = conv.weight.detach().cpu().numpy()\n",
    "x_data = x.detach().cpu().numpy()\n",
    "y_data = y.detach().cpu().numpy()\n",
    "print(f\"x data - {x.shape} \\n{x_data}\\n\")\n",
    "print(f\"conv data - {conv_data.shape}\\n{conv_data}\\n\")\n",
    "print(f\"y data - {y.shape}\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
