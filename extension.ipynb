{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.cpp_extension import load\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch integer data flow 는 gpu에서 사용 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_data = torch.randint(0,255,(1,3,24,24), dtype=torch.uint8)\n",
    "# weight = torch.randint(0,255,(1,3,3,3), dtype=torch.uint8)\n",
    "\n",
    "# # b = torch.nn.functional.conv2d(int_data.cuda(), weight=weight.cuda(),stride=1)\n",
    "# b = torch.nn.functional.conv2d(int_data, weight=weight,stride=1,bias=None, padding=1, dtype=torch.uint8)\n",
    "# print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int8 torch.int8\n",
      "tensor([[  20,   -4,  -20, -100]], device='cuda:0', dtype=torch.int8)\n",
      "tensor([[  42,  -94,   85,  -93],\n",
      "        [ 103,   33,   60,  -19],\n",
      "        [  57,   27, -103,  -85],\n",
      "        [-112,   55,  109,  112],\n",
      "        [  56,  -43,   47,  -10],\n",
      "        [ 105,   18, -101,  -84],\n",
      "        [ -21, -118,   23, -121],\n",
      "        [ -22,  -98,    6,  -19],\n",
      "        [  19,   73,  -94,   26],\n",
      "        [  88, -101,   -8,  -38],\n",
      "        [   8,  -61,  -39,   16],\n",
      "        [  86,   26,  -93,   22]], device='cuda:0', dtype=torch.int8)\n",
      "tensor([[5, 5, 5, 0, 5, 5, 5, 5, 0, 5, 0, 5]], device='cuda:0',\n",
      "       dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "import int8mm_cuda\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "class IntLinear(Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(IntLinear,self).__init__()\n",
    "        self.weight = torch.randint(-127,127,(out_channels, in_channels), dtype=torch.int8)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # weight [OUT, IN} - > [IN, OUT]\n",
    "        # input [BATCH, IN]\n",
    "        y = int8mm_cuda.int8_mm(x,self.weight.transpose(1,0).contiguous())\n",
    "        y = (y > 127).int()*5\n",
    "        y = y.type(torch.int8)\n",
    "        return y\n",
    "    \n",
    "    def cuda(self):\n",
    "        self.weight = self.weight.cuda()\n",
    "        \n",
    "\n",
    "mm = IntLinear(4,12)\n",
    "x = torch.randint(-127,127,(1,4), dtype=torch.int8).cuda()\n",
    "print(x.dtype, mm.weight.dtype)\n",
    "with torch.no_grad():\n",
    "    mm.cuda()\n",
    "    y = mm(x)\n",
    "print(x)\n",
    "print(mm.weight)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  42,  103,   57, -112,   56,  105,  -21,  -22,   19,   88,    8,   86],\n",
      "        [ -94,   33,   27,   55,  -43,   18, -118,  -98,   73, -101,  -61,   26],\n",
      "        [  85,   60, -103,  109,   47, -101,   23,    6,  -94,   -8,  -39,  -93],\n",
      "        [ -93,  -19,  -85,  112,  -10,  -84, -121,  -19,   26,  -38,   16,   22]],\n",
      "       device='cuda:0', dtype=torch.int8)\n",
      "\n",
      "x data - [[  20   -4  -20 -100]]\n",
      "\n",
      "mm data - [[  42  -94   85  -93]\n",
      " [ 103   33   60  -19]\n",
      " [  57   27 -103  -85]\n",
      " [-112   55  109  112]\n",
      " [  56  -43   47  -10]\n",
      " [ 105   18 -101  -84]\n",
      " [ -21 -118   23 -121]\n",
      " [ -22  -98    6  -19]\n",
      " [  19   73  -94   26]\n",
      " [  88 -101   -8  -38]\n",
      " [   8  -61  -39   16]\n",
      " [  86   26  -93   22]]\n",
      "mm Trans - [[  42  103   57 -112   56  105  -21  -22   19   88    8   86]\n",
      " [ -94   33   27   55  -43   18 -118  -98   73 -101  -61   26]\n",
      " [  85   60 -103  109   47 -101   23    6  -94   -8  -39  -93]\n",
      " [ -93  -19  -85  112  -10  -84 -121  -19   26  -38   16   22]]\n",
      "\n",
      "y - [[ 112   68   72   32   72  -96  -84  -60 -120  -20   96   -4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "print(mm.weight.transpose(1,0),end=\"\\n\\n\")\n",
    "x_data = x.detach().cpu().numpy()\n",
    "mm_data = mm.weight.detach().cpu().numpy()\n",
    "print(f\"x data - {x_data}\\n\")\n",
    "print(f\"mm data - {mm_data}\\nmm Trans - {mm_data.T}\\n\")\n",
    "y = x_data @ mm_data.T\n",
    "print(f\"y - {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import int8pool_cuda\n",
    "\n",
    "class IntPool(Module):\n",
    "    def __init__(self,kernel_size = 2, stride = 2, padding=0, mode=0):\n",
    "        super(IntPool,self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.mode = mode\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y = int8pool_cuda.int8_pool(x,self.kernel_size, self.stride, self.padding, self.mode)\n",
    "        y = (y > 127).int()*5\n",
    "        y = y.type(torch.int8)\n",
    "        return y\n",
    "\n",
    "pool = IntPool()\n",
    "x = torch.randint(-127, 127,(4,32,32,4), dtype=torch.int8).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y = pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x - torch.Size([4, 32, 32, 4]) \n",
      "tensor([[[[ -26,   80,  -42,   88],\n",
      "          [-107,  -43,  -32,  -61],\n",
      "          [  27,   17,  -28,  109],\n",
      "          ...,\n",
      "          [-122,   76,  -96,   50],\n",
      "          [ -21,   95,   41,   58],\n",
      "          [ 107,   24, -111,  -94]],\n",
      "\n",
      "         [[  11,  -73,   34,   97],\n",
      "          [  40,  -90,  -18,   99],\n",
      "          [ -14, -119,    7,  -90],\n",
      "          ...,\n",
      "          [ -35,    4,   25,  111],\n",
      "          [ 122,  -48,  -29,   25],\n",
      "          [-110,  108, -105,  -73]],\n",
      "\n",
      "         [[  95,  101,   48,  -72],\n",
      "          [   0,  -35, -109,  -59],\n",
      "          [ -25,  -39,    2,  -12],\n",
      "          ...,\n",
      "          [  89,  -72, -117,   54],\n",
      "          [  86,   96,   -9,  -56],\n",
      "          [   9,  -28,   52,   64]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  71,   47,  -39,    3],\n",
      "          [   7, -107,    7,  -48],\n",
      "          [  83,  -28,   25,   47],\n",
      "          ...,\n",
      "          [ 124,   40,   11,   24],\n",
      "          [ 109,   17,   33,  110],\n",
      "          [  95,  107, -104,  107]],\n",
      "\n",
      "         [[  44,  -76,   55,  -60],\n",
      "          [-102, -102,    3,   34],\n",
      "          [  81,   -4,   22,  -13],\n",
      "          ...,\n",
      "          [ -89,   21,   40,  123],\n",
      "          [ 113,  -59,   33,   -1],\n",
      "          [ -66, -116,   68,  -60]],\n",
      "\n",
      "         [[ -64,  -94,   60,   82],\n",
      "          [  -4,  110,   96,  -45],\n",
      "          [-112,  -99, -124,   52],\n",
      "          ...,\n",
      "          [ -18,   93,  100,   48],\n",
      "          [ 121,    0,  105, -112],\n",
      "          [-123,   55, -123,  112]]],\n",
      "\n",
      "\n",
      "        [[[  67,    8,   26,  -62],\n",
      "          [ -61,  -68,  -69,  -31],\n",
      "          [  19,  103,  -39,  -72],\n",
      "          ...,\n",
      "          [ -44,   40,   26,  -20],\n",
      "          [  90,   73,   77, -120],\n",
      "          [  47,   19,  -42,   11]],\n",
      "\n",
      "         [[ -62,   98,   88,    3],\n",
      "          [  43, -124,   -1,   46],\n",
      "          [ 113,  -37,  -23,   97],\n",
      "          ...,\n",
      "          [  27,   42,   15,   11],\n",
      "          [  82,   38,   34,  -97],\n",
      "          [-110,  -36,    7,  -27]],\n",
      "\n",
      "         [[  42,   91,   -1,  -57],\n",
      "          [-119,  -79,   42,   49],\n",
      "          [ -97,   73,  -59,  -74],\n",
      "          ...,\n",
      "          [ -51,   14,   42,  -68],\n",
      "          [  99,    5,   72,   -9],\n",
      "          [   2,   30,  -22, -103]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 117,  -86,   96,  -48],\n",
      "          [  85,   21,   74,  124],\n",
      "          [ -27,  -38, -108,  -58],\n",
      "          ...,\n",
      "          [  23,  111,  120,   78],\n",
      "          [  21,   -4, -116,   21],\n",
      "          [  28, -115,  -11,  -93]],\n",
      "\n",
      "         [[ -97,  123,   81,   56],\n",
      "          [ -72,  -60,   63, -104],\n",
      "          [  60,   37,   68,   89],\n",
      "          ...,\n",
      "          [ -95,  -79,  -42,   64],\n",
      "          [  23,   90,  -65, -113],\n",
      "          [ -91,  -36,   55,  -84]],\n",
      "\n",
      "         [[ -24,   37, -126,  -11],\n",
      "          [  88,  -24,  -95,  101],\n",
      "          [  39,   84,   12,  -81],\n",
      "          ...,\n",
      "          [  70,  -53,   57,  -73],\n",
      "          [ -13,  -38,  -80,   31],\n",
      "          [ -12,   88,  -11,   -6]]],\n",
      "\n",
      "\n",
      "        [[[  50,  -16,  -69,  125],\n",
      "          [-112,  120, -115, -105],\n",
      "          [-111,  -44,  122,  -22],\n",
      "          ...,\n",
      "          [  85, -116,  126,  -28],\n",
      "          [ 125,  -48, -110,  -53],\n",
      "          [  83,   93,  -68,  -42]],\n",
      "\n",
      "         [[  97,  -57,  122,  -86],\n",
      "          [ 125,  -60,   33, -104],\n",
      "          [  99, -112,  -20,   57],\n",
      "          ...,\n",
      "          [  47,  -21,  122, -120],\n",
      "          [ -35,   27,  -70, -120],\n",
      "          [ -97,  -35,  125, -122]],\n",
      "\n",
      "         [[  70,  -89,   49,   99],\n",
      "          [   6,   68,   43,   97],\n",
      "          [  40,   -6,   88,  -43],\n",
      "          ...,\n",
      "          [  83,  121,   -2,   -4],\n",
      "          [  94,   53,   28,   44],\n",
      "          [ -41,   30,  -67,   81]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -41,   44,  119,  -21],\n",
      "          [  50,   45,   58,   90],\n",
      "          [ -58,   22,   26, -123],\n",
      "          ...,\n",
      "          [-107,  -99,  -95,   33],\n",
      "          [  -5,   50,  -41,   77],\n",
      "          [ -16,  106,  -97,  -58]],\n",
      "\n",
      "         [[   9, -113,   94,  -27],\n",
      "          [-100,    3,   80,  -33],\n",
      "          [ -85,   72,   82,  -58],\n",
      "          ...,\n",
      "          [ 119,   71,  125,   22],\n",
      "          [ -69,  122,  -57,   19],\n",
      "          [ -86,  -52,  -74, -101]],\n",
      "\n",
      "         [[  -2,  -46,  -29,   82],\n",
      "          [  90,   -5,   39,   68],\n",
      "          [ -95, -115,  -66, -114],\n",
      "          ...,\n",
      "          [-103,  -61,   48,   26],\n",
      "          [  22,  -51,   51,  -65],\n",
      "          [  65,   70,  -53, -107]]],\n",
      "\n",
      "\n",
      "        [[[  54,  -19,   22,  -40],\n",
      "          [ -22,  -36,   97,   72],\n",
      "          [ -33,   -8, -117,  -71],\n",
      "          ...,\n",
      "          [ -93,   31,  102,  -49],\n",
      "          [-117,  -47,   96,  -71],\n",
      "          [ -44,   21,   68,   95]],\n",
      "\n",
      "         [[-103,  -54,   60,   88],\n",
      "          [  84,   63,    1,   90],\n",
      "          [-126,  -21,    0,   74],\n",
      "          ...,\n",
      "          [ 124,    3,   93,  -68],\n",
      "          [  95,   94,  -55, -114],\n",
      "          [  31,   68, -115,   34]],\n",
      "\n",
      "         [[  35,   40,   66,  119],\n",
      "          [  -3,  -74,   59, -104],\n",
      "          [ -92,  -48,   72,   74],\n",
      "          ...,\n",
      "          [  10,  115,   32,   58],\n",
      "          [ -87,  -31, -101,   79],\n",
      "          [ 125,  -88,   50,   70]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -97,   49,  -84,  -29],\n",
      "          [  33,  -54,  -60,   23],\n",
      "          [ -24,   97,   36, -113],\n",
      "          ...,\n",
      "          [  23,   13,   74,  -89],\n",
      "          [  67,  -14, -116,  -51],\n",
      "          [  16,  102, -112,   -9]],\n",
      "\n",
      "         [[ -21,   11,   90,  -54],\n",
      "          [   3,  -86,   85,  -92],\n",
      "          [ -62,   99,   55,   45],\n",
      "          ...,\n",
      "          [ -28, -102,  -72,  -66],\n",
      "          [-107,   83,    3,  100],\n",
      "          [ -69,  -98,   81,   59]],\n",
      "\n",
      "         [[  10,   35,  -70,   53],\n",
      "          [ -50,   -9,   11,  -65],\n",
      "          [ -36,   -4,  -83,   34],\n",
      "          ...,\n",
      "          [ -33,  -53,  -36,  -39],\n",
      "          [  80,  -85,  -86,  -29],\n",
      "          [ -59,   28,    2,   17]]]], device='cuda:0', dtype=torch.int8)\n",
      "\n",
      "y - torch.Size([4, 16, 16, 4])\n",
      "tensor([[[[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 0]]]], device='cuda:0', dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x - {x.shape} \\n{x}\\n\")\n",
    "print(f\"y - {y.shape}\\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch conv layer parmeter shape 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([12, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.vgg.vgg16(pretrained=True)\n",
    "print(model.features[0].weight.shape)\n",
    "c = torch.nn.Conv2d(4,12,3,1,1)\n",
    "print(c.weight.shape) # NCHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 16])\n"
     ]
    }
   ],
   "source": [
    "import cutlassconv\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "class IntConv2d(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride =1, padding =1):\n",
    "        super(IntConv2d,self).__init__()\n",
    "        self.weight = torch.randint(-127,127,(out_channels, kernel_size, kernel_size, in_channels), dtype=torch.int8)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self,x):\n",
    "        # trans_weight = torch.flip(self.weight,[1,2]).transpose(0,3).contiguous()\n",
    "        # trans_weight = self.weight.permute(0,2,3,1).contiguous()\n",
    "        trans_weight = self.weight\n",
    "        return cutlassconv.int8_conv(x,trans_weight)\n",
    "    \n",
    "    def cuda(self):\n",
    "        self.weight = self.weight.cuda()\n",
    "        \n",
    "## cutlass는 16의 배수만\n",
    "input_channel= 16\n",
    "conv = IntConv2d(input_channel,32,3,1,1)\n",
    "print(conv.weight.shape)\n",
    "x = torch.randint(0,127,(1,32,32,input_channel), dtype=torch.int8).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.cuda()\n",
    "    y = conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x data - torch.Size([1, 32, 32, 16]) \n",
      "[[  20   -4  -20 -100]]\n",
      "\n",
      "conv data - torch.Size([32, 3, 3, 16])\n",
      "tensor([[[[ -34,   39, -102,  ...,   91, -123, -122],\n",
      "          [  82,  -92,  120,  ...,   66,  113,  106],\n",
      "          [ 102,  -17,  -38,  ...,   26,   82,  115]],\n",
      "\n",
      "         [[   2, -122,    0,  ..., -105,  -98,  -72],\n",
      "          [  90,  -27,   30,  ...,  120,  -79,  -57],\n",
      "          [ -88,  -56,   55,  ...,   20,  -87,  122]],\n",
      "\n",
      "         [[  45,   30,  -16,  ...,  112,   78,  -28],\n",
      "          [ 105,   99,    8,  ...,   -9,   23, -115],\n",
      "          [ -88,  -54, -113,  ...,   21,   95,  -29]]],\n",
      "\n",
      "\n",
      "        [[[-115,  -12, -100,  ...,   83,   90,   18],\n",
      "          [  68,  -94,   33,  ...,   99,  -90, -100],\n",
      "          [-101,  -18, -106,  ...,  118,  -10,   56]],\n",
      "\n",
      "         [[-111,  -41,   49,  ...,  104,   83, -123],\n",
      "          [-107, -121,   41,  ...,  -55, -126,  -79],\n",
      "          [  16,   52,  -90,  ...,  -88,  -75,   50]],\n",
      "\n",
      "         [[ -19,    1, -118,  ...,  124,  -26,  -84],\n",
      "          [ -95,  -44,   28,  ...,   32,   78,  113],\n",
      "          [-127,   -5,  -68,  ...,  119,   -3,  -10]]],\n",
      "\n",
      "\n",
      "        [[[  57, -110,    2,  ...,  -44,   37,  118],\n",
      "          [-115,  105,  -93,  ..., -112,  107,  121],\n",
      "          [ -77,   97,   39,  ...,  -41,  119,   94]],\n",
      "\n",
      "         [[  98,   55,   95,  ...,    7,  -39, -118],\n",
      "          [-114,  -69,  -52,  ...,   -7,   36,   -8],\n",
      "          [  12,    1,  -87,  ...,  -18,  -95,  120]],\n",
      "\n",
      "         [[  22,  121,   56,  ..., -124,  -40,  -99],\n",
      "          [ -74,  -63, -119,  ...,    8,  -16,  117],\n",
      "          [  93,   39,   58,  ...,  107,   74,  -26]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[  59,   74,  125,  ...,  -67,   18,   86],\n",
      "          [  32,  -52, -125,  ...,  -32, -103,  -61],\n",
      "          [ -92,  -19,   91,  ...,  -11,   73,  -32]],\n",
      "\n",
      "         [[ -32,  113,  -13,  ..., -104,   59,  -46],\n",
      "          [  76,  -86, -127,  ...,  119,  -40,  -58],\n",
      "          [ -77,   27,  107,  ...,    3,  -89,  -33]],\n",
      "\n",
      "         [[-112, -120,  -21,  ...,  -55,  -33,  -19],\n",
      "          [ -46,   37, -118,  ..., -105,  -27,   28],\n",
      "          [ -11,  -57,   -8,  ...,  107,   -1,   -3]]],\n",
      "\n",
      "\n",
      "        [[[  86,  -95,    1,  ..., -111,  112,  -14],\n",
      "          [ -63,  -72,  -22,  ...,   84,   20,  -88],\n",
      "          [ 117,   53,  -53,  ...,   16,  121,   41]],\n",
      "\n",
      "         [[ -14,   65,  110,  ...,   58,   40,   96],\n",
      "          [   2,  -29,  106,  ...,  -62, -104,  -84],\n",
      "          [ -75,  -89,  -35,  ...,  -61,  -93,   64]],\n",
      "\n",
      "         [[-112,  -92,  -42,  ...,   47,   89, -118],\n",
      "          [ -44,  -40, -121,  ...,  -80,   27,   33],\n",
      "          [ 120,  -43,  -21,  ...,   52,    4,  -37]]],\n",
      "\n",
      "\n",
      "        [[[  32,   13,  -68,  ...,   -7,  -39, -118],\n",
      "          [  82,  110,   22,  ...,   93, -119,  -54],\n",
      "          [ -65,  -53,   -8,  ...,  -93,  -84,   22]],\n",
      "\n",
      "         [[-125,  -95, -103,  ..., -107,  121, -125],\n",
      "          [  54,  118,  -35,  ...,  124,   62,  -79],\n",
      "          [ -56,   58,   93,  ...,  -67,   28, -105]],\n",
      "\n",
      "         [[-104,  125,  125,  ...,   73,  -35,   99],\n",
      "          [ -87, -101,  102,  ..., -119,  -76,   55],\n",
      "          [ -34,   61,   37,  ...,   41,  -83,   78]]]], device='cuda:0',\n",
      "       dtype=torch.int8)\n",
      "\n",
      "y data - torch.Size([1, 32, 32, 32])\n",
      "tensor([[[[ -62587,  -33526,   -3861,  ...,   -2962,  -78127,   31287],\n",
      "          [ -83880,  -37793,   -6966,  ...,  -33031,  -65776,   18049],\n",
      "          [ -14704,  -54847,   24422,  ...,   16784,  -42949,  -19257],\n",
      "          ...,\n",
      "          [ -18868,  -84327,  -10994,  ...,   -7665,   -5879,     -59],\n",
      "          [  -9907,  -22866,    7890,  ...,   -1904,   23697,    9448],\n",
      "          [   9933,  -61894,   26162,  ...,  -47491,   14201,  -39054]],\n",
      "\n",
      "         [[  26921,    6354,   21451,  ...,   10736,  -19183,   -5949],\n",
      "          [  -9551,  -27831,   13089,  ...,  -85382,   -7484,  -94306],\n",
      "          [  33614,  -17742,  -15448,  ...,   -9754,  -13875,    2114],\n",
      "          ...,\n",
      "          [ -32718,  -67505,   24134,  ...,  -28930,   17790,  -48701],\n",
      "          [   6630,  -23466,   27002,  ...,   -5615,   30332,  -99447],\n",
      "          [  29582,    6545,  -34642,  ...,   -7545,  -10031,  -63933]],\n",
      "\n",
      "         [[  52056,   20292,  -23452,  ...,   47181,  -18556,   66817],\n",
      "          [ -61380,  -75758,   67250,  ...,   23116,   37013,  -97163],\n",
      "          [  25324,  -27087,   62042,  ...,   13047,  -21428, -103027],\n",
      "          ...,\n",
      "          [  14881,    2518,   42277,  ...,     -65,   73357, -114144],\n",
      "          [ -28038, -106994,   49259,  ...,   15493,  -32750,  -47266],\n",
      "          [ -41288,  -52144,   12082,  ...,   29465,   -2255,  -63034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -36489,   21166,  -32917,  ...,  -51055,  -18858,   12666],\n",
      "          [   5414,  -57117,   26353,  ...,  -71755,  -30181,  -57679],\n",
      "          [   3879,  -33978,  -11394,  ...,   25637,   29524,  -65271],\n",
      "          ...,\n",
      "          [  36504,  -12121,    5319,  ...,  -26935,   22567, -147623],\n",
      "          [  48979,   29653,   15422,  ...,    8518,   29950,  -90020],\n",
      "          [  -2409,  -14823,  -16252,  ...,  -72261,   -3774,  -56589]],\n",
      "\n",
      "         [[ -31774,    8528,    7363,  ...,   19265,    7949,  -41692],\n",
      "          [   8992,  -41572,  -17636,  ...,   50158,  -10513,  -56208],\n",
      "          [  -6197,  -64745,   73241,  ...,   48251,   81069,  -67858],\n",
      "          ...,\n",
      "          [   5792,  -11876,   55349,  ...,   38489,  -42850, -125001],\n",
      "          [ -33258,  -38579,  108652,  ...,   38048,    8563, -116048],\n",
      "          [  -4836,  -46879,   40049,  ...,  -54915,  -51244,  -81781]],\n",
      "\n",
      "         [[  50037,    -933,  -65444,  ...,   29944,   10141,  -30615],\n",
      "          [  -1619,  -61887,  -77496,  ...,   33527,   38397,  -66214],\n",
      "          [ -88212,   13301,  -36052,  ...,   20395,   75725,  -35230],\n",
      "          ...,\n",
      "          [ -58704,     277,  -31090,  ...,   27014,   42071,  -89017],\n",
      "          [  11769,   -5023,  -50960,  ...,   38361,    6941,  -53310],\n",
      "          [ -51845,  -67428,  -11264,  ...,   25341,   61843,   -6558]]]],\n",
      "       device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "print(f\"x data - {x.shape} \\n{x_data}\\n\")\n",
    "print(f\"conv data - {conv.weight.shape}\\n{conv.weight}\\n\")\n",
    "print(f\"y data - {y.shape}\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import int8conv_cuda\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "class IntConv2d(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride =1, padding =1):\n",
    "        super(IntConv2d,self).__init__()\n",
    "        self.weight = torch.randint(0,127,(out_channels, kernel_size, kernel_size, in_channels), dtype=torch.int8)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self,x):\n",
    "        # trans_weight = torch.flip(self.weight,[1,2]).transpose(0,3).contiguous()\n",
    "        # trans_weight = self.weight.permute(0,2,3,1).contiguous()\n",
    "        trans_weight = self.weight\n",
    "        y = int8conv_cuda.cu_int8_conv(x,trans_weight,self.stride, self.padding,1)\n",
    "        y = (y > 127).int()*5\n",
    "        y = y.type(torch.int8)\n",
    "        return y\n",
    "    \n",
    "    def cuda(self):\n",
    "        self.weight = self.weight.cuda()\n",
    "    \n",
    "# cudnn은 4의 배수만\n",
    "input_channel= 4\n",
    "conv = IntConv2d(input_channel,32,3,1,1)\n",
    "print(conv.weight.shape)\n",
    "x = torch.randint(0,127,(1,32,32,input_channel), dtype=torch.int8).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    conv.cuda()\n",
    "    y = conv(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x data - torch.Size([1, 32, 32, 4]) \n",
      "[[[[115 113 121  50]\n",
      "   [ 20   9 125  21]\n",
      "   [ 95  41 112   2]\n",
      "   ...\n",
      "   [ 85  94  28  66]\n",
      "   [ 38  10  73  42]\n",
      "   [110  92  59  29]]\n",
      "\n",
      "  [[ 37 112  41   5]\n",
      "   [107  49  35 115]\n",
      "   [ 66  37 116  34]\n",
      "   ...\n",
      "   [ 22  78  79  67]\n",
      "   [  3  52   3  98]\n",
      "   [ 82  35 117  57]]\n",
      "\n",
      "  [[ 40  72  39  88]\n",
      "   [ 97  56   4  74]\n",
      "   [ 84  66  45  85]\n",
      "   ...\n",
      "   [ 32 103  72 107]\n",
      "   [ 28  41  97 116]\n",
      "   [119  74  43  53]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 99  80  93  44]\n",
      "   [ 97 109  19  29]\n",
      "   [ 40  57  70  85]\n",
      "   ...\n",
      "   [ 97   0  84 120]\n",
      "   [ 58  62  68 120]\n",
      "   [  4  10  79  35]]\n",
      "\n",
      "  [[118  37  56 115]\n",
      "   [ 92  18 115  11]\n",
      "   [ 51 122  36  16]\n",
      "   ...\n",
      "   [106  66 112  31]\n",
      "   [  8  80  60 125]\n",
      "   [ 14 123  80 120]]\n",
      "\n",
      "  [[124  57  44  51]\n",
      "   [ 80  46  54 110]\n",
      "   [  6  32   7 107]\n",
      "   ...\n",
      "   [ 51 122   4  17]\n",
      "   [ 91   1  81 117]\n",
      "   [ 72  60  69  92]]]]\n",
      "\n",
      "conv data - (32, 3, 3, 4)\n",
      "[[[[ 90  38  94 101]\n",
      "   [ 46  17   6  59]\n",
      "   [ 77  53  57 113]]\n",
      "\n",
      "  [[104  24  76  50]\n",
      "   [ 59  31  46  38]\n",
      "   [ 40  45  62  18]]\n",
      "\n",
      "  [[ 42 114  94 118]\n",
      "   [ 65  43  76   3]\n",
      "   [ 54  12  62  83]]]\n",
      "\n",
      "\n",
      " [[[  1  73 120  73]\n",
      "   [ 14  25  79  42]\n",
      "   [ 67 105  20  27]]\n",
      "\n",
      "  [[116  52   3  54]\n",
      "   [ 12  22 115 110]\n",
      "   [  6   0 110   4]]\n",
      "\n",
      "  [[102  89   0  12]\n",
      "   [104  24 115  23]\n",
      "   [112  17   9 124]]]\n",
      "\n",
      "\n",
      " [[[ 26  28  58   2]\n",
      "   [ 72   5  44  65]\n",
      "   [ 94  61  48 115]]\n",
      "\n",
      "  [[118  60  74  73]\n",
      "   [ 94  41  28 103]\n",
      "   [ 57  82  64 118]]\n",
      "\n",
      "  [[ 26  75  91  41]\n",
      "   [ 16   4  92  26]\n",
      "   [  2  46 104  94]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 94 107   6 120]\n",
      "   [ 50  66 115  69]\n",
      "   [ 70  55  98  10]]\n",
      "\n",
      "  [[103  96  74  16]\n",
      "   [103 121 100  34]\n",
      "   [ 48  63 109  95]]\n",
      "\n",
      "  [[ 17 118  41  13]\n",
      "   [ 78   0  12   4]\n",
      "   [ 65  94  20 101]]]\n",
      "\n",
      "\n",
      " [[[ 15 107 116  22]\n",
      "   [  5  81 120  61]\n",
      "   [110 105  24  85]]\n",
      "\n",
      "  [[  9  16  19  26]\n",
      "   [ 66  24  27  14]\n",
      "   [  5 123 102 117]]\n",
      "\n",
      "  [[105  81   5  27]\n",
      "   [ 30  96  74  48]\n",
      "   [ 67 124 113  68]]]\n",
      "\n",
      "\n",
      " [[[123  57  99  31]\n",
      "   [ 55  78  45  19]\n",
      "   [ 57  58  71   4]]\n",
      "\n",
      "  [[  0  95  48  92]\n",
      "   [ 64  25 105 117]\n",
      "   [ 97  70  69  46]]\n",
      "\n",
      "  [[ 21   2  26 115]\n",
      "   [ 15  71  23 104]\n",
      "   [ 58  79 121  59]]]]\n",
      "\n",
      "y data - torch.Size([1, 32, 32, 32])\n",
      "tensor([[[[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]],\n",
      "\n",
      "         [[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]],\n",
      "\n",
      "         [[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]],\n",
      "\n",
      "         [[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]],\n",
      "\n",
      "         [[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]]]], device='cuda:0', dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "conv_data = conv.weight.detach().cpu().numpy()\n",
    "x_data = x.detach().cpu().numpy()\n",
    "y_data = y.detach().cpu().numpy()\n",
    "print(f\"x data - {x.shape} \\n{x_data}\\n\")\n",
    "print(f\"conv data - {conv_data.shape}\\n{conv_data}\\n\")\n",
    "print(f\"y data - {y.shape}\\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(\n",
    "        self, features: nn.Module, num_classes: int = 100, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = IntPool(7,1,0,1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            IntLinear(512,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            IntLinear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            IntLinear(4096,num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def cuda(self):\n",
    "        for layer in model.modules():\n",
    "            if 'Int' in str(type(layer)):\n",
    "                layer.cuda()\n",
    "\n",
    "def make_layers(cfg, batch_norm: bool = False) -> nn.Sequential:\n",
    "    layers = []\n",
    "    in_channels = 4\n",
    "    for vs in cfg:\n",
    "        for v in vs:\n",
    "            v = int(v)\n",
    "            conv2d = IntConv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            layers += [conv2d, nn.ReLU()]\n",
    "            in_channels = v\n",
    "        layers += [IntPool(kernel_size=2, stride=2)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    \"D\": [[64, 64], [128, 128], [256, 256, 256], [512, 512, 512],[512, 512, 512]],\n",
    "    # \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "}\n",
    "\n",
    "def int_vgg(cfg: str, **kwargs) -> VGG:\n",
    "    model = VGG(make_layers(cfgs[cfg]), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = []\n",
    "before_l = []\n",
    "after_l = []\n",
    "hooks = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    modules.append(module)\n",
    "    before_l.append(input[0])\n",
    "    after_l.append(output)\n",
    "\n",
    "def add_forward_hook(net, hooks):\n",
    "    for name, layer in net._modules.items():\n",
    "        if isinstance(layer, nn.Sequential) or isinstance(layer, torchvision.models.vgg.VGG):\n",
    "            add_forward_hook(layer, hooks)\n",
    "        else:\n",
    "            hook = layer.register_forward_hook(hook_fn)\n",
    "            hooks.append(hook)\n",
    "            \n",
    "    return hooks\n",
    "\n",
    "def remove_forward_hook(hooks):\n",
    "    for i in hooks:\n",
    "        i.remove()\n",
    "# out = model((torch.randn(1,3,32,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class test_module(Module):\n",
    "#     def __init__(self,num_classes= 100):\n",
    "#         super(test_module,self).__init__()\n",
    "#         self.layers = nn.Sequential(\n",
    "#             IntLinear(512,4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             IntLinear(4096,4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             IntLinear(4096,num_classes),\n",
    "#         )\n",
    "#     def forward(self,x):\n",
    "#         for l in self.layers:\n",
    "#             x = l(x)\n",
    "#             print(x.shape, x.dtype)\n",
    "#         return x\n",
    "#     def cuda(self):\n",
    "#         for layer in model.modules():\n",
    "#             if 'Int' in str(type(layer)):\n",
    "#                 layer.cuda()\n",
    "\n",
    "# model = test_module()\n",
    "# x = torch.randint(-127,127,(1,512)).cuda()\n",
    "# model.eval()\n",
    "# model.cuda()\n",
    "# print(model.layers[0].weight)\n",
    "# print(x.dtype)\n",
    "# with torch.no_grad():\n",
    "#     y = model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 0 0 0\n",
      "torch.int8 torch.Size([1, 100]) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]], device='cuda:0', dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "model = int_vgg(\"D\")\n",
    "model.eval()\n",
    "hooks = add_forward_hook(model, hooks)\n",
    "# remove hook, hook works at once\n",
    "remove_forward_hook(hooks)\n",
    "model.cuda()\n",
    "with torch.no_grad():\n",
    "    x = torch.randint(-127,127,(1,224,224,4), dtype=torch.int8).cuda()\n",
    "    y = model(x)\n",
    "    print(len(hooks), len(modules), len(before_l), len(after_l))\n",
    "    remove_forward_hook(hooks)\n",
    "    hooks=[]\n",
    "print(y.dtype, y.shape, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-108,  117,   34],\n",
      "          [  60,   15,  -27],\n",
      "          [  -1, -124,    6],\n",
      "          [  67,   70,  116]],\n",
      "\n",
      "         [[  28,  -51,    8],\n",
      "          [  86,   71,  -30],\n",
      "          [  68,  122,  111],\n",
      "          [-103,   33,  -62]],\n",
      "\n",
      "         [[-102,   31, -122],\n",
      "          [  71, -110,   -3],\n",
      "          [  65,   78,   35],\n",
      "          [  50,  101,   -6]],\n",
      "\n",
      "         [[  19,  125,  -79],\n",
      "          [ 113,   37,  -89],\n",
      "          [ -86,  -91,   72],\n",
      "          [-114,   86,   95]]]], device='cuda:0', dtype=torch.int8)\n",
      "tensor([[[[  0, 117,  34],\n",
      "          [ 60,  15,   0],\n",
      "          [  0,   0,   6],\n",
      "          [ 67,  70, 116]],\n",
      "\n",
      "         [[ 28,   0,   8],\n",
      "          [ 86,  71,   0],\n",
      "          [ 68, 122, 111],\n",
      "          [  0,  33,   0]],\n",
      "\n",
      "         [[  0,  31,   0],\n",
      "          [ 71,   0,   0],\n",
      "          [ 65,  78,  35],\n",
      "          [ 50, 101,   0]],\n",
      "\n",
      "         [[ 19, 125,   0],\n",
      "          [113,  37,   0],\n",
      "          [  0,   0,  72],\n",
      "          [  0,  86,  95]]]], device='cuda:0', dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "i = torch.randint(-127, 127,(1,4,4,3), dtype=torch.int8).cuda()\n",
    "lay = nn.Dropout(0.5)\n",
    "\n",
    "lay.cuda()\n",
    "with torch.no_grad():\n",
    "    lay.eval()\n",
    "    y = lay(i)\n",
    "    k = nn.functional.relu(y)\n",
    "print(y)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
