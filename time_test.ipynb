{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import vgg,layers\n",
    "import torch.utils.benchmark as benchmark\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def measure_time_host(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = False,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start = timer()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        if synchronize:\n",
    "            torch.cuda.synchronize()\n",
    "        end = timer()\n",
    "        elapsed_time_ms = (end - start) * 1000\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start = timer()\n",
    "            _ = model.forward(input_tensor)\n",
    "            if synchronize:\n",
    "                torch.cuda.synchronize()\n",
    "            end = timer()\n",
    "            elapsed_time_ms += (end - start) * 1000\n",
    "\n",
    "    return elapsed_time_ms / num_repeats\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_time_device(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = False,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        end_event.record()\n",
    "        if synchronize:\n",
    "            # This has to be synchronized to compute the elapsed time.\n",
    "            # Otherwise, there will be runtime error.\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start_event = torch.cuda.Event(enable_timing=True)\n",
    "            end_event = torch.cuda.Event(enable_timing=True)\n",
    "            start_event.record()\n",
    "            _ = model.forward(input_tensor)\n",
    "            end_event.record()\n",
    "            if synchronize:\n",
    "                # This has to be synchronized to compute the elapsed time.\n",
    "                # Otherwise, there will be runtime error.\n",
    "                torch.cuda.synchronize()\n",
    "            elapsed_time_ms += start_event.elapsed_time(end_event)\n",
    "\n",
    "    return elapsed_time_ms / num_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def run_inference(model: nn.Module,\n",
    "                  input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    return model.forward(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- TOTAL PYTORCH MODEL -----------\n",
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 2.77948 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 2.74886 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 2.81305 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: 2.70466 ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 2.74054 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 2.69934 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n",
      "Latency: 2.74536 ms\n",
      "--------- TOTAL FLOAT MODEL -----------\n",
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 5.96707 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 5.89511 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 6.15634 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: 5.89762 ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 5.99325 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 6.02665 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n",
      "Latency: 5.99762 ms\n",
      "\n",
      "\n",
      "--------- TOTAL INT8 MODEL -----------\n",
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 7.27795 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 7.44723 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 7.72090 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: 7.46922 ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 7.52883 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 7.54584 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n",
      "Latency: 7.53098 ms\n",
      "\n",
      "\n",
      "--------- PYTORCH Conv2d 1 LAYER -----------\n",
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 0.06645 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 0.04745 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 0.09449 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: 0.04679 ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 0.07279 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 0.08201 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n",
      "Latency: 0.07301 ms\n",
      "\n",
      "\n",
      "--------- FloatConv2d 1 LAYER -----------\n",
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 0.04152 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 0.04089 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 0.08357 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: 0.03530 ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 0.03667 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 0.07357 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n",
      "Latency: 0.04335 ms\n",
      "\n",
      "\n",
      "--------- IntConv2d 1 LAYER -----------\n",
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 0.03373 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 0.03355 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 0.06634 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: 0.03341 ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 0.03487 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 0.03501 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 0.06553 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n",
      "Latency: 0.03938 ms\n",
      "\n",
      "\n",
      "--------- PYTORCH Linear 1 LAYER -----------\n",
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 0.46813 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 0.01254 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 0.51306 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: 0.01228 ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 0.47156 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 0.48479 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n",
      "Latency: 0.47283 ms\n",
      "\n",
      "\n",
      "--------- FloatLinear 1 LAYER -----------\n",
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 3.22029 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 2.09755 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 3.30477 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: 2.28274 ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 3.46599 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 3.39605 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n",
      "Latency: 3.48882 ms\n",
      "\n",
      "\n",
      "--------- IntLinear 1 LAYER -----------\n",
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 2.07288 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: 1.01628 ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 2.02870 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: 1.01707 ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: 2.06181 ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: 1.86817 ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n",
      "Latency: 2.09306 ms\n"
     ]
    }
   ],
   "source": [
    "def main(model, input_tensor) -> None:\n",
    "\n",
    "    num_warmups = 100\n",
    "    num_repeats = 1000\n",
    "    input_shape = (1,224, 224,4)\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    # model = torchvision.models.resnet18(pretrained=False)\n",
    "\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    # Input tensor\n",
    "    input_tensor = input_tensor.cuda()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print(\"Latency Measurement Using CPU Timer...\")\n",
    "    for continuous_measure in [True, False]:\n",
    "        for synchronize in [True, False]:\n",
    "            try:\n",
    "                latency_ms = measure_time_host(\n",
    "                    model=model,\n",
    "                    input_tensor=input_tensor,\n",
    "                    num_repeats=num_repeats,\n",
    "                    num_warmups=num_warmups,\n",
    "                    synchronize=synchronize,\n",
    "                    continuous_measure=continuous_measure,\n",
    "                )\n",
    "                print(f\"|\"\n",
    "                      f\"Synchronization: {synchronize!s:5}| \"\n",
    "                      f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                      f\"Latency: {latency_ms:.5f} ms| \")\n",
    "            except Exception as e:\n",
    "                print(f\"|\"\n",
    "                      f\"Synchronization: {synchronize!s:5}| \"\n",
    "                      f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                      f\"Latency: N/A     ms| \")\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "    print(\"Latency Measurement Using CUDA Timer...\")\n",
    "    for continuous_measure in [True, False]:\n",
    "        for synchronize in [True, False]:\n",
    "            try:\n",
    "                latency_ms = measure_time_device(\n",
    "                    model=model,\n",
    "                    input_tensor=input_tensor,\n",
    "                    num_repeats=num_repeats,\n",
    "                    num_warmups=num_warmups,\n",
    "                    synchronize=synchronize,\n",
    "                    continuous_measure=continuous_measure,\n",
    "                )\n",
    "                print(f\"|\"\n",
    "                      f\"Synchronization: {synchronize!s:5}| \"\n",
    "                      f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                      f\"Latency: {latency_ms:.5f} ms| \")\n",
    "            except Exception as e:\n",
    "                print(f\"|\"\n",
    "                      f\"Synchronization: {synchronize!s:5}| \"\n",
    "                      f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                      f\"Latency: N/A     ms| \")\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "    print(\"Latency Measurement Using PyTorch Benchmark...\")\n",
    "    num_threads = 1\n",
    "    timer = benchmark.Timer(stmt=\"run_inference(model, input_tensor)\",\n",
    "                            setup=\"from __main__ import run_inference\",\n",
    "                            globals={\n",
    "                                \"model\": model,\n",
    "                                \"input_tensor\": input_tensor\n",
    "                            },\n",
    "                            num_threads=num_threads,\n",
    "                            label=\"Latency Measurement\",\n",
    "                            sub_label=\"torch.utils.benchmark.\")\n",
    "\n",
    "    profile_result = timer.timeit(num_repeats)\n",
    "    # https://pytorch.org/docs/stable/_modules/torch/utils/benchmark/utils/common.html#Measurement\n",
    "    print(f\"Latency: {profile_result.mean * 1000:.5f} ms\")\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print(\"--------- TOTAL PYTORCH MODEL -----------\")\n",
    "    model = vgg.vgg16()\n",
    "    tensor = torch.rand((1,4, 224,224))\n",
    "    main(model, tensor)\n",
    "    print(\"--------- TOTAL FLOAT MODEL -----------\")\n",
    "    model = vgg.float_vgg16()\n",
    "    tensor = torch.rand((1,224,224,4))\n",
    "    main(model, tensor)\n",
    "    print(\"\\n\\n--------- TOTAL INT8 MODEL -----------\")\n",
    "    model = vgg.int_vgg16()\n",
    "    tensor = torch.randint(-128,127,(1,224,224,4),dtype=torch.int8)\n",
    "    main(model, tensor)\n",
    "    print(\"\\n\\n--------- PYTORCH Conv2d 1 LAYER -----------\")\n",
    "    layer = nn.Conv2d(4,64,3)\n",
    "    tensor = torch.rand((1,4, 224,224))\n",
    "    main(layer, tensor)\n",
    "    print(\"\\n\\n--------- FloatConv2d 1 LAYER -----------\")\n",
    "    layer = layers.FLOATConv2d(4,64,3)\n",
    "    tensor = torch.rand((1,224,224,4))\n",
    "    main(layer, tensor)\n",
    "    print(\"\\n\\n--------- IntConv2d 1 LAYER -----------\")\n",
    "    layer = layers.IntConv2d(4,64,3)\n",
    "    tensor = torch.randint(-128,127,(1,224,224,4),dtype=torch.int8)\n",
    "    main(layer, tensor)\n",
    "\n",
    "    print(\"\\n\\n--------- PYTORCH Linear 1 LAYER -----------\")\n",
    "    layer = nn.Linear(25088,4096)\n",
    "    tensor = torch.rand((1,25088))\n",
    "    main(layer, tensor)\n",
    "    print(\"\\n\\n--------- FloatLinear 1 LAYER -----------\")\n",
    "    layer = layers.FLOATLinear(25088,4096)\n",
    "    tensor = torch.rand((1,25088))\n",
    "    main(layer, tensor)\n",
    "    print(\"\\n\\n--------- IntLinear 1 LAYER -----------\")\n",
    "    layer = layers.IntLinear(25088,4096)\n",
    "    tensor = torch.randint(-128,127,(1,25088),dtype=torch.int8)\n",
    "    main(layer, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-25 18:33:49 1805140:1805140 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-11-25 18:33:49 1805140:1805140 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-11-25 18:33:49 1805140:1805140 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = vgg.vgg16().cuda()\n",
    "tensor = torch.rand((1,4, 224,224)).cuda()\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True, profile_memory=True) as prof:\n",
    "    with torch.no_grad():\n",
    "        y = model(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::conv2d         5.20%     186.000us        52.31%       1.870ms     143.846us       0.000us         0.00%       2.029ms     156.077us           0 b           0 b      54.34 Mb      11.81 Mb            13  \n",
      "                                      aten::convolution         0.95%      34.000us        51.52%       1.842ms     141.692us       0.000us         0.00%       2.615ms     201.154us           0 b           0 b      54.34 Mb           0 b            13  \n",
      "                                     aten::_convolution         2.46%      88.000us        50.57%       1.808ms     139.077us       0.000us         0.00%       2.615ms     201.154us           0 b           0 b      54.34 Mb           0 b            13  \n",
      "                                aten::cudnn_convolution        38.74%       1.385ms        43.47%       1.554ms     119.538us       1.581ms        64.22%       2.481ms     190.846us           0 b           0 b      54.34 Mb      54.34 Mb            13  \n",
      "                                  cudaStreamIsCapturing         0.03%       1.000us         0.03%       1.000us       0.067us     202.000us         8.20%     202.000us      13.467us           0 b           0 b           0 b           0 b            15  \n",
      "                                  cudaStreamGetPriority         0.00%       0.000us         0.00%       0.000us       0.000us      33.000us         1.34%      33.000us       2.538us           0 b           0 b           0 b           0 b            13  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.03%       1.000us         0.03%       1.000us       0.077us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            13  \n",
      "                                       cudaLaunchKernel         8.56%     306.000us         8.56%     306.000us       3.732us     669.000us        27.17%     669.000us       8.159us           0 b           0 b           0 b           0 b            82  \n",
      "                                        cudaMemsetAsync         0.56%      20.000us         0.56%      20.000us       2.500us       2.000us         0.08%       2.000us       0.250us           0 b           0 b           0 b           0 b             8  \n",
      "                                          aten::reshape         1.01%      36.000us         1.06%      38.000us       2.923us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            13  \n",
      "                                   aten::_reshape_alias         0.17%       6.000us         0.17%       6.000us       0.429us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            14  \n",
      "                                             aten::add_         2.57%      92.000us         3.58%     128.000us       9.846us     132.000us         5.36%     134.000us      10.308us           0 b           0 b           0 b           0 b            13  \n",
      "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.08%       2.000us       2.000us           0 b           0 b           0 b           0 b             1  \n",
      "           cudnn_ampere_scudnn_128x64_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us      31.000us         1.26%      31.000us      31.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::relu         0.81%      29.000us         4.14%     148.000us      11.385us       0.000us         0.00%     127.000us       9.769us           0 b           0 b      51.68 Mb           0 b            13  \n",
      "                                        aten::clamp_min         2.15%      77.000us         3.33%     119.000us       9.154us     123.000us         5.00%     127.000us       9.769us           0 b           0 b      51.68 Mb      51.68 Mb            13  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     132.000us         5.36%     132.000us      10.154us           0 b           0 b           0 b           0 b            13  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b    -121.08 Mb    -121.08 Mb            38  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     127.000us         5.16%     127.000us       8.467us           0 b           0 b           0 b           0 b            15  \n",
      "void cudnn::ops::nchwToNhwcKernel<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     269.000us        10.93%     269.000us      11.208us           0 b           0 b           0 b           0 b            24  \n",
      "                                   cudaFuncSetAttribute         0.11%       4.000us         0.11%       4.000us       0.235us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            17  \n",
      "sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f3...         0.00%       0.000us         0.00%       0.000us       0.000us     280.000us        11.37%     280.000us      70.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                       aten::max_pool2d         0.28%      10.000us         1.90%      68.000us      13.600us       0.000us         0.00%      60.000us      12.000us           0 b           0 b      14.99 Mb      -4.02 Mb             5  \n",
      "                          aten::max_pool2d_with_indices         1.15%      41.000us         1.62%      58.000us      11.600us      60.000us         2.44%      60.000us      12.000us           0 b           0 b      19.01 Mb      19.01 Mb             5  \n",
      "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us      60.000us         2.44%      60.000us      12.000us           0 b           0 b           0 b           0 b             5  \n",
      "sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us     228.000us         9.26%     228.000us     114.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             7  \n",
      "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fpr...         0.00%       0.000us         0.00%       0.000us       0.000us     317.000us        12.88%     317.000us     105.667us           0 b           0 b           0 b           0 b             3  \n",
      "void cudnn::ops::nhwcToNchwKernel<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us      30.000us         1.22%      30.000us       5.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                          aten::flatten         0.06%       2.000us         0.17%       6.000us       6.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                           aten::linear         0.25%       9.000us         3.55%     127.000us      42.333us       0.000us         0.00%     558.000us     186.000us           0 b           0 b      32.50 Kb           0 b             3  \n",
      "                                                aten::t         0.22%       8.000us         0.50%      18.000us       6.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                        aten::transpose         0.22%       8.000us         0.25%       9.000us       3.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                       aten::as_strided         0.06%       2.000us         0.06%       2.000us       0.667us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                           aten::matmul         0.14%       5.000us         2.80%     100.000us      33.333us       0.000us         0.00%     558.000us     186.000us           0 b           0 b      32.50 Kb           0 b             3  \n",
      "                                               aten::mm         2.13%      76.000us         2.66%      95.000us      31.667us     558.000us        22.66%     558.000us     186.000us           0 b           0 b      32.50 Kb      32.50 Kb             3  \n",
      "sm80_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f3...         0.00%       0.000us         0.00%       0.000us       0.000us     424.000us        17.22%     424.000us     141.333us           0 b           0 b           0 b           0 b             3  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.08%       3.000us         0.08%       3.000us       1.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                            aten::relu_         0.22%       8.000us         0.70%      25.000us      12.500us       0.000us         0.00%       4.000us       2.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                       aten::clamp_min_         0.31%      11.000us         0.48%      17.000us       8.500us       4.000us         0.16%       4.000us       2.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                          aten::dropout         0.31%      11.000us         3.50%     125.000us      62.500us       0.000us         0.00%       4.000us       2.000us           0 b           0 b      36.00 Kb      -4.00 Kb             2  \n",
      "                                   aten::native_dropout         1.31%      47.000us         3.19%     114.000us      57.000us       4.000us         0.16%       4.000us       2.000us           0 b           0 b      40.00 Kb           0 b             2  \n",
      "                                       aten::empty_like         0.22%       8.000us         0.59%      21.000us       5.250us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      40.00 Kb           0 b             4  \n",
      "                                    aten::empty_strided         0.36%      13.000us         0.36%      13.000us       3.250us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      40.00 Kb      40.00 Kb             4  \n",
      "                                  cudaDeviceSynchronize        29.31%       1.048ms        29.31%       1.048ms       1.048ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us     479.000us        19.46%     479.000us     239.500us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.16%       4.000us       2.000us           0 b           0 b           0 b           0 b             2  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us      79.000us         3.21%      79.000us      79.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.575ms\n",
      "Self CUDA time total: 2.462ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-25 19:57:02 1850541:1850541 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-11-25 19:57:03 1850541:1850541 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-11-25 19:57:03 1850541:1850541 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "[W collection.cpp:700] Warning: Failed to recover relationship between all profiler and kineto events: 1 vs. 0  reassociated. (function reassociate)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((1,224,224,4)).cuda()\n",
    "layer = layers.FLOATConv2d(4,64)\n",
    "layer.cuda()\n",
    "with profile(activities=[ProfilerActivity.CUDA], record_shapes=True, profile_memory=True) as prof:\n",
    "    with torch.no_grad():\n",
    "        y = layer(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     cudaGetDeviceCount         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                   cudaDriverGetVersion         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                 cudaDeviceGetAttribute         0.00%       1.000us         0.00%       1.000us       0.031us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            32  \n",
      "                                cudaGetDeviceProperties         0.01%      46.000us         0.01%      46.000us      46.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                              cudaStreamCreateWithFlags         8.29%      62.604ms         8.29%      62.604ms       3.913ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            16  \n",
      "                                             cudaMalloc         0.04%     306.000us         0.04%     306.000us      61.200us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             5  \n",
      "                                        cudaMemsetAsync         0.00%      24.000us         0.00%      24.000us      24.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                          cudaHostAlloc         0.07%     509.000us         0.07%     509.000us     509.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         5.71%       2.000us       2.000us           0 b           0 b           0 b           0 b             1  \n",
      "                               cudaHostGetDevicePointer         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                               cudaFree        60.57%     457.450ms        60.57%     457.450ms     152.483ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                   cudaGetSymbolAddress         0.00%       1.000us         0.00%       1.000us       1.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                  cudaStreamIsCapturing         0.00%       3.000us         0.00%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                  cudaStreamGetPriority         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      12.25 Mb      12.25 Mb             1  \n",
      "                                       cudaLaunchKernel        31.03%     234.332ms        31.03%     234.332ms     234.332ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "void implicit_convolve_sgemm<float, float, 1024, 5, ...         0.00%       0.000us         0.00%       0.000us       0.000us      33.000us        94.29%      33.000us      33.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                  cudaDeviceSynchronize         0.00%       7.000us         0.00%       7.000us       7.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 755.283ms\n",
      "Self CUDA time total: 35.000us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-25 19:58:42 1850541:1850541 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-11-25 19:58:42 1850541:1850541 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-11-25 19:58:42 1850541:1850541 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "[W collection.cpp:700] Warning: Failed to recover relationship between all profiler and kineto events: 2 vs. 0  reassociated. (function reassociate)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randint(-128,127,(1,224,224,4), dtype=torch.int8).cuda()\n",
    "layer = layers.IntConv2d(4,64)\n",
    "layer.cuda()\n",
    "with profile(activities=[ProfilerActivity.CUDA], record_shapes=True, profile_memory=True) as prof:\n",
    "    with torch.no_grad():\n",
    "        y = layer(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  cudaStreamIsCapturing         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
      "                                  cudaStreamGetPriority         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             2  \n",
      "                                       cudaLaunchKernel        63.92%      62.000us        63.92%      62.000us      62.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
      "                                  cudaDeviceSynchronize        36.08%      35.000us        36.08%      35.000us      35.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
      "void convolve_common_engine_int8_NHWC<char, int, int...         0.00%       0.000us         0.00%       0.000us       0.000us      29.000us       100.00%      29.000us      29.000us           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 97.000us\n",
      "Self CUDA time total: 29.000us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
