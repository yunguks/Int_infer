{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from models import vgg,layers\n",
    "from torchvision.utils import _log_api_usage_once\n",
    "\n",
    "def manual_seed(seed):\n",
    "    np.random.seed(seed) #1\n",
    "    random.seed(seed) #2\n",
    "    torch.manual_seed(seed) #3\n",
    "    torch.cuda.manual_seed(seed) #4.1\n",
    "    torch.cuda.manual_seed_all(seed) #4.2\n",
    "    torch.backends.cudnn.benchmark = False #5 \n",
    "    torch.backends.cudnn.deterministic = True #6\n",
    "\n",
    "manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_option = True\n",
    "\n",
    "pre_vgg16 = vgg.vgg16(bias=bias_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU()\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU()\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU()\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU()\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU()\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU()\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU()\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pre_vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight parameter 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('features.0.weight', tensor([[[[ 0.0088, -0.0178, -0.0959],\n",
      "          [ 0.1229,  0.0205, -0.0342],\n",
      "          [ 0.0236,  0.1382,  0.0203]],\n",
      "\n",
      "         [[-0.0419,  0.0439,  0.0065],\n",
      "          [-0.1620,  0.0823,  0.0110],\n",
      "          [-0.0216,  0.0952,  0.0605]],\n",
      "\n",
      "         [[-0.1239,  0.1539,  0.0574],\n",
      "          [ 0.1103,  0.0528, -0.1128],\n",
      "          [ 0.1326, -0.1258, -0.0360]],\n",
      "\n",
      "         [[-0.1210,  0.0103, -0.1533],\n",
      "          [-0.0023,  0.1015,  0.0797],\n",
      "          [-0.1425, -0.1219, -0.0327]]],\n",
      "\n",
      "\n",
      "        [[[-0.1381, -0.0145, -0.1343],\n",
      "          [-0.1463, -0.1411,  0.0838],\n",
      "          [ 0.0225, -0.0231,  0.1605]],\n",
      "\n",
      "         [[ 0.0207,  0.0834, -0.0976],\n",
      "          [-0.0444, -0.1356, -0.1069],\n",
      "          [-0.1590, -0.0449,  0.1114]],\n",
      "\n",
      "         [[ 0.0404,  0.0889,  0.0159],\n",
      "          [-0.0699,  0.1607, -0.0762],\n",
      "          [ 0.0506, -0.1206,  0.0825]],\n",
      "\n",
      "         [[ 0.1037,  0.0541, -0.0952],\n",
      "          [-0.1022, -0.0776,  0.0323],\n",
      "          [ 0.0259,  0.0098,  0.1579]]],\n",
      "\n",
      "\n",
      "        [[[-0.0707, -0.0866, -0.0642],\n",
      "          [-0.1151, -0.0519,  0.1227],\n",
      "          [ 0.0886, -0.0435, -0.0869]],\n",
      "\n",
      "         [[-0.0134, -0.0062,  0.0206],\n",
      "          [ 0.0105,  0.0856, -0.0408],\n",
      "          [-0.0592,  0.1277, -0.0903]],\n",
      "\n",
      "         [[-0.1394,  0.0996, -0.0335],\n",
      "          [ 0.1151, -0.1086,  0.0772],\n",
      "          [ 0.0332,  0.0377, -0.0759]],\n",
      "\n",
      "         [[-0.0849,  0.0125, -0.1179],\n",
      "          [-0.0406, -0.1552,  0.1014],\n",
      "          [-0.1387, -0.1572,  0.0812]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1327,  0.1064, -0.1350],\n",
      "          [-0.0445,  0.1287,  0.1426],\n",
      "          [-0.1582,  0.0674, -0.1192]],\n",
      "\n",
      "         [[-0.0084, -0.1207,  0.0892],\n",
      "          [ 0.1142,  0.0544,  0.1280],\n",
      "          [-0.0643,  0.1474, -0.0309]],\n",
      "\n",
      "         [[ 0.1567,  0.1633,  0.0584],\n",
      "          [-0.0213,  0.0320, -0.1621],\n",
      "          [ 0.0024, -0.0201, -0.0208]],\n",
      "\n",
      "         [[-0.0755,  0.0472,  0.0672],\n",
      "          [-0.1249,  0.1338,  0.0330],\n",
      "          [-0.0788,  0.0646,  0.1532]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0140, -0.1285, -0.0982],\n",
      "          [-0.0979,  0.1142,  0.0805],\n",
      "          [-0.0469, -0.1388,  0.0213]],\n",
      "\n",
      "         [[ 0.1310, -0.0628, -0.1320],\n",
      "          [-0.1116,  0.0691, -0.1366],\n",
      "          [-0.1352, -0.1377, -0.1145]],\n",
      "\n",
      "         [[ 0.0184,  0.0595,  0.0758],\n",
      "          [-0.0485, -0.0502,  0.0876],\n",
      "          [ 0.1375,  0.0588,  0.0570]],\n",
      "\n",
      "         [[ 0.0240, -0.1261,  0.1605],\n",
      "          [ 0.1266,  0.0684,  0.0531],\n",
      "          [-0.1399, -0.1216,  0.0307]]],\n",
      "\n",
      "\n",
      "        [[[-0.0824, -0.0953,  0.1062],\n",
      "          [ 0.1031,  0.0692, -0.1592],\n",
      "          [-0.1220,  0.0115,  0.1367]],\n",
      "\n",
      "         [[ 0.0366,  0.0529, -0.0268],\n",
      "          [-0.0633,  0.0591, -0.1235],\n",
      "          [-0.0958, -0.0064,  0.0942]],\n",
      "\n",
      "         [[ 0.1381, -0.1604,  0.1231],\n",
      "          [-0.0949,  0.0858, -0.1202],\n",
      "          [ 0.0645, -0.1235,  0.0797]],\n",
      "\n",
      "         [[-0.1639,  0.0115,  0.0798],\n",
      "          [ 0.1552, -0.0823,  0.0081],\n",
      "          [ 0.1596, -0.0576,  0.0009]]]], device='cuda:0')), ('features.0.bias', tensor([-0.1466,  0.0587, -0.0155,  0.0434,  0.0622, -0.1552,  0.1071,  0.0120,\n",
      "        -0.1275, -0.0767,  0.0724,  0.1414, -0.1074,  0.0540, -0.0494, -0.1203,\n",
      "        -0.1500, -0.0217,  0.1141,  0.0851, -0.1277,  0.1019,  0.0264,  0.0421,\n",
      "        -0.1191,  0.1432, -0.0470, -0.0160, -0.0173,  0.0216,  0.0560, -0.0034,\n",
      "        -0.0385, -0.1230, -0.1539,  0.0532,  0.0920, -0.0545, -0.1577, -0.0766,\n",
      "        -0.0834, -0.0456, -0.0675, -0.0849,  0.0843,  0.0920, -0.0672,  0.1603,\n",
      "        -0.0549,  0.0356,  0.1170,  0.1209,  0.0125,  0.0041, -0.1162,  0.0013,\n",
      "         0.1133, -0.0847,  0.0776,  0.0218, -0.0643, -0.1204,  0.1652,  0.1292],\n",
      "       device='cuda:0')), ('features.2.weight', tensor([[[[-3.0606e-02, -9.8520e-02, -1.3260e-01],\n",
      "          [ 6.8208e-03, -8.3483e-02, -1.6697e-01],\n",
      "          [ 3.1015e-02, -6.5803e-02, -1.3171e-01]],\n",
      "\n",
      "         [[ 4.7407e-02, -2.7588e-02, -5.1127e-02],\n",
      "          [ 7.0129e-02,  8.2528e-03, -1.8340e-02],\n",
      "          [ 6.9918e-02,  3.8993e-02,  1.6228e-02]],\n",
      "\n",
      "         [[ 7.0700e-02,  5.2703e-03, -4.7362e-02],\n",
      "          [ 8.4006e-02,  4.9190e-02, -1.6474e-03],\n",
      "          [ 8.5166e-03,  2.2350e-02,  5.9118e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7666e-02,  2.1778e-02, -9.4606e-03],\n",
      "          [ 2.5511e-02,  4.1186e-03, -3.4521e-02],\n",
      "          [ 2.0150e-02,  3.7068e-02, -1.3509e-02]],\n",
      "\n",
      "         [[ 2.1684e-02,  4.1812e-02,  5.8284e-02],\n",
      "          [ 2.7431e-02,  3.6847e-02,  3.4335e-02],\n",
      "          [-9.4839e-03,  1.9745e-02,  5.0264e-02]],\n",
      "\n",
      "         [[ 2.1769e-02, -2.1388e-02, -9.9363e-02],\n",
      "          [-5.7156e-02, -7.1328e-02, -7.7600e-02],\n",
      "          [-3.7508e-02, -2.5453e-02, -4.5096e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.3319e-02, -7.7979e-02, -1.3496e-01],\n",
      "          [-3.7411e-02, -8.1807e-02, -1.4195e-01],\n",
      "          [-4.1913e-02, -1.0756e-01, -1.6164e-01]],\n",
      "\n",
      "         [[-6.8725e-03,  4.8598e-02,  1.5008e-02],\n",
      "          [ 1.8636e-02,  9.8393e-03, -1.5973e-02],\n",
      "          [ 9.5164e-04, -3.2665e-02, -3.5824e-02]],\n",
      "\n",
      "         [[ 1.4780e-02, -1.4260e-02, -4.4468e-02],\n",
      "          [-1.8438e-02,  1.4841e-02, -8.2337e-02],\n",
      "          [ 1.8329e-02,  2.1435e-03,  9.0911e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0342e-02,  3.6146e-02,  2.5515e-02],\n",
      "          [ 1.5779e-02,  3.1012e-03, -1.0942e-02],\n",
      "          [ 2.3790e-02,  1.6440e-02, -2.5835e-02]],\n",
      "\n",
      "         [[-2.2844e-02,  2.5371e-03, -2.1714e-02],\n",
      "          [ 3.9534e-04, -6.4903e-03,  1.6979e-02],\n",
      "          [-4.7200e-03, -2.2301e-02, -2.1298e-02]],\n",
      "\n",
      "         [[-2.8434e-02, -2.6771e-02,  2.7432e-02],\n",
      "          [-5.8088e-02, -5.5869e-02,  7.0289e-02],\n",
      "          [-6.4470e-02, -3.8172e-02,  4.1569e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2508e-02,  2.4738e-02,  5.3893e-02],\n",
      "          [-2.5838e-02, -1.6176e-02,  2.8344e-02],\n",
      "          [ 1.2948e-02,  9.0717e-03,  2.8181e-02]],\n",
      "\n",
      "         [[-7.9309e-02, -8.8828e-02, -5.5737e-02],\n",
      "          [-4.8359e-02, -1.1139e-01, -1.0901e-02],\n",
      "          [ 3.4640e-02,  2.3298e-02,  1.1002e-01]],\n",
      "\n",
      "         [[-4.3616e-02, -1.6598e-02, -1.0547e-02],\n",
      "          [ 2.8982e-02,  4.5279e-02,  1.6869e-02],\n",
      "          [ 8.8168e-02,  1.2599e-01,  7.2292e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3967e-03,  1.5333e-02, -1.7196e-02],\n",
      "          [-8.3107e-03, -1.2905e-02, -1.4394e-03],\n",
      "          [ 6.3471e-03,  1.7825e-03, -3.3770e-02]],\n",
      "\n",
      "         [[-7.9354e-03, -5.8610e-03, -7.6292e-05],\n",
      "          [ 6.8661e-04, -6.0019e-03,  1.0119e-02],\n",
      "          [ 3.0581e-02,  1.6821e-02,  3.2570e-02]],\n",
      "\n",
      "         [[ 5.9351e-02, -7.4398e-03,  3.8274e-02],\n",
      "          [-2.0792e-02, -4.8833e-02,  4.0274e-02],\n",
      "          [ 2.3138e-02,  7.4794e-03,  3.5027e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.5464e-02, -2.9275e-02,  1.0282e-02],\n",
      "          [-4.6952e-02, -4.9473e-02,  1.7632e-02],\n",
      "          [-4.3815e-02, -2.4871e-02, -2.4908e-02]],\n",
      "\n",
      "         [[-1.9359e-02,  1.5948e-02, -6.3554e-02],\n",
      "          [ 3.0096e-02,  2.8515e-02, -6.4439e-02],\n",
      "          [-1.4547e-02,  2.2238e-03, -6.3371e-02]],\n",
      "\n",
      "         [[-2.7915e-02, -2.1738e-02, -5.1691e-02],\n",
      "          [ 1.0889e-02, -5.1994e-02, -5.4649e-02],\n",
      "          [-3.9741e-02,  5.2832e-04,  3.5375e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9130e-03,  1.0995e-03, -7.4082e-03],\n",
      "          [ 1.8428e-03,  8.2602e-03,  1.8680e-02],\n",
      "          [ 1.1709e-02,  6.9263e-03,  3.3630e-02]],\n",
      "\n",
      "         [[ 8.9195e-03,  3.2807e-02,  3.9282e-02],\n",
      "          [-2.5044e-03,  1.7645e-03,  1.4056e-02],\n",
      "          [-5.4708e-03,  9.5572e-03,  2.8639e-02]],\n",
      "\n",
      "         [[-3.0241e-02, -6.7225e-02, -7.4299e-02],\n",
      "          [-3.6222e-02, -9.7721e-03,  6.1669e-02],\n",
      "          [-1.6392e-02,  5.8156e-02,  1.2894e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0321e-02,  3.7677e-02,  1.7181e-02],\n",
      "          [ 4.0298e-02,  2.9479e-02,  1.6698e-02],\n",
      "          [-4.8739e-03,  2.1128e-02, -2.6295e-03]],\n",
      "\n",
      "         [[ 3.1079e-02, -1.6475e-02,  1.0769e-02],\n",
      "          [-5.8626e-02, -4.6721e-02, -2.7764e-02],\n",
      "          [-3.1245e-02,  1.7635e-02, -1.2211e-02]],\n",
      "\n",
      "         [[-9.8675e-02, -9.8915e-02, -1.3225e-01],\n",
      "          [ 7.3214e-02, -7.5238e-03, -7.4033e-02],\n",
      "          [ 1.7070e-01,  1.8346e-01,  3.3906e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5318e-02,  3.2680e-02,  5.2874e-03],\n",
      "          [-4.1894e-03,  2.0011e-02,  1.6021e-02],\n",
      "          [-4.8276e-03, -2.9130e-02,  7.4975e-04]],\n",
      "\n",
      "         [[ 7.1959e-03, -5.1528e-03,  5.1333e-03],\n",
      "          [-8.6466e-04,  1.2417e-02,  2.0805e-02],\n",
      "          [ 2.4862e-03, -1.3194e-02,  3.6563e-03]],\n",
      "\n",
      "         [[ 3.2415e-02,  1.0823e-02,  3.1720e-02],\n",
      "          [-8.4911e-03,  5.9831e-02,  3.4606e-02],\n",
      "          [-2.0674e-02,  1.6525e-02, -1.3183e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.6955e-02,  1.0821e-02,  7.9260e-02],\n",
      "          [ 1.0361e-02, -3.3380e-02,  5.2775e-02],\n",
      "          [-3.8372e-02, -3.0964e-02,  6.5422e-02]],\n",
      "\n",
      "         [[ 5.4925e-02, -1.9160e-01,  9.9709e-02],\n",
      "          [-1.8754e-01,  1.3248e-02,  2.4748e-01],\n",
      "          [-5.6662e-03,  2.8737e-02, -8.9787e-02]],\n",
      "\n",
      "         [[-1.4905e-01, -1.2974e-01,  1.7649e-01],\n",
      "          [-1.5774e-01,  1.5130e-01,  8.4126e-02],\n",
      "          [ 9.4988e-02,  8.5186e-02, -3.3635e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2278e-02,  3.3348e-02, -1.0524e-02],\n",
      "          [ 5.0310e-02, -9.1280e-03, -3.3890e-02],\n",
      "          [ 1.3459e-02, -2.9601e-02,  2.6862e-02]],\n",
      "\n",
      "         [[ 3.1006e-02,  2.8481e-02,  5.2361e-03],\n",
      "          [ 3.8914e-03, -1.8899e-02, -2.1819e-02],\n",
      "          [-8.4505e-03, -3.6632e-02, -1.9476e-02]],\n",
      "\n",
      "         [[ 2.3835e-02,  4.5658e-02,  6.7297e-02],\n",
      "          [ 1.1103e-02,  3.2035e-02, -5.8449e-02],\n",
      "          [ 2.6805e-02, -9.3975e-02, -4.0504e-02]]]], device='cuda:0')), ('features.2.bias', tensor([ 0.0020, -0.0902,  0.6164, -0.0818,  0.2450, -0.0488,  0.1307, -0.0290,\n",
      "        -0.1429,  0.3068, -0.0399, -0.2524,  0.0999, -0.2326,  0.0353, -0.0904,\n",
      "         0.1138, -0.0307, -0.0108, -0.0215,  0.0554,  0.1382,  0.0362, -0.4511,\n",
      "         0.0056, -0.0246, -0.4296, -0.1458,  0.3813, -0.0359,  0.1184, -0.3527,\n",
      "        -0.0239, -0.0235,  0.6499, -0.0634, -0.0152, -0.2285,  0.0941, -0.5053,\n",
      "         0.1906,  0.0944,  0.3406, -0.0833,  0.1924, -0.1953, -0.0421, -0.1606,\n",
      "         0.3964,  0.2068,  0.1812, -0.1198, -0.0724, -0.1240,  0.1313,  0.1043,\n",
      "         0.5469,  0.5208,  0.0509, -0.8278,  0.4372, -0.3734, -0.3264, -0.1213],\n",
      "       device='cuda:0')), ('features.5.weight', tensor([[[[-6.2810e-02,  1.1339e-02, -4.0391e-02],\n",
      "          [-5.1637e-02, -5.7086e-02, -1.2647e-01],\n",
      "          [-1.3824e-02, -5.4079e-02, -8.2741e-02]],\n",
      "\n",
      "         [[-5.1361e-02, -3.3589e-02, -3.0128e-02],\n",
      "          [-3.1981e-02, -3.5140e-02,  2.4252e-03],\n",
      "          [-4.1960e-03, -1.4064e-02,  1.3642e-02]],\n",
      "\n",
      "         [[-2.8838e-02,  5.2136e-02,  5.1848e-02],\n",
      "          [-3.7392e-02,  1.4356e-01, -3.5255e-02],\n",
      "          [-2.9268e-02,  2.1488e-02, -3.1739e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3000e-02, -1.1137e-02, -4.2528e-03],\n",
      "          [-1.9321e-02, -4.3134e-02, -5.5873e-04],\n",
      "          [-4.2867e-02, -1.4233e-02, -1.3526e-02]],\n",
      "\n",
      "         [[-2.7698e-02, -1.6312e-02, -2.3137e-02],\n",
      "          [ 2.7924e-02,  3.4780e-02, -4.5055e-02],\n",
      "          [ 4.9343e-02,  1.1931e-02, -3.7526e-03]],\n",
      "\n",
      "         [[ 1.4084e-02,  1.7446e-02, -8.3521e-03],\n",
      "          [ 6.4733e-03,  7.4886e-02, -5.2302e-03],\n",
      "          [-3.3729e-02,  5.7670e-02, -1.1322e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.6400e-04, -3.0072e-02, -2.5162e-02],\n",
      "          [-1.5606e-02, -3.7128e-02, -4.2133e-02],\n",
      "          [-4.9897e-03, -2.8128e-03, -4.8388e-02]],\n",
      "\n",
      "         [[-2.1050e-02, -1.2844e-02,  2.3434e-03],\n",
      "          [-3.1928e-02, -3.5125e-02,  1.3496e-02],\n",
      "          [ 1.2840e-02, -2.1722e-03,  1.9916e-02]],\n",
      "\n",
      "         [[-5.4853e-02, -1.4703e-02,  5.7742e-02],\n",
      "          [-1.4970e-01,  9.0838e-02,  1.8018e-01],\n",
      "          [-5.1293e-02,  4.0009e-03,  7.5791e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3281e-02, -2.7738e-02, -4.9568e-02],\n",
      "          [ 2.3973e-02, -2.3895e-02, -6.5836e-03],\n",
      "          [ 5.9873e-02,  2.1132e-02, -1.5224e-02]],\n",
      "\n",
      "         [[-5.2145e-02, -2.6414e-02, -2.5841e-02],\n",
      "          [-3.0816e-02, -5.0158e-02,  3.9022e-02],\n",
      "          [ 4.1870e-02, -2.2169e-02, -3.2523e-02]],\n",
      "\n",
      "         [[-2.4134e-03,  3.2657e-03,  2.7356e-02],\n",
      "          [-4.2036e-02,  7.5291e-03, -1.1726e-02],\n",
      "          [ 4.0441e-02,  1.2264e-01, -4.8728e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3180e-02, -2.2260e-02, -3.3540e-03],\n",
      "          [ 1.4570e-02,  7.5933e-02, -5.2729e-02],\n",
      "          [-4.9156e-02,  3.9846e-02,  8.7439e-04]],\n",
      "\n",
      "         [[ 1.5670e-02,  5.4018e-03,  4.5666e-02],\n",
      "          [-6.3589e-03,  4.6707e-02,  4.5305e-02],\n",
      "          [-7.1617e-02,  3.8063e-02,  1.4691e-02]],\n",
      "\n",
      "         [[-4.5694e-02,  3.2703e-02,  1.1262e-02],\n",
      "          [-4.9579e-02,  2.9527e-02, -2.7634e-02],\n",
      "          [ 1.1622e-02,  5.6397e-02, -2.6861e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1792e-02, -2.6591e-02, -2.0085e-04],\n",
      "          [-6.0890e-02, -5.5885e-02, -3.8149e-02],\n",
      "          [ 3.8406e-02, -9.7790e-03, -1.4222e-03]],\n",
      "\n",
      "         [[-4.4498e-02, -2.2446e-02, -6.2459e-02],\n",
      "          [-2.5728e-02,  1.1222e-02, -2.5034e-02],\n",
      "          [ 1.9746e-02, -4.1720e-02, -3.2745e-02]],\n",
      "\n",
      "         [[ 2.3275e-02, -5.6597e-04,  1.7023e-02],\n",
      "          [-3.7929e-02,  8.4074e-02,  1.5500e-02],\n",
      "          [ 8.4187e-03, -5.3071e-02, -1.9120e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.8440e-03, -9.4784e-03, -1.9466e-02],\n",
      "          [-1.7608e-02,  4.3330e-02, -4.1369e-02],\n",
      "          [-2.6391e-02, -2.8507e-02, -9.8986e-04]],\n",
      "\n",
      "         [[-6.2622e-02, -4.5775e-02,  1.0037e-02],\n",
      "          [-3.5123e-02, -5.3560e-02,  2.6610e-02],\n",
      "          [ 7.1417e-03, -1.4646e-02,  6.5733e-03]],\n",
      "\n",
      "         [[ 1.5414e-02,  2.7492e-01,  2.1435e-01],\n",
      "          [-9.2970e-02, -1.7520e-02,  6.8770e-02],\n",
      "          [-1.4798e-01, -1.1129e-01, -7.8531e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.9160e-03,  5.5912e-02,  8.1550e-03],\n",
      "          [-8.3287e-03, -3.8522e-02, -4.4384e-02],\n",
      "          [ 3.0769e-02,  5.2761e-02, -3.3069e-03]],\n",
      "\n",
      "         [[ 4.4858e-03,  1.0840e-01, -9.7890e-03],\n",
      "          [-3.9745e-02, -1.3879e-01,  1.2488e-02],\n",
      "          [-4.7321e-02, -2.9251e-02, -2.4057e-02]],\n",
      "\n",
      "         [[-9.8491e-02,  7.1428e-03, -3.5822e-02],\n",
      "          [-3.7229e-02,  1.6014e-01, -2.8598e-02],\n",
      "          [-1.4895e-02,  7.6893e-02,  7.7165e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3394e-02,  4.9751e-02,  2.0830e-02],\n",
      "          [ 1.6439e-02,  1.7401e-02, -2.3603e-02],\n",
      "          [-2.3165e-02, -9.2761e-02, -2.4903e-02]],\n",
      "\n",
      "         [[-4.5251e-02, -2.4458e-02,  9.8124e-03],\n",
      "          [-8.4512e-03, -2.0820e-02,  2.8578e-02],\n",
      "          [ 4.5104e-02,  1.2810e-03,  2.3833e-02]],\n",
      "\n",
      "         [[ 8.3300e-02,  6.6573e-02,  3.1433e-02],\n",
      "          [-1.1266e-01,  9.9167e-02,  1.6835e-01],\n",
      "          [-3.5607e-02, -4.2154e-02,  5.0973e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1448e-02,  3.5827e-02,  5.3240e-02],\n",
      "          [-4.3761e-02, -2.4301e-02,  2.9110e-02],\n",
      "          [-3.8008e-04,  3.3345e-02,  5.7502e-03]],\n",
      "\n",
      "         [[ 2.8796e-04,  6.5530e-03, -6.0024e-02],\n",
      "          [-4.6629e-02, -1.9900e-02,  9.3691e-03],\n",
      "          [ 7.9185e-02,  6.4821e-02,  1.0142e-02]],\n",
      "\n",
      "         [[ 7.4917e-02,  4.8451e-02,  1.5926e-01],\n",
      "          [-4.0570e-02, -1.6576e-01,  3.1683e-02],\n",
      "          [-5.5403e-02, -1.4255e-02,  2.3551e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4041e-02, -9.3939e-03,  3.3714e-02],\n",
      "          [ 6.1786e-02, -7.3343e-02, -4.9163e-02],\n",
      "          [ 7.0314e-02,  7.0862e-02, -3.5670e-02]],\n",
      "\n",
      "         [[-6.0474e-03,  2.3996e-03,  2.4723e-02],\n",
      "          [ 1.1873e-02, -1.4914e-02,  2.6962e-02],\n",
      "          [-9.5375e-03, -2.8718e-02, -1.2086e-02]],\n",
      "\n",
      "         [[-1.0172e-01, -2.3414e-01, -5.6336e-02],\n",
      "          [ 7.5019e-02,  1.3930e-03, -6.2536e-02],\n",
      "          [ 1.4913e-01,  2.4970e-01,  1.4187e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.7739e-03, -4.8837e-02, -3.6353e-03],\n",
      "          [ 1.8116e-02, -3.6125e-02,  6.8408e-03],\n",
      "          [ 3.9892e-02,  4.8252e-04,  1.6367e-02]],\n",
      "\n",
      "         [[-6.7317e-02, -1.9475e-01, -9.3308e-02],\n",
      "          [ 1.3558e-01,  7.9305e-02, -9.1780e-02],\n",
      "          [ 1.0593e-02,  3.3229e-02,  2.0905e-02]],\n",
      "\n",
      "         [[ 7.5557e-02, -2.7272e-02,  1.5518e-02],\n",
      "          [-6.9644e-03, -1.0359e-01,  4.6841e-02],\n",
      "          [ 3.0022e-02, -5.4782e-02,  5.3461e-02]]]], device='cuda:0')), ('features.5.bias', tensor([ 8.6646e-02, -1.8141e-02,  1.3419e-01,  2.1687e-02,  6.2591e-02,\n",
      "        -7.4722e-02,  3.3089e-02,  9.0404e-02,  1.8341e-01,  7.4501e-02,\n",
      "         5.9911e-02, -1.4331e-02,  1.7103e-01,  6.2786e-03,  3.5013e-02,\n",
      "         1.7912e-01, -5.8908e-02,  1.2702e-01,  1.7914e-01,  2.3746e-01,\n",
      "         1.8726e-02, -2.8949e-02,  1.8745e-01,  3.9840e-02,  1.4654e-01,\n",
      "         2.1923e-02,  1.0498e-01,  1.4209e-01, -7.0994e-02, -1.8345e-02,\n",
      "         8.8975e-02,  5.7054e-02,  1.3888e-01,  2.0818e-01,  1.0774e-01,\n",
      "         8.5410e-02,  1.7150e-02,  2.7108e-01,  8.7119e-02,  5.9371e-02,\n",
      "         3.1665e-01, -5.2632e-02,  1.5077e-01,  6.4080e-02,  1.7603e-01,\n",
      "         1.7029e-01, -6.4618e-02,  1.3616e-01,  1.6723e-02, -6.7827e-02,\n",
      "         6.3060e-02,  1.4921e-01,  1.0507e-01,  4.7822e-02,  2.7649e-01,\n",
      "         7.2342e-02, -1.2613e-01,  1.6345e-01, -6.4522e-02, -7.8599e-03,\n",
      "         1.4376e-01,  1.6144e-01,  2.5510e-02,  1.1751e-01, -8.8816e-02,\n",
      "         2.2240e-01,  5.5771e-02,  1.4372e-02,  1.6451e-01, -1.9882e-01,\n",
      "         1.9057e-04,  2.2923e-02, -1.7259e-01,  8.1201e-02,  3.7978e-02,\n",
      "        -1.1063e-01,  6.8450e-02,  5.3313e-02,  5.5594e-03,  6.8257e-02,\n",
      "        -2.5634e-01,  8.1244e-02, -6.9248e-02,  5.4548e-02, -5.9897e-02,\n",
      "         1.2019e-01, -1.7203e-01,  7.0961e-02,  3.0969e-02, -8.0818e-02,\n",
      "         5.1265e-02, -2.0620e-01,  1.9448e-01, -8.8990e-02, -8.6148e-02,\n",
      "         1.7088e-01,  1.6314e-01,  2.2548e-01,  1.3626e-01, -2.8991e-02,\n",
      "        -8.5338e-02, -1.5907e-03,  1.2849e-02, -7.6387e-02, -2.3490e-02,\n",
      "         3.2957e-02,  1.6553e-01, -2.1522e-02, -1.0091e-02,  1.2563e-01,\n",
      "         2.0017e-01,  1.6585e-01,  2.4983e-02,  9.0528e-02,  1.5877e-01,\n",
      "        -1.4161e-01,  8.8158e-02,  4.9040e-02, -7.7915e-02,  1.3045e-01,\n",
      "         8.2526e-02,  2.0595e-01,  7.4943e-02, -9.7283e-03, -1.0830e-02,\n",
      "         7.4388e-02,  7.4235e-02,  1.4483e-01], device='cuda:0')), ('features.7.weight', tensor([[[[ 2.5788e-02, -1.9852e-02, -1.0697e-02],\n",
      "          [-1.6114e-02, -4.1759e-03,  8.4582e-03],\n",
      "          [ 4.0309e-03,  1.8973e-02,  3.8059e-02]],\n",
      "\n",
      "         [[-5.4261e-02, -2.9872e-02,  1.1506e-02],\n",
      "          [-1.8266e-02, -1.5708e-02, -1.2726e-02],\n",
      "          [ 2.0867e-02, -5.6425e-03, -5.1218e-04]],\n",
      "\n",
      "         [[ 1.8961e-02, -2.3766e-03,  6.1427e-03],\n",
      "          [-5.1761e-02, -1.7272e-02,  8.7075e-03],\n",
      "          [-4.4383e-02,  2.3661e-02,  9.0710e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8603e-02, -2.2412e-02,  1.4266e-03],\n",
      "          [-1.0810e-02, -1.2563e-02,  5.8555e-02],\n",
      "          [-1.9603e-02,  3.8292e-02,  6.6033e-02]],\n",
      "\n",
      "         [[ 8.0053e-02,  4.5974e-02,  4.2854e-02],\n",
      "          [ 3.4144e-02,  4.1228e-02,  8.4107e-03],\n",
      "          [-8.5212e-02, -7.2149e-02, -6.1367e-02]],\n",
      "\n",
      "         [[-5.1872e-02, -1.7269e-02,  8.3412e-03],\n",
      "          [-1.5657e-02,  6.5357e-03,  5.3442e-03],\n",
      "          [ 7.0546e-02,  6.6640e-02,  2.9743e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4477e-02,  1.7372e-02,  3.8637e-02],\n",
      "          [ 1.7122e-02,  6.5499e-03,  3.3277e-02],\n",
      "          [ 5.1735e-02,  5.2232e-02,  2.2086e-02]],\n",
      "\n",
      "         [[-4.9817e-03,  7.8477e-03,  1.0481e-03],\n",
      "          [-5.5254e-03,  1.1731e-03, -2.8846e-02],\n",
      "          [-1.5166e-02,  1.4712e-02, -2.5996e-02]],\n",
      "\n",
      "         [[ 1.4313e-02,  7.7863e-03, -2.5710e-02],\n",
      "          [ 3.6445e-02,  3.8037e-02,  2.1568e-02],\n",
      "          [ 3.9633e-02,  4.1395e-02, -2.7349e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9668e-02, -1.8495e-02, -4.5170e-03],\n",
      "          [ 1.0013e-02,  8.0232e-03, -4.4554e-02],\n",
      "          [ 2.3961e-02, -2.2513e-02,  3.8967e-03]],\n",
      "\n",
      "         [[-9.3318e-03, -2.7975e-03, -4.5400e-03],\n",
      "          [ 1.9306e-03, -3.1315e-02,  6.2495e-03],\n",
      "          [ 8.4360e-03, -3.6533e-02,  3.6175e-03]],\n",
      "\n",
      "         [[-3.0665e-02, -4.4897e-02, -7.7372e-02],\n",
      "          [-3.9120e-02, -6.0861e-02, -8.4005e-02],\n",
      "          [ 5.7575e-02, -4.9973e-04, -1.2297e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7533e-02,  6.1958e-02, -1.5773e-02],\n",
      "          [-4.7994e-02, -5.2918e-02, -5.5357e-02],\n",
      "          [-9.8468e-04, -2.2081e-02,  8.1542e-03]],\n",
      "\n",
      "         [[ 2.1069e-02, -3.1143e-02, -2.8263e-02],\n",
      "          [-5.5108e-02, -1.2559e-01, -8.1983e-02],\n",
      "          [ 2.1143e-02, -3.4396e-02, -1.1907e-02]],\n",
      "\n",
      "         [[-9.8582e-03, -5.1275e-03,  1.4424e-03],\n",
      "          [ 5.5997e-02,  1.3562e-01,  1.9257e-02],\n",
      "          [-6.5687e-02, -1.8309e-02, -3.9470e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8227e-02,  4.5086e-02, -3.0288e-02],\n",
      "          [-1.6840e-02, -2.2179e-03, -3.2186e-02],\n",
      "          [-4.6969e-02, -8.1806e-02,  7.7194e-02]],\n",
      "\n",
      "         [[-7.4163e-02, -4.7645e-02,  5.8225e-02],\n",
      "          [-7.1075e-02,  1.0040e-02,  6.5806e-02],\n",
      "          [-3.9398e-03, -9.7729e-03,  9.5199e-02]],\n",
      "\n",
      "         [[-4.3413e-02,  2.7101e-02, -1.2636e-02],\n",
      "          [ 3.7488e-03,  4.2913e-03,  3.0900e-03],\n",
      "          [ 3.3433e-02,  3.0384e-02,  5.1019e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.5468e-02,  5.1462e-02,  2.2881e-02],\n",
      "          [ 5.7329e-02,  1.7325e-02, -1.2769e-02],\n",
      "          [ 3.1118e-02, -3.9026e-02, -6.2358e-02]],\n",
      "\n",
      "         [[-7.0737e-02, -4.5867e-02, -1.8765e-02],\n",
      "          [-6.7420e-03, -1.0010e-02, -6.2032e-02],\n",
      "          [ 6.2941e-03, -1.3777e-02, -5.5997e-02]],\n",
      "\n",
      "         [[-1.2475e-02,  2.6069e-02, -4.5512e-03],\n",
      "          [ 4.8936e-02, -7.6861e-03, -1.0415e-01],\n",
      "          [ 1.1287e-02, -4.4848e-02, -8.4382e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0006e-02,  5.7238e-02, -3.4275e-03],\n",
      "          [ 4.7454e-02,  4.8209e-03, -8.8796e-02],\n",
      "          [ 6.8828e-02, -3.6591e-02, -8.3883e-02]],\n",
      "\n",
      "         [[-8.6139e-02, -4.4840e-02, -5.2773e-02],\n",
      "          [-3.1619e-02,  8.5002e-04,  2.5091e-02],\n",
      "          [ 4.1867e-03,  2.5540e-02,  5.2885e-02]],\n",
      "\n",
      "         [[-2.6334e-02, -8.2095e-02, -4.9413e-02],\n",
      "          [-1.4520e-02, -6.7272e-02, -4.8400e-02],\n",
      "          [-3.4450e-02, -5.3121e-02,  1.4509e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1221e-02, -2.6395e-02, -6.8177e-02],\n",
      "          [-1.3308e-02, -2.4194e-02, -2.1912e-02],\n",
      "          [-1.8293e-02, -1.8923e-02, -1.0353e-02]],\n",
      "\n",
      "         [[-2.7944e-02, -2.5907e-02, -1.5582e-02],\n",
      "          [-4.8443e-02, -6.0070e-03,  1.2176e-04],\n",
      "          [-3.3587e-02, -2.2929e-02, -3.5778e-03]],\n",
      "\n",
      "         [[-5.3952e-02, -5.4047e-02, -2.1393e-02],\n",
      "          [-2.5399e-02, -4.8201e-03,  1.2715e-02],\n",
      "          [-3.3006e-02, -9.2941e-03,  4.0095e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0834e-01,  3.6012e-02, -1.4283e-02],\n",
      "          [ 6.2926e-02,  9.6225e-03, -1.5355e-02],\n",
      "          [ 3.4179e-02, -2.8131e-03, -3.6031e-02]],\n",
      "\n",
      "         [[-6.5453e-02, -4.3534e-02, -1.2491e-02],\n",
      "          [-6.4196e-02, -5.0347e-02, -1.9350e-02],\n",
      "          [-2.0023e-02,  6.0370e-04,  1.2963e-03]],\n",
      "\n",
      "         [[-1.2661e-02, -8.3580e-03,  5.1847e-03],\n",
      "          [ 4.2209e-03, -1.9068e-02,  1.4444e-02],\n",
      "          [ 4.2795e-03,  7.2975e-03,  1.5227e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.0003e-03,  1.0324e-02, -7.5080e-03],\n",
      "          [-4.3927e-04,  4.9710e-03,  2.4126e-02],\n",
      "          [ 4.4565e-03,  3.8436e-02,  6.3350e-03]],\n",
      "\n",
      "         [[-1.2821e-02,  1.2153e-02,  1.8981e-02],\n",
      "          [-9.3514e-03,  1.8435e-02, -1.3223e-02],\n",
      "          [-5.3401e-04,  1.0125e-02, -6.2764e-03]],\n",
      "\n",
      "         [[-3.9147e-05,  2.6507e-02, -2.3274e-02],\n",
      "          [-3.3350e-02,  3.1395e-02, -3.3022e-02],\n",
      "          [-2.0826e-02,  2.2062e-03, -4.0605e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3357e-02,  1.3738e-02, -3.0007e-02],\n",
      "          [-4.8696e-03,  3.5501e-02, -3.0733e-02],\n",
      "          [-3.6084e-02, -4.8515e-03, -2.5580e-02]],\n",
      "\n",
      "         [[ 4.5643e-02, -8.4773e-03, -1.2161e-02],\n",
      "          [ 2.9042e-02,  1.0096e-02,  2.8676e-02],\n",
      "          [-1.9727e-02, -2.3097e-02,  1.5411e-03]],\n",
      "\n",
      "         [[ 4.5912e-02,  5.1751e-02, -1.0848e-02],\n",
      "          [-6.4884e-03, -2.1099e-02, -1.6500e-02],\n",
      "          [-7.0777e-03, -5.5341e-03,  1.7106e-02]]]], device='cuda:0')), ('features.7.bias', tensor([-2.6160e-02,  3.7561e-01, -1.0959e-01, -1.2908e-01, -3.3063e-02,\n",
      "        -1.7771e-01,  2.6658e-01, -3.4235e-04,  1.0146e-01, -1.3632e-01,\n",
      "        -1.3493e-01, -8.2296e-02, -3.8719e-02, -1.3540e-02,  1.4804e-01,\n",
      "         1.4590e-01,  1.2211e-01, -2.6188e-01, -3.8504e-03,  2.6068e-01,\n",
      "        -1.3415e-01,  8.1108e-02,  4.6663e-02,  8.8426e-02,  9.2182e-01,\n",
      "         1.7636e-01,  2.6631e-01, -2.4935e-02,  1.4909e-01,  5.3638e-02,\n",
      "         6.0319e-02,  1.1674e-01, -1.2548e-01,  1.7780e-01, -3.8083e-02,\n",
      "        -7.0598e-02, -1.6346e-02, -8.9410e-03, -2.6236e-01,  1.8348e-01,\n",
      "        -2.4746e-02, -1.6002e-02,  4.1249e-02, -1.3394e-01,  4.4561e-02,\n",
      "        -2.6911e-01, -5.6208e-02,  3.5030e-02, -4.0998e-02, -8.0173e-03,\n",
      "        -9.4496e-02,  1.1803e-01, -2.1164e-01,  2.5524e-01,  8.3103e-02,\n",
      "        -8.4798e-02,  1.7564e-04,  3.2745e-02,  1.9275e-02, -8.3005e-02,\n",
      "         1.2351e-01,  1.2453e-01,  4.2522e-02,  1.9826e-01,  3.5919e-02,\n",
      "         3.3214e-02, -1.5068e-02,  1.7456e-02, -5.5684e-02,  1.8592e-02,\n",
      "         9.8663e-02,  5.8580e-03, -7.4203e-02,  8.3461e-02,  1.1803e-01,\n",
      "         2.2759e-01,  2.6386e-01,  1.8882e-02,  7.1198e-03,  2.4375e-02,\n",
      "        -3.8069e-02,  1.1858e-01, -2.5809e-02, -1.6493e-01, -6.0023e-02,\n",
      "         1.5828e-01, -1.8128e-02,  1.7147e-02, -7.6780e-02, -1.1399e-01,\n",
      "        -1.0978e-02,  1.5395e-02, -1.7809e-01,  2.4206e-02, -6.1828e-02,\n",
      "         5.8281e-02, -2.2583e-02, -4.3978e-03, -2.1522e-01,  3.5710e-01,\n",
      "         7.0420e-02,  8.9824e-02, -1.2217e-01,  2.8388e-02,  2.8128e-01,\n",
      "         3.2103e-02, -2.4124e-02,  9.8025e-02,  1.9275e-01,  4.8849e-02,\n",
      "         1.8694e-01, -3.0950e-01,  4.4180e-02,  2.6609e-01, -6.0079e-02,\n",
      "        -1.0044e-01, -2.3358e-01,  6.0253e-02, -5.7333e-02,  4.0281e-02,\n",
      "        -1.8849e-01, -1.0592e-01,  2.7282e-01,  1.7372e-01,  2.6091e-01,\n",
      "        -3.5119e-02,  6.3524e-02,  2.1413e-01], device='cuda:0')), ('features.10.weight', tensor([[[[-1.1008e-02,  5.2181e-04,  2.0165e-02],\n",
      "          [-1.9239e-02, -3.1387e-02, -9.3394e-03],\n",
      "          [-5.2665e-02, -5.4552e-02, -6.9972e-03]],\n",
      "\n",
      "         [[ 2.0017e-02,  1.7184e-02,  2.1192e-02],\n",
      "          [ 8.5676e-03,  1.1236e-02,  2.0709e-02],\n",
      "          [ 6.6602e-03, -2.2648e-02,  1.2209e-02]],\n",
      "\n",
      "         [[ 4.9262e-02,  1.0558e-02, -2.9823e-03],\n",
      "          [-8.8304e-04,  1.2206e-02,  2.0749e-03],\n",
      "          [ 2.7586e-02,  7.7105e-05,  2.1245e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0546e-02,  2.1967e-02,  2.3511e-02],\n",
      "          [-6.7902e-02, -8.1078e-03,  2.6165e-02],\n",
      "          [-1.0581e-01, -6.6538e-02,  2.7534e-03]],\n",
      "\n",
      "         [[ 3.6559e-02,  3.6259e-02,  4.6347e-02],\n",
      "          [-9.3869e-03,  7.9205e-03,  3.2348e-02],\n",
      "          [-3.5539e-02, -1.5318e-02,  1.1864e-03]],\n",
      "\n",
      "         [[-2.1000e-02,  5.7321e-03, -8.2030e-03],\n",
      "          [-1.8231e-02,  1.2254e-02,  1.4853e-02],\n",
      "          [-3.0732e-02, -5.5477e-03, -2.5914e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1417e-02, -2.8491e-02, -3.2380e-02],\n",
      "          [ 2.3106e-03, -1.5136e-02, -2.7720e-02],\n",
      "          [-4.1440e-02, -3.7288e-02, -1.8089e-02]],\n",
      "\n",
      "         [[ 3.9357e-03, -6.3219e-03,  6.6615e-03],\n",
      "          [ 2.0829e-02,  1.1740e-02, -2.5786e-03],\n",
      "          [ 2.2405e-02,  1.2657e-02, -1.9856e-02]],\n",
      "\n",
      "         [[ 5.5530e-02,  7.8947e-02,  7.7657e-02],\n",
      "          [ 9.1851e-02,  3.1986e-01,  1.6033e-01],\n",
      "          [ 7.9647e-02,  2.1483e-01,  1.2694e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3931e-03, -3.2048e-02, -2.0430e-02],\n",
      "          [-2.4674e-02, -4.8157e-02, -5.4472e-02],\n",
      "          [-3.8650e-02, -5.1003e-02, -2.0275e-02]],\n",
      "\n",
      "         [[ 4.0564e-02,  1.2618e-02,  9.2595e-03],\n",
      "          [ 2.6360e-02, -1.4243e-02, -1.0471e-02],\n",
      "          [-7.4169e-03, -2.0603e-02, -2.5345e-02]],\n",
      "\n",
      "         [[ 1.3168e-04,  5.7046e-03, -2.1024e-04],\n",
      "          [ 4.6556e-02,  7.7847e-03,  1.2681e-02],\n",
      "          [ 6.8144e-04, -1.5033e-02, -1.1644e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0750e-02, -3.4188e-02, -2.8340e-03],\n",
      "          [-4.3754e-02, -5.6995e-02,  1.2863e-02],\n",
      "          [-3.1518e-02, -6.6091e-02,  1.4699e-02]],\n",
      "\n",
      "         [[ 5.0747e-02, -3.6635e-03,  3.6801e-03],\n",
      "          [-1.9261e-03, -4.4846e-02,  5.4276e-02],\n",
      "          [-2.3349e-03, -2.0560e-02,  4.7001e-02]],\n",
      "\n",
      "         [[ 2.7941e-02,  5.9823e-02, -1.0393e-02],\n",
      "          [ 8.7131e-02, -4.7270e-03,  1.1249e-02],\n",
      "          [ 6.9137e-02,  7.5738e-04,  1.6339e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6982e-02,  4.0079e-02, -7.7930e-03],\n",
      "          [-3.7076e-02, -1.9312e-02, -2.7063e-02],\n",
      "          [-1.0673e-02, -2.4535e-02,  9.9783e-03]],\n",
      "\n",
      "         [[-1.2083e-02,  2.4626e-03, -1.4940e-02],\n",
      "          [ 2.1548e-03,  2.9447e-02, -2.1811e-03],\n",
      "          [-2.0534e-02,  3.7243e-02, -2.7121e-02]],\n",
      "\n",
      "         [[-1.3047e-02, -3.7589e-02, -6.5744e-02],\n",
      "          [ 8.3570e-03,  8.3306e-03, -3.1694e-02],\n",
      "          [-1.6594e-02, -2.7705e-03, -8.8299e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.9315e-02,  1.2145e-02, -3.1176e-02],\n",
      "          [ 6.3027e-03, -7.1481e-04, -3.1927e-02],\n",
      "          [ 1.9364e-02,  4.2052e-03, -1.9566e-02]],\n",
      "\n",
      "         [[-1.9855e-02,  1.7430e-02,  2.4015e-02],\n",
      "          [ 2.1444e-02,  3.7237e-02,  1.4681e-02],\n",
      "          [ 1.5801e-02,  2.6180e-02, -1.6995e-02]],\n",
      "\n",
      "         [[ 4.5251e-02,  4.0553e-02, -7.1369e-03],\n",
      "          [ 3.3669e-02,  2.8528e-02,  2.5468e-02],\n",
      "          [ 8.5669e-04, -2.9174e-02, -1.8554e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4969e-02, -3.0427e-02, -9.2000e-03],\n",
      "          [ 1.9208e-02, -4.9419e-02, -3.1581e-02],\n",
      "          [ 3.0536e-02, -2.1661e-02, -2.9521e-02]],\n",
      "\n",
      "         [[ 4.3994e-02,  5.1959e-02,  3.9573e-02],\n",
      "          [ 1.3979e-02,  1.1414e-02,  3.1020e-03],\n",
      "          [ 3.2651e-04, -8.9496e-03, -7.7691e-03]],\n",
      "\n",
      "         [[ 1.4944e-02,  5.2261e-03, -1.3485e-02],\n",
      "          [ 3.2752e-02,  3.7579e-02,  2.5116e-02],\n",
      "          [ 2.9907e-02,  5.7022e-02,  3.0312e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9953e-02,  4.8833e-02,  5.2309e-02],\n",
      "          [ 3.7285e-02,  1.9263e-02, -2.6015e-03],\n",
      "          [ 2.8197e-02, -1.7366e-02, -1.4688e-02]],\n",
      "\n",
      "         [[ 4.1824e-02,  5.1154e-02, -8.5273e-03],\n",
      "          [ 3.7180e-02,  3.8831e-02,  3.7352e-03],\n",
      "          [ 7.8400e-03,  2.2572e-02, -2.8450e-02]],\n",
      "\n",
      "         [[-1.7513e-02,  1.5097e-02,  6.8811e-03],\n",
      "          [-1.1041e-02, -4.0475e-02, -1.7788e-02],\n",
      "          [-2.0693e-02, -5.6653e-03,  1.1377e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3747e-02,  9.7299e-03,  1.4505e-02],\n",
      "          [ 2.7115e-02,  2.3613e-02,  4.5637e-02],\n",
      "          [ 2.6436e-02,  5.4756e-02,  1.0891e-02]],\n",
      "\n",
      "         [[ 2.0090e-02,  1.5176e-02,  1.1319e-02],\n",
      "          [ 8.3680e-03, -1.9435e-02, -1.6546e-02],\n",
      "          [ 6.3271e-04, -2.2041e-02,  4.5867e-04]],\n",
      "\n",
      "         [[-5.0706e-03,  1.8152e-02, -9.4108e-03],\n",
      "          [ 4.8371e-02,  4.0391e-02,  2.3098e-02],\n",
      "          [-3.6311e-03, -1.9629e-02, -1.4882e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8183e-03, -3.6297e-02, -3.2657e-02],\n",
      "          [-2.4205e-02, -9.7398e-03,  3.2626e-02],\n",
      "          [-5.6366e-03, -4.0292e-03,  2.0640e-03]],\n",
      "\n",
      "         [[ 3.1122e-02,  4.8816e-03, -1.5482e-02],\n",
      "          [ 6.2455e-02,  5.1292e-02, -1.9035e-02],\n",
      "          [ 5.9365e-03,  3.6890e-02, -1.8871e-02]],\n",
      "\n",
      "         [[-2.6442e-02, -3.0729e-02, -4.8413e-02],\n",
      "          [ 1.6397e-02, -6.3393e-03, -9.1918e-03],\n",
      "          [ 2.1574e-03, -5.1694e-02, -2.1939e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9026e-03, -3.0305e-02, -1.5312e-02],\n",
      "          [-1.8327e-02,  1.9854e-03,  1.4306e-03],\n",
      "          [-3.1173e-02,  2.7919e-02,  3.5750e-02]],\n",
      "\n",
      "         [[ 2.5499e-02, -1.9174e-04,  1.8887e-03],\n",
      "          [ 2.0551e-02,  4.8186e-03, -2.3756e-02],\n",
      "          [ 1.6665e-03,  1.3548e-02, -7.0371e-03]],\n",
      "\n",
      "         [[-7.9219e-03, -9.3038e-03, -4.3883e-03],\n",
      "          [ 2.5065e-02,  4.2599e-02,  5.9507e-02],\n",
      "          [-3.5919e-02, -3.5388e-02, -1.7800e-02]]]], device='cuda:0')), ('features.10.bias', tensor([ 0.0202,  0.0338, -0.0698,  0.0923, -0.0507, -0.1150,  0.0449,  0.0521,\n",
      "        -0.0903,  0.0583, -0.0690,  0.1236,  0.0341,  0.3370,  0.0851,  0.2053,\n",
      "        -0.0117,  0.0298,  0.0317,  0.0693,  0.2639,  0.0290, -0.0116,  0.2532,\n",
      "        -0.0276, -0.0319,  0.1731,  0.1032, -0.0482, -0.0700,  0.1377,  0.1121,\n",
      "         0.1247, -0.1866,  0.0523,  0.0129, -0.0979,  0.0436, -0.0428, -0.0525,\n",
      "        -0.0452,  0.0206, -0.0350, -0.2777,  0.0497, -0.0120,  0.0802,  0.0229,\n",
      "        -0.0659, -0.0475,  0.0331,  0.0134,  0.0792, -0.1670, -0.0224,  0.2618,\n",
      "        -0.0800, -0.0817,  0.1192,  0.1644,  0.0690, -0.0693, -0.0453,  0.0007,\n",
      "         0.0384,  0.1381, -0.0329,  0.1217, -0.1571,  0.1048,  0.2537,  0.0729,\n",
      "         0.0065, -0.1082,  0.0637,  0.1831,  0.0179,  0.0243, -0.0031,  0.0226,\n",
      "         0.0155,  0.1098, -0.0128,  0.0941, -0.0131, -0.0109,  0.1651,  0.0746,\n",
      "        -0.0199,  0.1716,  0.1827,  0.0386, -0.0462,  0.0753, -0.0519,  0.0758,\n",
      "        -0.0737,  0.1672, -0.0833,  0.0866,  0.0048,  0.1771,  0.0611,  0.0143,\n",
      "        -0.0191, -0.0037, -0.0503,  0.0224,  0.0290, -0.0603,  0.0606,  0.0479,\n",
      "         0.0623,  0.0467,  0.0509,  0.0057, -0.1018,  0.3235,  0.0255, -0.0259,\n",
      "         0.0334,  0.0222,  0.0960, -0.0305,  0.1143,  0.0661, -0.0127, -0.1167,\n",
      "        -0.1040, -0.0135, -0.0364, -0.0290, -0.0250,  0.1876, -0.0326,  0.0989,\n",
      "         0.0342, -0.0897,  0.0944,  0.1789, -0.0282,  0.1338,  0.0010, -0.1821,\n",
      "        -0.0319, -0.0067, -0.0338,  0.0077, -0.0149,  0.0979,  0.1016,  0.2405,\n",
      "         0.0388,  0.0089, -0.0198,  0.0120,  0.1005, -0.0686, -0.1431, -0.0015,\n",
      "         0.0348,  0.0225, -0.0254, -0.0148, -0.1054,  0.0236, -0.0599,  0.0279,\n",
      "        -0.0951, -0.0027, -0.0068,  0.0917,  0.0216,  0.0261,  0.1450, -0.0396,\n",
      "        -0.0315, -0.1445,  0.0360,  0.0219,  0.1183,  0.0352, -0.0246,  0.0475,\n",
      "         0.1258, -0.1394,  0.0567,  0.0946,  0.0147,  0.1129,  0.0779,  0.0804,\n",
      "         0.0271, -0.0323, -0.0129, -0.0387, -0.0446,  0.1217,  0.0598,  0.0433,\n",
      "        -0.1319,  0.1268, -0.1234,  0.0316, -0.0856,  0.1249,  0.0661,  0.0018,\n",
      "        -0.0216, -0.0617,  0.2800, -0.0765,  0.1273, -0.0189,  0.0966, -0.1477,\n",
      "        -0.0838,  0.1879,  0.0175,  0.0795, -0.1509,  0.0410, -0.0384,  0.1817,\n",
      "        -0.0146, -0.0034, -0.1029,  0.0061, -0.0540,  0.0698, -0.0075,  0.0486,\n",
      "         0.0549,  0.1806,  0.0658,  0.0229,  0.0516, -0.0191, -0.0434,  0.0674,\n",
      "        -0.0060, -0.0954, -0.0659,  0.1381, -0.0737, -0.0144, -0.0212, -0.1298,\n",
      "        -0.0794,  0.1023, -0.0754, -0.1380, -0.0433,  0.0886,  0.1197,  0.1059],\n",
      "       device='cuda:0')), ('features.12.weight', tensor([[[[ 1.4458e-02,  5.4262e-02,  2.5967e-02],\n",
      "          [-1.6342e-02,  1.6133e-02,  3.6962e-03],\n",
      "          [-8.6773e-02, -4.2430e-02, -2.7797e-02]],\n",
      "\n",
      "         [[ 8.4293e-03, -1.0796e-03,  5.8639e-03],\n",
      "          [ 5.3881e-03, -3.8932e-03,  2.0397e-02],\n",
      "          [-2.7216e-02, -1.7411e-03, -2.5664e-03]],\n",
      "\n",
      "         [[-6.0055e-02,  2.7928e-02,  5.7307e-02],\n",
      "          [-7.8412e-02,  1.0588e-03, -2.2218e-02],\n",
      "          [-2.0841e-02,  5.3504e-02,  9.2433e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4644e-03,  9.6476e-03,  1.4500e-02],\n",
      "          [ 7.9505e-04,  7.9915e-03,  5.1864e-03],\n",
      "          [-9.7005e-03, -1.4069e-02, -8.9335e-03]],\n",
      "\n",
      "         [[ 1.5228e-02, -3.4120e-02, -5.4391e-02],\n",
      "          [-8.1824e-03, -7.1585e-03, -3.7906e-02],\n",
      "          [-1.5072e-02,  6.2816e-02, -4.9534e-03]],\n",
      "\n",
      "         [[ 1.1094e-02,  7.8073e-02,  2.7350e-02],\n",
      "          [-2.2723e-02,  4.1529e-02, -1.9598e-02],\n",
      "          [-1.6419e-02, -1.6679e-02, -9.1728e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5749e-02,  2.4898e-02,  1.9001e-02],\n",
      "          [ 8.7312e-04,  1.9976e-02,  2.9733e-02],\n",
      "          [ 3.0736e-03,  4.2173e-03,  7.2681e-03]],\n",
      "\n",
      "         [[ 4.7883e-02,  6.1909e-02,  9.2755e-02],\n",
      "          [-9.3805e-03, -1.6869e-02,  2.8851e-02],\n",
      "          [ 9.3722e-03, -3.0548e-02, -1.6118e-02]],\n",
      "\n",
      "         [[ 1.1930e-02, -7.6034e-03,  1.3502e-02],\n",
      "          [ 1.8976e-02,  8.4897e-03,  9.9239e-03],\n",
      "          [ 2.7998e-02,  3.3866e-03,  3.0706e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1611e-02,  1.3576e-02, -2.2638e-03],\n",
      "          [ 3.1981e-04,  5.5566e-03,  1.4303e-03],\n",
      "          [-1.3221e-03, -2.6181e-03,  1.6269e-02]],\n",
      "\n",
      "         [[ 9.1360e-03, -1.3612e-02,  1.0803e-02],\n",
      "          [-1.7446e-02, -2.3003e-02,  6.0578e-03],\n",
      "          [-1.7264e-02, -5.3412e-03,  1.1269e-03]],\n",
      "\n",
      "         [[-1.2673e-02,  1.9370e-02,  2.2894e-03],\n",
      "          [ 4.0198e-03,  1.6175e-03,  1.0278e-02],\n",
      "          [-2.4483e-02, -2.5677e-02, -7.6767e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.9262e-03, -5.6233e-03, -3.5152e-03],\n",
      "          [-6.5375e-03, -1.4448e-02, -9.9792e-03],\n",
      "          [-2.5880e-02, -1.3281e-02, -1.9598e-02]],\n",
      "\n",
      "         [[-8.5774e-03, -2.0572e-02, -1.4821e-02],\n",
      "          [ 1.8767e-02, -1.2778e-02, -1.5670e-02],\n",
      "          [ 1.3260e-02, -3.0004e-03, -1.8270e-02]],\n",
      "\n",
      "         [[ 1.7317e-02,  1.0014e-02,  1.5421e-02],\n",
      "          [ 1.6499e-02, -1.4778e-02,  1.2397e-02],\n",
      "          [-1.6704e-02, -2.5014e-02,  1.4771e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0394e-03,  1.2566e-02,  1.5867e-02],\n",
      "          [ 9.8934e-03,  2.9302e-02,  4.7297e-03],\n",
      "          [ 1.1337e-02, -1.9948e-03,  1.0692e-02]],\n",
      "\n",
      "         [[ 3.4212e-03,  5.1473e-03, -1.4110e-02],\n",
      "          [ 5.1296e-03, -1.3783e-02, -2.9022e-02],\n",
      "          [-5.5250e-03,  6.1991e-03,  7.0356e-03]],\n",
      "\n",
      "         [[ 3.5273e-03, -8.8340e-03, -2.1254e-02],\n",
      "          [ 1.5234e-02, -8.9212e-03,  1.2711e-02],\n",
      "          [-3.2081e-03, -2.3476e-02, -8.4571e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.8562e-02, -7.5180e-03,  1.4599e-02],\n",
      "          [-2.0243e-02, -2.9485e-02,  5.4713e-05],\n",
      "          [-2.6308e-03, -2.8685e-02, -1.9327e-02]],\n",
      "\n",
      "         [[ 7.3137e-03, -6.8900e-03,  1.6473e-03],\n",
      "          [ 2.3934e-02,  1.7293e-02,  1.8168e-02],\n",
      "          [ 3.2893e-02,  3.2778e-02,  4.1614e-02]],\n",
      "\n",
      "         [[ 1.5314e-03, -4.7585e-02,  3.9553e-02],\n",
      "          [-2.2300e-02, -5.7313e-02,  2.5074e-02],\n",
      "          [-4.3050e-02, -1.2614e-02,  2.3613e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.4826e-03,  4.6901e-03,  2.3574e-02],\n",
      "          [-7.8160e-03, -1.0316e-02,  3.5899e-02],\n",
      "          [ 2.1178e-02,  5.7244e-03, -1.8567e-03]],\n",
      "\n",
      "         [[-5.9718e-04,  2.6017e-03,  3.9694e-02],\n",
      "          [-3.0896e-03,  2.2937e-02,  3.3988e-02],\n",
      "          [-3.9173e-02, -4.4933e-03,  9.7815e-03]],\n",
      "\n",
      "         [[-4.7458e-02,  9.8044e-02,  2.5373e-02],\n",
      "          [-6.1261e-02,  4.3155e-02,  1.6545e-02],\n",
      "          [-5.1283e-02, -3.7696e-02, -4.9548e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.3331e-02, -8.1990e-03, -5.3522e-02],\n",
      "          [-2.2125e-02,  1.1858e-02, -3.4055e-02],\n",
      "          [-3.6413e-02, -1.7979e-02, -4.2806e-02]],\n",
      "\n",
      "         [[-2.5023e-03,  1.1622e-03, -4.5095e-03],\n",
      "          [-1.5937e-02,  1.3033e-03, -1.4039e-03],\n",
      "          [ 8.4911e-03,  1.6547e-02,  1.6302e-02]],\n",
      "\n",
      "         [[ 3.4255e-02,  1.4493e-03, -2.0719e-02],\n",
      "          [ 2.3174e-02, -2.6618e-02, -1.8910e-02],\n",
      "          [ 8.0609e-03, -1.6315e-02,  1.3355e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6971e-02,  3.6007e-03, -4.9184e-03],\n",
      "          [ 3.3523e-03,  1.8616e-02, -1.2742e-02],\n",
      "          [-2.6226e-03,  1.0755e-02, -2.8754e-03]],\n",
      "\n",
      "         [[-4.1152e-02, -1.6278e-02,  3.4659e-02],\n",
      "          [ 1.4860e-02,  2.6478e-02,  6.8205e-02],\n",
      "          [ 1.4101e-02,  4.9415e-02,  6.2358e-02]],\n",
      "\n",
      "         [[-3.2522e-02,  8.4283e-03, -3.2296e-02],\n",
      "          [-2.6740e-02,  6.3519e-02,  7.2680e-03],\n",
      "          [-8.6290e-03,  5.3084e-02,  2.2354e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.8128e-02,  4.9794e-03, -2.7731e-02],\n",
      "          [-5.2834e-02, -1.6674e-02, -4.8823e-02],\n",
      "          [-4.3085e-02, -4.8342e-03, -2.1020e-02]],\n",
      "\n",
      "         [[-1.8078e-02,  7.5349e-03,  2.1894e-02],\n",
      "          [ 2.0570e-03,  2.1014e-02,  2.7317e-02],\n",
      "          [-4.4044e-03, -5.6735e-03, -1.1678e-02]],\n",
      "\n",
      "         [[-3.9333e-03,  1.5431e-02,  3.1095e-03],\n",
      "          [-3.4266e-02, -8.0041e-03, -4.0737e-02],\n",
      "          [-1.0373e-02, -1.3137e-02, -2.5135e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1422e-02, -1.1068e-02, -2.6556e-02],\n",
      "          [ 5.5402e-04, -1.1401e-02, -2.5478e-02],\n",
      "          [-1.0598e-02,  1.1776e-02,  2.3815e-02]],\n",
      "\n",
      "         [[-2.0722e-02, -2.0430e-02, -1.3406e-02],\n",
      "          [-2.9648e-02, -2.0838e-02, -3.3982e-02],\n",
      "          [-2.5423e-02, -5.0160e-03, -1.6819e-02]],\n",
      "\n",
      "         [[-2.8305e-02, -3.1576e-02, -4.5957e-02],\n",
      "          [-2.3097e-02, -1.5578e-02, -2.3184e-02],\n",
      "          [-2.1999e-02,  3.7065e-03,  2.3179e-03]]]], device='cuda:0')), ('features.12.bias', tensor([ 0.0081,  0.0008,  0.0921,  0.0401, -0.0459,  0.0429,  0.0023,  0.0654,\n",
      "         0.0898,  0.0891,  0.0697,  0.2036, -0.1984, -0.0156, -0.0234, -0.0090,\n",
      "        -0.0117,  0.0390, -0.0326,  0.2342,  0.1007,  0.0658,  0.0196,  0.1381,\n",
      "        -0.1318,  0.0273,  0.2149,  0.0126,  0.0744,  0.1737, -0.1128,  0.1259,\n",
      "         0.0321,  0.1362,  0.0060,  0.0778,  0.1610,  0.2223,  0.1665, -0.0132,\n",
      "        -0.0238,  0.1425,  0.1552,  0.0869,  0.1412, -0.0429,  0.0677,  0.0206,\n",
      "         0.1080,  0.2640,  0.1063, -0.0261, -0.0140,  0.1273,  0.0410, -0.1462,\n",
      "        -0.0257,  0.0140,  0.0486, -0.0092,  0.0228,  0.0428,  0.0226,  0.0066,\n",
      "         0.0014,  0.1270,  0.0320,  0.0989, -0.0172,  0.1474,  0.0830,  0.1477,\n",
      "         0.2371,  0.0403, -0.0558,  0.0189,  0.0474, -0.0311,  0.0552,  0.0268,\n",
      "         0.0219, -0.1241, -0.0402,  0.0836,  0.0670,  0.0083,  0.0702,  0.1147,\n",
      "         0.1347, -0.0128,  0.2890,  0.1577, -0.1817, -0.0160, -0.0036,  0.0874,\n",
      "         0.0404,  0.0438,  0.0861,  0.1154,  0.1607, -0.0231,  0.1155, -0.0018,\n",
      "         0.0136,  0.0950,  0.0477, -0.0988,  0.0616,  0.0948, -0.0689, -0.0102,\n",
      "         0.1182, -0.1292,  0.0223,  0.0818,  0.0722,  0.0156,  0.1165, -0.0359,\n",
      "         0.0751,  0.0290,  0.0286, -0.0560,  0.1883,  0.0147,  0.1054,  0.1067,\n",
      "        -0.1083,  0.0514,  0.1042,  0.0518,  0.1017,  0.1114,  0.0223, -0.0822,\n",
      "        -0.0090,  0.0857,  0.0251, -0.0731,  0.1057,  0.1295,  0.0430,  0.0721,\n",
      "         0.0236,  0.0671,  0.0714,  0.0003,  0.0366, -0.0715,  0.0393,  0.0395,\n",
      "        -0.0209,  0.0509, -0.0400,  0.0318,  0.0060, -0.0212, -0.0153,  0.1134,\n",
      "         0.0069,  0.0592, -0.0839, -0.0743, -0.1683, -0.0244,  0.1875,  0.0369,\n",
      "         0.1861,  0.0996,  0.0322,  0.0711,  0.0483,  0.1173,  0.0322,  0.0079,\n",
      "        -0.0453,  0.0019,  0.0067,  0.1854,  0.0722,  0.0462,  0.0480,  0.0030,\n",
      "         0.1393,  0.0149, -0.0285,  0.0869,  0.0425, -0.0315,  0.0561,  0.1013,\n",
      "         0.0567,  0.1636, -0.0591,  0.1075, -0.0456,  0.0341, -0.0290,  0.1095,\n",
      "         0.1375, -0.0356,  0.0761,  0.0288,  0.0551,  0.1078, -0.0363,  0.2171,\n",
      "         0.0526,  0.0696, -0.1063,  0.1262,  0.0418,  0.0290,  0.0689,  0.1373,\n",
      "        -0.0678,  0.1006, -0.0019, -0.0919,  0.1378, -0.0968,  0.0735,  0.0374,\n",
      "         0.0339, -0.0866,  0.0631,  0.0561,  0.0815,  0.0047, -0.0130,  0.0500,\n",
      "        -0.1108,  0.0169,  0.1148,  0.0299,  0.0398,  0.1097,  0.0245,  0.0545,\n",
      "        -0.1936,  0.1633,  0.0391, -0.0328,  0.1820,  0.0246,  0.0244,  0.0986,\n",
      "        -0.0062,  0.0407, -0.0133,  0.0259,  0.1405,  0.0653, -0.0096,  0.0564],\n",
      "       device='cuda:0')), ('features.14.weight', tensor([[[[-0.0155,  0.0034, -0.0208],\n",
      "          [-0.0154,  0.0106, -0.0012],\n",
      "          [-0.0046,  0.0178, -0.0036]],\n",
      "\n",
      "         [[-0.0206,  0.0066, -0.0181],\n",
      "          [ 0.0116, -0.0038, -0.0226],\n",
      "          [ 0.0356, -0.0056, -0.0036]],\n",
      "\n",
      "         [[ 0.0001, -0.0145,  0.0259],\n",
      "          [ 0.0346,  0.0227,  0.0142],\n",
      "          [ 0.0486,  0.0350,  0.0236]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0004, -0.0091, -0.0099],\n",
      "          [-0.0138,  0.0159,  0.0132],\n",
      "          [-0.0383,  0.0032,  0.0217]],\n",
      "\n",
      "         [[-0.0250, -0.0385, -0.0223],\n",
      "          [-0.0498, -0.0494, -0.0421],\n",
      "          [-0.0433, -0.0373, -0.0203]],\n",
      "\n",
      "         [[ 0.0202,  0.0256,  0.0071],\n",
      "          [ 0.0002,  0.0084,  0.0243],\n",
      "          [ 0.0096,  0.0068,  0.0299]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0035, -0.0297, -0.0180],\n",
      "          [-0.0055, -0.0111, -0.0139],\n",
      "          [-0.0057, -0.0050,  0.0180]],\n",
      "\n",
      "         [[ 0.0206,  0.0164,  0.0047],\n",
      "          [ 0.0073, -0.0121, -0.0166],\n",
      "          [-0.0284, -0.0446, -0.0417]],\n",
      "\n",
      "         [[-0.0103, -0.0127, -0.0456],\n",
      "          [ 0.0228,  0.0107, -0.0024],\n",
      "          [ 0.0432,  0.0437,  0.0045]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0064,  0.0149,  0.0153],\n",
      "          [-0.0197, -0.0077, -0.0082],\n",
      "          [-0.0431, -0.0514, -0.0533]],\n",
      "\n",
      "         [[-0.0083, -0.0209, -0.0198],\n",
      "          [-0.0117, -0.0369, -0.0420],\n",
      "          [ 0.0041, -0.0264, -0.0139]],\n",
      "\n",
      "         [[ 0.0012, -0.0141,  0.0099],\n",
      "          [-0.0099,  0.0026,  0.0137],\n",
      "          [-0.0091, -0.0219, -0.0225]]],\n",
      "\n",
      "\n",
      "        [[[-0.0026, -0.0110, -0.0143],\n",
      "          [-0.0088,  0.0134, -0.0115],\n",
      "          [-0.0059,  0.0095, -0.0092]],\n",
      "\n",
      "         [[ 0.0043,  0.0160,  0.0076],\n",
      "          [ 0.0087, -0.0036, -0.0117],\n",
      "          [-0.0139, -0.0317, -0.0239]],\n",
      "\n",
      "         [[-0.0228, -0.0144,  0.0040],\n",
      "          [-0.0152,  0.0229,  0.0016],\n",
      "          [ 0.0171,  0.0368,  0.0052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0307, -0.0318,  0.0092],\n",
      "          [-0.0025, -0.0352,  0.0248],\n",
      "          [-0.0022, -0.0496,  0.0067]],\n",
      "\n",
      "         [[-0.0238, -0.0304, -0.0117],\n",
      "          [-0.0160, -0.0534, -0.0285],\n",
      "          [-0.0202, -0.0389, -0.0290]],\n",
      "\n",
      "         [[ 0.0012,  0.0030, -0.0082],\n",
      "          [ 0.0119,  0.0235, -0.0012],\n",
      "          [ 0.0316,  0.0985,  0.0112]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0140, -0.0101, -0.0068],\n",
      "          [-0.0203, -0.0128, -0.0156],\n",
      "          [ 0.0132,  0.0380,  0.0003]],\n",
      "\n",
      "         [[ 0.0400,  0.0588,  0.0293],\n",
      "          [-0.0021, -0.0102,  0.0251],\n",
      "          [ 0.0239,  0.0076,  0.0139]],\n",
      "\n",
      "         [[-0.0110, -0.0177, -0.0225],\n",
      "          [ 0.0084, -0.0072, -0.0040],\n",
      "          [ 0.0245,  0.0288,  0.0386]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0257,  0.0162,  0.0248],\n",
      "          [-0.0309, -0.0531, -0.0038],\n",
      "          [ 0.0115, -0.0205, -0.0375]],\n",
      "\n",
      "         [[-0.0366, -0.0466, -0.0149],\n",
      "          [-0.0095, -0.0091,  0.0004],\n",
      "          [ 0.0051,  0.0243,  0.0338]],\n",
      "\n",
      "         [[-0.0167, -0.0234,  0.0059],\n",
      "          [-0.0096, -0.0118, -0.0073],\n",
      "          [ 0.0377,  0.0049,  0.0104]]],\n",
      "\n",
      "\n",
      "        [[[-0.0026,  0.0093, -0.0170],\n",
      "          [ 0.0186,  0.0128, -0.0145],\n",
      "          [ 0.0127,  0.0089, -0.0180]],\n",
      "\n",
      "         [[-0.0024, -0.0154,  0.0187],\n",
      "          [ 0.0314,  0.0011,  0.0186],\n",
      "          [ 0.0314,  0.0315,  0.0257]],\n",
      "\n",
      "         [[ 0.0145, -0.0050, -0.0023],\n",
      "          [ 0.0153,  0.0001,  0.0007],\n",
      "          [ 0.0055, -0.0118,  0.0134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0206,  0.0158, -0.0130],\n",
      "          [-0.0167,  0.0069, -0.0166],\n",
      "          [-0.0069,  0.0104, -0.0177]],\n",
      "\n",
      "         [[ 0.0131, -0.0182, -0.0116],\n",
      "          [ 0.0130, -0.0077, -0.0058],\n",
      "          [ 0.0296, -0.0123,  0.0070]],\n",
      "\n",
      "         [[-0.0069, -0.0300, -0.0034],\n",
      "          [-0.0463, -0.0545,  0.0007],\n",
      "          [-0.0487, -0.0396,  0.0036]]],\n",
      "\n",
      "\n",
      "        [[[-0.0162, -0.0564, -0.0175],\n",
      "          [-0.0174, -0.0550, -0.0238],\n",
      "          [ 0.0310,  0.0137, -0.0105]],\n",
      "\n",
      "         [[ 0.0491,  0.0133,  0.0053],\n",
      "          [ 0.0197,  0.0342,  0.0044],\n",
      "          [ 0.0079,  0.0057,  0.0301]],\n",
      "\n",
      "         [[ 0.0128,  0.0056,  0.0155],\n",
      "          [ 0.0344, -0.0082, -0.0097],\n",
      "          [ 0.0366,  0.0003, -0.0246]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0080,  0.0117,  0.0118],\n",
      "          [-0.0008,  0.0092,  0.0115],\n",
      "          [-0.0109,  0.0008, -0.0158]],\n",
      "\n",
      "         [[-0.0206, -0.0768, -0.0746],\n",
      "          [-0.0025, -0.0355, -0.0422],\n",
      "          [ 0.0171, -0.0114, -0.0314]],\n",
      "\n",
      "         [[-0.0121, -0.0113,  0.0153],\n",
      "          [-0.0141, -0.0066,  0.0138],\n",
      "          [-0.0083, -0.0219, -0.0005]]]], device='cuda:0')), ('features.14.bias', tensor([ 0.1527,  0.0026,  0.0118,  0.0612,  0.0751,  0.0336,  0.0359,  0.1965,\n",
      "        -0.0776, -0.0464,  0.0143, -0.0799, -0.1670, -0.0019,  0.2606,  0.1202,\n",
      "        -0.0356, -0.0970,  0.1096,  0.3574, -0.1109, -0.1799,  0.0262,  0.0853,\n",
      "         0.0695,  0.1890,  0.0186, -0.0910, -0.0431, -0.1330,  0.0615, -0.0163,\n",
      "         0.0268,  0.0015,  0.0059,  0.3832, -0.0661, -0.0292,  0.1524,  0.0463,\n",
      "         0.0012, -0.0849,  0.0185,  0.1371,  0.0122, -0.0279,  0.0299,  0.2400,\n",
      "         0.0575,  0.0058, -0.0423, -0.0749,  0.0616,  0.0374, -0.0554,  0.2787,\n",
      "        -0.0078,  0.0378,  0.0448,  0.0146,  0.1976, -0.0101,  0.1134, -0.0527,\n",
      "         0.0147,  0.0263,  0.0608,  0.1433, -0.1462,  0.0421,  0.1858,  0.0425,\n",
      "        -0.0079,  0.1064,  0.0585,  0.0768, -0.0239, -0.0044, -0.0805, -0.0221,\n",
      "         0.1140, -0.0683, -0.0827, -0.0357, -0.0555,  0.3748,  0.0047,  0.4622,\n",
      "        -0.1137,  0.0499, -0.0782, -0.0067, -0.1540,  0.0021,  0.0214,  0.2276,\n",
      "        -0.0322, -0.1061,  0.0281,  0.0258,  0.0006,  0.0171, -0.0165, -0.0237,\n",
      "         0.0153, -0.1518,  0.0878, -0.0198, -0.0478,  0.0325, -0.0095, -0.0673,\n",
      "         0.0015, -0.0601, -0.0157,  0.0288,  0.3301, -0.0207,  0.1275,  0.0270,\n",
      "         0.1409, -0.0736, -0.0761,  0.0053, -0.1070,  0.0598, -0.0250,  0.3023,\n",
      "        -0.0699,  0.0256,  0.1078, -0.0116, -0.0383, -0.0591, -0.1085,  0.0720,\n",
      "        -0.0430,  0.2818,  0.0155, -0.0255, -0.0499,  0.0225,  0.0256,  0.1965,\n",
      "         0.0169, -0.0636, -0.0493,  0.2131,  0.0348,  0.0979,  0.0510, -0.0073,\n",
      "        -0.0826, -0.0063, -0.0395,  0.0054,  0.1830,  0.0029,  0.0332,  0.2406,\n",
      "         0.0567,  0.0066, -0.1359, -0.0163,  0.1877, -0.0564, -0.1024, -0.0884,\n",
      "         0.0464,  0.1190, -0.1196,  0.0211, -0.0810,  0.0997, -0.1556, -0.0740,\n",
      "        -0.0100, -0.0201,  0.0839, -0.0453,  0.0081,  0.0599, -0.0338,  0.2230,\n",
      "        -0.1076,  0.0043,  0.0065, -0.0494, -0.0767,  0.0475, -0.0149,  0.2279,\n",
      "        -0.0490, -0.0124, -0.0288, -0.0238,  0.0233, -0.0998,  0.0037,  0.3284,\n",
      "        -0.0424,  0.3322,  0.0159, -0.0710,  0.0465,  0.0838,  0.0332,  0.1902,\n",
      "         0.0334, -0.0613,  0.1509,  0.0363,  0.1291, -0.1115, -0.0433,  0.0450,\n",
      "        -0.0986,  0.0771,  0.0814,  0.0824, -0.0308, -0.0128, -0.0068, -0.0059,\n",
      "        -0.0202,  0.0106, -0.1317,  0.1157, -0.1242, -0.0816, -0.0769, -0.0481,\n",
      "         0.0572,  0.1796, -0.0352, -0.0285,  0.0144,  0.1194, -0.0091,  0.1399,\n",
      "        -0.0381,  0.0255, -0.0679,  0.0725,  0.0707,  0.0324,  0.0248, -0.0288,\n",
      "        -0.0367,  0.1565,  0.0469, -0.0201, -0.0677, -0.0388, -0.1451, -0.1943],\n",
      "       device='cuda:0')), ('features.17.weight', tensor([[[[-7.0407e-03, -1.2371e-02,  2.2388e-03],\n",
      "          [-3.4945e-04,  8.3066e-03, -3.3719e-03],\n",
      "          [ 1.4878e-03,  1.1629e-02,  1.7914e-02]],\n",
      "\n",
      "         [[ 1.7044e-02,  1.3268e-02,  1.6129e-02],\n",
      "          [-9.7721e-04, -1.2761e-03,  5.3491e-03],\n",
      "          [-4.9739e-03,  6.8304e-03, -1.4400e-02]],\n",
      "\n",
      "         [[-1.3706e-02, -1.5852e-02, -7.2444e-03],\n",
      "          [ 1.1695e-02,  7.9012e-03,  3.7443e-03],\n",
      "          [ 3.4724e-03,  1.2283e-02,  1.2933e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5974e-02,  6.9182e-02,  6.9327e-02],\n",
      "          [ 4.5527e-02, -1.3160e-03,  6.0608e-02],\n",
      "          [ 7.0592e-02,  5.3374e-02,  2.0030e-02]],\n",
      "\n",
      "         [[ 1.4789e-02, -1.7400e-02, -2.3320e-02],\n",
      "          [ 1.1156e-02,  1.5264e-02, -9.4171e-03],\n",
      "          [ 2.1255e-02,  1.4230e-02, -1.3540e-02]],\n",
      "\n",
      "         [[-2.0577e-02, -9.5674e-03,  6.9175e-03],\n",
      "          [-7.2709e-03, -1.7179e-02,  2.0196e-02],\n",
      "          [ 1.7350e-02,  5.2181e-03, -1.2872e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0917e-02, -1.6156e-02, -4.3484e-03],\n",
      "          [-2.5008e-02, -4.2966e-02, -3.0563e-02],\n",
      "          [-2.6327e-02, -2.4413e-02, -8.5690e-03]],\n",
      "\n",
      "         [[-3.7772e-02, -1.2624e-02, -2.0013e-02],\n",
      "          [-3.3966e-02, -1.6831e-02, -1.0124e-02],\n",
      "          [-1.8217e-02, -1.5020e-02,  1.3080e-03]],\n",
      "\n",
      "         [[ 1.2184e-02, -1.2087e-02,  1.7991e-02],\n",
      "          [ 5.2722e-02,  8.0374e-03,  2.2514e-02],\n",
      "          [ 5.8993e-02,  3.2782e-02,  2.1087e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8349e-03, -4.7245e-03,  2.4834e-02],\n",
      "          [-7.2375e-03, -1.1020e-02,  1.7923e-02],\n",
      "          [ 2.6053e-02, -1.8564e-02, -2.8714e-03]],\n",
      "\n",
      "         [[ 1.6234e-02, -3.4470e-02, -1.4160e-02],\n",
      "          [ 2.6344e-03, -3.5605e-02, -4.0918e-02],\n",
      "          [ 3.2230e-03, -1.3359e-02, -1.6670e-02]],\n",
      "\n",
      "         [[-2.8010e-02, -1.8247e-02, -1.0266e-02],\n",
      "          [-2.4739e-02, -4.9246e-02, -2.1506e-02],\n",
      "          [-3.2995e-02, -3.5000e-02, -2.9097e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9750e-03,  2.6729e-02,  3.2822e-02],\n",
      "          [ 3.6466e-03, -1.7902e-02, -4.3422e-03],\n",
      "          [-8.5616e-03, -1.7390e-02, -6.4783e-03]],\n",
      "\n",
      "         [[-2.4613e-02, -1.8950e-02, -2.5066e-02],\n",
      "          [-1.7697e-02, -9.3534e-03, -6.0126e-03],\n",
      "          [ 9.1716e-03, -2.1026e-03,  8.8393e-03]],\n",
      "\n",
      "         [[-8.2647e-03, -1.0965e-02,  1.1624e-02],\n",
      "          [ 1.5643e-02, -1.4625e-02,  3.9084e-03],\n",
      "          [ 3.4610e-02, -3.9968e-03,  1.7886e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8449e-02, -2.2875e-02, -3.0008e-02],\n",
      "          [-3.7424e-02, -4.2076e-02, -5.0794e-02],\n",
      "          [-1.4039e-02,  4.4702e-02,  7.4715e-02]],\n",
      "\n",
      "         [[ 3.3004e-03,  7.3116e-03,  3.0886e-03],\n",
      "          [-4.4847e-02, -5.6967e-03, -1.3882e-02],\n",
      "          [-2.5696e-02, -2.6993e-02,  6.3057e-03]],\n",
      "\n",
      "         [[ 1.8556e-03, -1.5118e-02,  2.4970e-03],\n",
      "          [ 4.8854e-02,  2.7233e-02, -2.2185e-02],\n",
      "          [ 1.1909e-02,  5.5265e-03, -2.7282e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.5810e-03, -9.0366e-03,  1.4369e-03],\n",
      "          [-4.1151e-03, -5.4969e-03,  1.4365e-02],\n",
      "          [-1.1409e-03,  2.9281e-03,  4.0953e-03]],\n",
      "\n",
      "         [[-4.2916e-02, -3.9380e-02, -1.5347e-02],\n",
      "          [-3.2325e-02, -1.0138e-02, -8.9602e-03],\n",
      "          [-6.7189e-03,  9.2747e-03,  3.9578e-03]],\n",
      "\n",
      "         [[ 6.2547e-03,  2.0394e-02,  3.2767e-02],\n",
      "          [-9.7907e-03, -4.7231e-03,  3.3003e-02],\n",
      "          [-7.1901e-03, -9.9433e-03, -3.3229e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7658e-02,  4.6615e-02,  9.7046e-03],\n",
      "          [ 2.7706e-03,  1.7994e-03, -3.2915e-03],\n",
      "          [-3.6330e-05,  1.3310e-02, -3.9286e-03]],\n",
      "\n",
      "         [[-6.9039e-03,  6.3574e-03,  1.6824e-02],\n",
      "          [-2.9717e-02, -2.2547e-02,  7.5127e-03],\n",
      "          [ 1.7091e-03, -2.6405e-02, -7.0685e-03]],\n",
      "\n",
      "         [[ 7.4595e-03,  1.0742e-02, -3.1499e-04],\n",
      "          [-6.9448e-03, -2.4510e-02, -2.4144e-02],\n",
      "          [-3.1542e-02, -1.5262e-02, -1.4584e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9512e-02,  2.3043e-02,  2.2162e-02],\n",
      "          [-1.2518e-03, -3.5788e-03,  6.6051e-03],\n",
      "          [ 1.4536e-02,  1.2092e-02,  1.0204e-02]],\n",
      "\n",
      "         [[-5.4716e-05, -9.5875e-03,  1.0365e-02],\n",
      "          [-8.1047e-03, -2.0313e-02, -4.4185e-03],\n",
      "          [ 1.3795e-02,  1.4303e-03,  1.5385e-02]],\n",
      "\n",
      "         [[ 2.8190e-03, -1.0707e-02, -1.1369e-03],\n",
      "          [-2.1748e-03, -2.2595e-02, -1.0350e-02],\n",
      "          [-2.2768e-02, -1.3309e-02, -9.0804e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8838e-02,  2.8987e-02,  1.6121e-02],\n",
      "          [ 1.1093e-02, -2.4850e-02, -2.4911e-02],\n",
      "          [ 5.4552e-03, -4.9657e-03, -1.5505e-02]],\n",
      "\n",
      "         [[ 5.5599e-03, -3.9190e-02, -2.5970e-02],\n",
      "          [-1.9628e-02, -4.3369e-02, -1.1961e-02],\n",
      "          [-1.9965e-02, -3.1207e-02,  4.5270e-04]],\n",
      "\n",
      "         [[ 1.1173e-02,  8.0449e-04,  9.5013e-03],\n",
      "          [-1.9043e-02, -2.9472e-02, -1.4361e-02],\n",
      "          [-3.0420e-02, -1.2566e-02, -1.6186e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5104e-03, -3.1250e-03, -1.4089e-02],\n",
      "          [-2.5407e-03,  4.5601e-03, -3.2633e-02],\n",
      "          [ 9.2935e-03, -2.8452e-03,  1.9294e-03]],\n",
      "\n",
      "         [[-1.2509e-02, -1.7259e-02,  1.3495e-03],\n",
      "          [ 5.4679e-03, -5.5054e-03,  2.3635e-02],\n",
      "          [ 5.8567e-03,  1.2592e-02,  2.7611e-02]],\n",
      "\n",
      "         [[-1.3583e-02, -4.1725e-02, -3.4188e-02],\n",
      "          [-1.9751e-02, -3.7626e-02, -2.4501e-02],\n",
      "          [-5.7688e-03, -2.1353e-02, -4.6215e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1298e-02, -5.5083e-03, -1.7650e-02],\n",
      "          [-7.7781e-03, -3.0555e-02, -2.7287e-02],\n",
      "          [-2.6451e-02, -4.3400e-02, -2.3002e-02]],\n",
      "\n",
      "         [[-2.6287e-03, -1.7704e-02, -2.6902e-02],\n",
      "          [-4.5120e-03, -4.0293e-02, -2.8228e-02],\n",
      "          [-1.3612e-02, -2.6651e-02, -7.3693e-03]],\n",
      "\n",
      "         [[-9.8540e-03, -1.2848e-02, -8.3328e-04],\n",
      "          [-1.2088e-02, -1.4440e-02,  1.5528e-02],\n",
      "          [-2.7315e-02,  5.2576e-03,  2.6680e-02]]]], device='cuda:0')), ('features.17.bias', tensor([ 6.2630e-02, -6.2566e-03, -9.5154e-02,  6.4328e-02,  5.0604e-02,\n",
      "         1.8327e-01,  1.2081e-01,  3.9497e-02,  1.2995e-01, -1.3335e-01,\n",
      "         2.9477e-01,  1.0096e-02, -2.2026e-02, -2.4025e-02, -8.8757e-02,\n",
      "        -1.2469e-01, -2.6338e-02,  1.2272e-02,  4.2654e-02,  2.2218e-02,\n",
      "         7.9092e-02,  5.8674e-02, -4.9218e-02,  3.2132e-02,  2.7338e-03,\n",
      "        -6.4431e-02, -2.5716e-02, -2.5200e-02,  6.7211e-02,  2.0753e-02,\n",
      "        -3.7940e-02, -1.2187e-02, -4.8100e-02, -1.3841e-01, -9.5291e-02,\n",
      "        -1.7405e-02, -3.6244e-02, -1.3165e-02,  1.0913e-01, -3.8103e-02,\n",
      "         1.1590e-02, -1.6605e-02, -4.3746e-02, -4.6994e-02, -6.2096e-02,\n",
      "        -1.5154e-01, -9.5747e-02, -4.6606e-02, -6.6613e-02,  4.0910e-01,\n",
      "        -1.3951e-02,  5.8377e-03, -1.0199e-01, -4.1269e-02,  6.6074e-03,\n",
      "        -2.0249e-02,  7.1135e-02, -5.4637e-02,  4.8560e-03,  5.7287e-02,\n",
      "         6.7055e-03, -1.1529e-03,  5.6607e-02, -6.2156e-02,  5.4827e-02,\n",
      "         5.0320e-02,  6.2363e-03,  2.5100e-01, -3.2767e-02, -3.2222e-01,\n",
      "        -8.2089e-02, -8.2794e-02,  5.0875e-02,  1.5371e-01,  1.5838e-01,\n",
      "         9.6299e-02,  4.4111e-02, -9.3503e-02, -4.1314e-02, -6.7891e-02,\n",
      "         7.4247e-02, -6.7585e-02,  9.1610e-02, -4.3105e-02, -1.7745e-02,\n",
      "        -3.2365e-02, -2.2697e-01, -1.8510e-02, -2.1880e-03,  3.1550e-02,\n",
      "         6.3727e-02,  4.1032e-02,  3.5628e-02, -1.5736e-02, -3.9801e-02,\n",
      "         7.6651e-02, -2.4468e-02,  1.7755e-02,  4.5166e-02, -7.7999e-02,\n",
      "        -1.2810e-01,  5.5851e-03, -3.6472e-02, -7.2317e-02,  1.5489e-02,\n",
      "         3.0743e-02,  1.2406e-02,  3.5693e-03,  7.0128e-03,  1.1360e-02,\n",
      "         1.2189e-02,  1.7629e-02, -4.9695e-02,  2.9514e-01,  7.7049e-02,\n",
      "         1.2381e-01,  2.9648e-01,  5.6095e-03, -9.5551e-02, -5.5258e-02,\n",
      "        -4.8147e-02,  4.4906e-02,  5.3674e-03, -4.0218e-02, -2.7745e-02,\n",
      "         7.8927e-02,  3.4750e-02,  2.0862e-01, -5.5249e-02,  9.2615e-02,\n",
      "         2.5378e-02, -1.1578e-02, -9.1153e-03, -4.7815e-02,  7.5379e-03,\n",
      "         4.1849e-02, -2.6778e-02, -1.6734e-01,  1.5851e-02,  1.0453e-01,\n",
      "        -1.2898e-02,  2.8317e-02, -1.0005e-01,  4.8676e-03,  6.8762e-02,\n",
      "        -1.7776e-02, -7.6952e-02, -6.7671e-02, -2.1532e-01,  1.6099e-01,\n",
      "        -2.2366e-02,  2.8839e-01,  1.2463e-01, -7.8280e-02, -6.7696e-02,\n",
      "        -1.5392e-02,  2.7303e-01, -1.7751e-02,  6.3972e-02, -1.6900e-02,\n",
      "        -4.4733e-02, -6.5058e-02, -2.8436e-02,  5.2585e-02, -1.7819e-01,\n",
      "        -1.3598e-02, -8.1296e-02,  1.7016e-01,  6.5367e-02, -5.1451e-02,\n",
      "        -1.9416e-01,  2.6761e-02, -1.7197e-02,  1.4929e-01,  3.7100e-02,\n",
      "        -5.5770e-02,  1.1710e-01,  8.2504e-03,  9.1099e-02,  3.5156e-02,\n",
      "        -1.8383e-03,  2.4381e-02,  6.6448e-04,  2.3547e-03, -4.6125e-02,\n",
      "        -1.5554e-01,  1.4569e-01,  1.3094e-01,  7.5967e-02,  4.9593e-02,\n",
      "        -1.1754e-01,  7.9274e-02,  1.8338e-01,  1.4139e-02,  3.5021e-02,\n",
      "        -1.5334e-01,  2.8388e-01, -3.1315e-02,  2.7762e-02,  2.2338e-01,\n",
      "         2.2379e-01,  2.7575e-02, -1.7353e-02,  6.6190e-02, -1.4153e-02,\n",
      "         3.4527e-02,  2.2380e-01, -8.0898e-02, -1.0985e-01, -5.3484e-02,\n",
      "        -1.3191e-01,  2.8662e-03,  4.6227e-01, -9.5797e-02, -4.0930e-02,\n",
      "         1.2140e-01,  5.0590e-02, -2.0373e-02, -9.4393e-03,  1.5747e-02,\n",
      "        -1.3306e-01, -2.3312e-02, -4.7898e-02, -8.1193e-02, -3.3583e-02,\n",
      "         1.6073e-02,  7.3700e-02, -4.9819e-02, -8.0139e-03, -8.4200e-03,\n",
      "        -1.1419e-01,  3.2303e-03, -1.3205e-01, -5.2488e-02,  2.3260e-03,\n",
      "        -8.2563e-02,  2.9214e-02,  8.5484e-05, -8.0803e-02,  8.5734e-02,\n",
      "        -3.0113e-02,  3.3095e-02, -5.3173e-02,  9.1359e-03,  2.9478e-02,\n",
      "        -2.5184e-02, -1.2302e-02, -1.7977e-01, -3.6971e-02, -1.3840e-02,\n",
      "        -2.4956e-01,  5.0414e-03, -3.7441e-02,  1.5297e-01,  6.9945e-02,\n",
      "         3.8480e-02, -1.5420e-01,  1.0126e-01,  8.8586e-02, -5.2075e-02,\n",
      "        -3.4113e-02,  1.3338e-01, -6.2594e-03,  5.5215e-02, -3.4489e-02,\n",
      "         5.4913e-03,  1.8711e-03,  1.0383e-01, -4.5990e-02, -7.4082e-02,\n",
      "         3.0732e-02,  1.0529e-01, -1.3858e-01, -1.2477e-03, -4.1135e-04,\n",
      "         9.1124e-03, -4.6323e-02,  6.6734e-04, -2.7023e-03,  8.9828e-02,\n",
      "        -2.7475e-02, -9.0151e-02, -5.8980e-02,  2.1231e-01, -4.4924e-02,\n",
      "         2.0364e-02, -4.3869e-02,  9.3140e-03,  7.3586e-02, -8.7737e-02,\n",
      "         8.8909e-03, -1.8896e-02, -2.1631e-01,  9.3183e-02, -1.3093e-01,\n",
      "        -1.8491e-01, -3.7379e-02,  5.4902e-02,  2.0206e-02,  2.0681e-02,\n",
      "        -2.0113e-02,  1.4271e-01, -4.7136e-04,  1.0624e-03,  9.0683e-02,\n",
      "        -1.2395e-01, -3.4734e-02, -3.1123e-02,  2.4467e-01, -1.2942e-01,\n",
      "        -3.4137e-02, -2.9040e-02,  6.4992e-02,  3.8564e-02,  1.1797e-01,\n",
      "        -8.0304e-03, -9.3801e-02,  6.8520e-02,  2.1830e-02,  1.5698e-01,\n",
      "         2.2785e-03, -9.0569e-02,  2.1953e-02,  1.0814e-02,  1.7791e-03,\n",
      "         3.1800e-01, -1.9108e-02, -6.5618e-02,  7.6786e-03, -1.0349e-01,\n",
      "        -3.9480e-03, -8.8860e-03, -1.3378e-02,  4.2281e-02,  1.1424e-01,\n",
      "         2.8361e-01, -7.3144e-02,  4.0058e-02,  1.2552e-01,  9.1824e-03,\n",
      "        -1.2902e-01, -1.5494e-01, -3.9942e-02, -9.9273e-02, -8.9162e-02,\n",
      "         8.3584e-02, -4.1889e-02,  6.9821e-02,  1.2279e-01, -8.4987e-02,\n",
      "        -6.6632e-02,  7.0565e-02, -1.4372e-01,  5.8389e-02,  5.2051e-02,\n",
      "        -8.9793e-02, -1.1338e-01, -1.9009e-02,  3.2576e-02, -6.1294e-02,\n",
      "         1.6543e-01,  8.1262e-02, -1.9153e-01, -1.6996e-02, -6.4067e-03,\n",
      "         4.0050e-02,  1.5593e-01, -1.1438e-01,  1.3713e-01,  3.1640e-02,\n",
      "         1.0470e-01,  2.3170e-03,  1.9655e-01, -2.2174e-02, -1.4331e-02,\n",
      "         1.0551e-01, -8.7134e-02, -8.6777e-02, -6.7960e-02, -1.8113e-01,\n",
      "         4.7958e-02, -4.2129e-02, -1.1096e-01,  2.6425e-01, -1.5025e-02,\n",
      "         2.8779e-02,  1.3790e-01, -4.2245e-02,  3.8898e-02,  1.7363e-01,\n",
      "        -5.6602e-02, -7.0436e-02,  8.6140e-02,  8.3959e-02, -9.0827e-02,\n",
      "        -5.0942e-02, -5.6560e-02, -3.2493e-02, -4.1888e-02, -2.3820e-02,\n",
      "         1.7373e-01, -5.6791e-02, -4.0089e-02,  4.4692e-02,  5.8470e-03,\n",
      "         1.1869e-01, -9.9367e-02,  1.0134e-01, -3.4385e-02,  3.2599e-02,\n",
      "        -7.0188e-02, -8.2939e-02,  4.2470e-02,  4.9906e-02, -1.2907e-01,\n",
      "        -1.0754e-01, -5.3669e-02,  2.0852e-02,  2.8985e-02,  1.2880e-02,\n",
      "        -8.5557e-03,  1.1347e-01,  5.1852e-02,  7.4684e-02,  4.8715e-02,\n",
      "         1.1101e-01, -5.6256e-02,  2.0418e-01, -5.2352e-02,  2.1019e-01,\n",
      "         7.7646e-02,  6.8654e-02, -4.9674e-02, -1.0711e-02, -6.9467e-02,\n",
      "         2.0559e-01, -4.3798e-02,  6.3782e-02, -1.5429e-01, -4.0386e-02,\n",
      "         2.5244e-02, -8.2869e-02, -1.1579e-02, -7.2033e-02,  1.7581e-01,\n",
      "        -3.5858e-02,  3.7866e-02, -5.2666e-03,  4.5334e-02, -6.5432e-02,\n",
      "        -1.1455e-01,  2.1535e-01, -2.3169e-02,  9.2674e-03,  2.5537e-02,\n",
      "        -1.3971e-02, -1.6709e-01, -8.7050e-02,  1.0423e-01,  3.0700e-01,\n",
      "        -9.9891e-02, -8.8479e-02, -1.3738e-02, -1.2333e-02, -3.9320e-02,\n",
      "        -2.8744e-02, -7.7326e-02,  1.8170e-02, -6.9338e-02,  2.8836e-02,\n",
      "        -6.8453e-02,  5.1214e-02, -6.9454e-02,  1.1975e-02, -4.2582e-02,\n",
      "        -7.5787e-02, -1.7702e-01, -5.8028e-02, -1.4638e-01,  4.3677e-02,\n",
      "         3.7741e-03, -7.6761e-02, -8.2503e-02, -7.3439e-04,  1.1584e-01,\n",
      "         2.5212e-02, -1.7453e-01,  1.3903e-01,  1.1208e-01, -1.3188e-01,\n",
      "         6.6298e-02,  6.0701e-03, -7.4587e-02, -2.9380e-03, -7.1081e-02,\n",
      "         2.5348e-02, -5.3189e-02, -3.0765e-02, -7.2377e-02,  4.1903e-01,\n",
      "        -7.2105e-02,  3.8079e-02,  2.1747e-01, -2.1013e-02, -2.7792e-03,\n",
      "        -9.6949e-02,  1.9648e-03, -9.0626e-02,  6.9204e-02, -8.3690e-02,\n",
      "        -4.8536e-02, -1.1388e-02], device='cuda:0')), ('features.19.weight', tensor([[[[-2.5535e-03, -1.1158e-02, -8.2769e-03],\n",
      "          [ 7.9291e-03, -3.0797e-03, -1.7211e-02],\n",
      "          [ 2.1517e-02, -6.8554e-03, -2.0203e-02]],\n",
      "\n",
      "         [[ 1.7328e-02,  1.3599e-02,  2.5407e-02],\n",
      "          [ 5.3267e-03,  1.1174e-02,  7.7055e-03],\n",
      "          [ 2.3977e-02,  2.4697e-02,  1.7318e-02]],\n",
      "\n",
      "         [[-1.0630e-02, -2.0177e-02, -2.8308e-02],\n",
      "          [ 2.3042e-02,  1.2405e-02, -1.9934e-02],\n",
      "          [ 1.9213e-02, -1.2397e-02, -3.3434e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6772e-02, -1.8914e-02, -3.7924e-02],\n",
      "          [-2.5502e-02, -3.1720e-02, -2.6252e-02],\n",
      "          [-2.4845e-02, -1.8907e-02, -1.9230e-02]],\n",
      "\n",
      "         [[-1.1758e-02, -2.0107e-02, -1.0928e-02],\n",
      "          [-4.7293e-03,  1.3684e-03, -4.3430e-03],\n",
      "          [ 1.3007e-02,  1.9641e-03, -4.9493e-03]],\n",
      "\n",
      "         [[-1.1713e-02, -1.2694e-04,  8.5288e-04],\n",
      "          [-4.5545e-04,  1.5829e-02,  1.3876e-02],\n",
      "          [-1.1323e-02,  2.0346e-02,  6.9136e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9240e-03, -1.9465e-02, -1.7367e-02],\n",
      "          [ 5.8091e-04,  3.8840e-03,  2.4610e-02],\n",
      "          [-1.8340e-02,  1.6218e-02,  2.9450e-02]],\n",
      "\n",
      "         [[ 3.4527e-03, -1.0844e-02, -3.3924e-03],\n",
      "          [ 1.0002e-02, -1.9492e-03,  1.1047e-02],\n",
      "          [ 3.6633e-03,  6.9817e-03,  1.9736e-02]],\n",
      "\n",
      "         [[-3.8001e-02, -1.4251e-02,  2.6339e-03],\n",
      "          [-3.6224e-02,  2.2680e-02,  3.3290e-02],\n",
      "          [-1.0769e-02,  1.2441e-02, -4.9949e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9896e-03, -6.4058e-03, -2.4101e-02],\n",
      "          [ 1.2791e-02, -2.0637e-02, -2.6050e-02],\n",
      "          [-2.7292e-03, -1.5665e-02, -4.9022e-03]],\n",
      "\n",
      "         [[ 2.3085e-02,  9.5574e-03, -7.8941e-03],\n",
      "          [ 7.1988e-03, -8.5825e-03, -3.2298e-03],\n",
      "          [-2.0175e-02, -9.5496e-03, -4.6666e-03]],\n",
      "\n",
      "         [[-2.0695e-02,  8.8610e-03,  5.2169e-03],\n",
      "          [-5.8898e-03,  1.4058e-02,  5.3525e-03],\n",
      "          [-1.4002e-02, -1.2316e-03,  7.7627e-05]]],\n",
      "\n",
      "\n",
      "        [[[-5.8429e-03,  2.7116e-03,  2.3624e-02],\n",
      "          [-4.1978e-03, -9.0837e-03,  2.5292e-03],\n",
      "          [ 1.2860e-02,  6.1783e-03,  1.3395e-02]],\n",
      "\n",
      "         [[ 2.6529e-02,  1.9222e-02,  1.7867e-02],\n",
      "          [ 8.9680e-03,  1.4672e-02, -7.2351e-04],\n",
      "          [-1.3411e-02, -3.4650e-03, -6.1179e-03]],\n",
      "\n",
      "         [[ 1.7954e-02, -6.7881e-03,  3.9998e-03],\n",
      "          [ 1.2262e-02,  4.4036e-03,  5.8230e-03],\n",
      "          [ 8.0924e-03,  9.9460e-03,  1.5369e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3355e-02, -4.9726e-03, -2.5974e-02],\n",
      "          [ 1.8754e-02,  1.0445e-02, -4.4697e-04],\n",
      "          [-1.1814e-02, -6.5553e-03, -2.6682e-03]],\n",
      "\n",
      "         [[-2.2084e-02, -9.9309e-03, -1.2186e-02],\n",
      "          [-8.3404e-03, -8.9806e-03, -5.7598e-03],\n",
      "          [-3.5855e-03, -4.3484e-03, -4.0049e-03]],\n",
      "\n",
      "         [[-1.0454e-03,  1.1157e-02,  1.2471e-02],\n",
      "          [-2.7479e-04,  3.7508e-03,  1.3845e-02],\n",
      "          [ 2.7957e-03, -1.5454e-03,  1.0712e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.6992e-02, -2.6317e-03, -7.9817e-03],\n",
      "          [ 2.4494e-03,  2.6524e-02,  1.9120e-02],\n",
      "          [ 1.5663e-02,  3.9729e-02,  4.4346e-02]],\n",
      "\n",
      "         [[ 1.5429e-02,  9.7136e-03,  1.5909e-02],\n",
      "          [-1.8311e-02,  6.4525e-03,  1.9531e-02],\n",
      "          [-1.6276e-02, -8.5435e-03, -2.8023e-03]],\n",
      "\n",
      "         [[-1.1841e-02, -1.3319e-02, -2.5728e-02],\n",
      "          [-7.2776e-03, -1.2659e-02, -1.2658e-02],\n",
      "          [-3.5886e-03, -3.3302e-03,  3.1721e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8700e-04, -1.0890e-03, -8.2800e-03],\n",
      "          [-1.0539e-02, -1.0870e-02, -1.2052e-02],\n",
      "          [-2.7241e-02, -2.3530e-02, -9.9151e-03]],\n",
      "\n",
      "         [[ 7.9957e-03,  3.4473e-03,  2.3797e-02],\n",
      "          [-1.9361e-02, -1.4075e-02, -7.2387e-03],\n",
      "          [-3.0355e-02, -2.7729e-02, -7.0975e-03]],\n",
      "\n",
      "         [[ 1.6241e-02,  5.0342e-03, -5.4142e-03],\n",
      "          [-8.1496e-03, -5.3835e-03, -1.0105e-02],\n",
      "          [-1.8767e-02, -9.4346e-03, -1.6970e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2802e-03, -8.8761e-03, -2.2022e-02],\n",
      "          [ 1.7355e-02,  1.4267e-02, -5.1140e-03],\n",
      "          [ 8.5410e-03, -1.5400e-04,  3.2840e-03]],\n",
      "\n",
      "         [[-3.5262e-03, -1.5919e-02,  2.0676e-02],\n",
      "          [-2.5445e-03,  1.6820e-03,  1.6177e-02],\n",
      "          [-3.4168e-03, -6.6551e-03, -7.9188e-03]],\n",
      "\n",
      "         [[ 3.0259e-02,  2.8690e-02,  3.0252e-02],\n",
      "          [-1.8220e-02, -9.3668e-03,  2.9770e-02],\n",
      "          [-2.1978e-02, -4.9280e-03,  2.1961e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8668e-02, -1.5138e-02,  8.6974e-03],\n",
      "          [-1.4765e-02, -2.3513e-02,  1.1347e-03],\n",
      "          [-1.4733e-02, -3.1786e-02, -2.6354e-03]],\n",
      "\n",
      "         [[ 1.5800e-02,  1.3073e-02,  3.2280e-02],\n",
      "          [ 1.2601e-02,  1.1681e-02,  1.1965e-02],\n",
      "          [ 3.5136e-03,  4.3679e-03, -2.2507e-03]],\n",
      "\n",
      "         [[ 2.8722e-04,  4.1636e-03,  1.7368e-02],\n",
      "          [-1.7108e-02,  3.4045e-03,  3.0699e-02],\n",
      "          [-2.1262e-02, -2.2950e-02,  1.6036e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1554e-03, -4.7330e-04,  9.6674e-03],\n",
      "          [ 1.3853e-04, -9.1627e-03, -1.6065e-03],\n",
      "          [-1.4993e-03, -8.4020e-03,  1.5302e-02]],\n",
      "\n",
      "         [[ 1.3718e-02,  1.3465e-02,  1.9703e-02],\n",
      "          [ 9.3828e-03,  4.3403e-02,  4.0656e-02],\n",
      "          [-1.7159e-02,  8.0563e-03,  3.4450e-03]],\n",
      "\n",
      "         [[-1.5223e-03,  3.1755e-02,  2.9220e-02],\n",
      "          [ 1.0546e-02,  1.4674e-02,  2.5458e-03],\n",
      "          [-5.4571e-03, -8.4497e-03, -6.3715e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.9381e-04, -2.2163e-03,  2.0394e-02],\n",
      "          [-1.3424e-02, -1.4380e-02,  2.3028e-02],\n",
      "          [-1.1290e-02, -1.5281e-02, -9.1222e-03]],\n",
      "\n",
      "         [[ 1.4791e-02,  2.7121e-02,  1.8470e-02],\n",
      "          [-1.2051e-02,  4.4541e-03,  6.4978e-04],\n",
      "          [-7.1708e-03, -1.5393e-02, -1.3675e-02]],\n",
      "\n",
      "         [[ 2.5665e-02,  2.3979e-02,  1.5356e-02],\n",
      "          [-2.4473e-03, -8.8645e-03, -5.5669e-03],\n",
      "          [-2.3476e-02, -1.9197e-02, -2.3337e-03]]]], device='cuda:0')), ('features.19.bias', tensor([-1.1752e-01,  9.3718e-03,  1.1343e-01,  1.2496e-02, -8.0347e-02,\n",
      "        -3.8229e-02,  2.5911e-02,  1.7084e-02, -3.2369e-02, -1.7167e-02,\n",
      "         3.6917e-02,  5.6103e-02, -3.6792e-02, -7.3691e-02, -2.3732e-02,\n",
      "         7.0886e-02,  1.3879e-01,  8.3961e-03,  1.0029e-01,  1.1617e-01,\n",
      "         9.5724e-02, -1.5288e-01, -8.2482e-02,  7.5386e-02,  4.3616e-02,\n",
      "         3.5308e-02, -5.1831e-02,  5.5101e-02,  1.0002e-01, -1.2884e+00,\n",
      "         5.3676e-04,  4.9927e-02,  6.3197e-02,  1.0285e-01,  2.3175e-01,\n",
      "         8.1985e-03,  2.7595e-02,  8.3366e-02,  1.2768e-01,  1.3917e-01,\n",
      "         1.4572e-01,  2.9283e-02, -1.3841e-01,  2.5616e-02, -6.9595e-02,\n",
      "        -1.3612e-01,  3.1376e-02,  9.8765e-02,  8.2654e-02,  8.4328e-02,\n",
      "         1.3563e-01,  5.0649e-02,  1.2511e-02,  1.5002e-01, -6.7553e-02,\n",
      "         4.3009e-02, -1.8281e-03,  1.6613e-01, -9.1294e-02,  7.8736e-02,\n",
      "         8.7640e-02,  1.0324e-02, -1.7400e-01,  1.0301e-01,  1.9302e-01,\n",
      "         5.4685e-02, -2.9570e-02,  2.8155e-02,  2.4079e-01,  1.0872e-01,\n",
      "         5.2928e-02,  7.9099e-02,  8.8713e-02,  1.0865e-02, -5.1822e-02,\n",
      "        -3.7291e-02,  2.6983e-01,  3.0904e-03,  2.8206e-03,  2.0598e-01,\n",
      "        -2.5845e-03,  1.3051e-04, -2.2920e-01,  2.2763e-01,  3.3266e-02,\n",
      "        -1.0871e-01,  6.8843e-02, -3.3600e-02,  8.5373e-02, -2.2240e-02,\n",
      "         1.3290e-01, -1.5021e-02, -2.1608e-01, -5.1593e-02,  2.9458e-01,\n",
      "        -5.8781e-02, -1.1782e-02, -3.7792e-02,  4.2807e-02,  4.9526e-02,\n",
      "         1.9662e-01, -1.9459e-01,  5.0997e-02, -2.3870e-02,  5.9481e-02,\n",
      "        -9.4280e-02,  1.2516e-01,  5.8879e-02, -3.8560e-02,  6.0303e-03,\n",
      "        -1.1376e-03,  9.4548e-02,  5.5031e-02,  3.3100e-01,  1.0379e-01,\n",
      "         7.5330e-03,  1.0166e-01, -4.6531e-02,  1.7130e-01,  1.6491e-01,\n",
      "         1.7477e-01, -3.7272e-03,  8.3344e-02,  1.2243e-01,  1.3192e-02,\n",
      "         6.0393e-02,  1.3215e-01, -2.8612e-01,  2.1367e-01, -4.4983e-02,\n",
      "         7.6503e-02,  4.0292e-02, -5.4988e-02,  2.7456e-01,  8.8115e-02,\n",
      "         4.4357e-02,  1.3897e-01,  3.0585e-02,  2.1787e-02,  1.6900e-02,\n",
      "         1.5338e-02,  2.2825e-01, -3.6196e-02, -3.0091e-02,  3.5445e-02,\n",
      "         2.2176e-02,  2.2434e-01, -3.0888e-02,  8.1282e-02,  9.7392e-02,\n",
      "         8.2857e-02,  1.0359e-02,  9.7639e-02,  4.7845e-02, -2.3539e-01,\n",
      "         9.2643e-02,  5.1654e-02, -9.9514e-02,  5.7799e-02,  1.0307e-01,\n",
      "         9.1732e-02,  1.2984e-02,  3.6802e-02,  1.1253e-01,  1.9391e-02,\n",
      "        -1.1692e-01,  3.9203e-01, -6.3642e-02,  1.1514e-01, -1.5983e-01,\n",
      "         1.2919e-01,  1.7574e-01,  1.2229e-02, -5.7805e-02,  1.7859e-01,\n",
      "         8.7310e-02,  1.9079e-01,  3.7651e-02,  2.8623e-02,  5.9517e-02,\n",
      "        -2.1159e-01,  3.4242e-02, -1.0591e-02,  2.5614e-02,  1.0470e-01,\n",
      "        -5.5612e-02, -2.0477e-02,  6.9557e-02,  1.8120e-01, -6.2036e-03,\n",
      "        -9.7789e-02, -2.1976e-02, -3.1304e-03,  6.2532e-02,  1.1730e-02,\n",
      "        -3.4909e-03,  4.2647e-02,  9.3915e-02,  1.2538e-01,  4.1627e-02,\n",
      "         7.6311e-02,  1.2136e-01, -5.5574e-02,  1.3379e-01,  1.0269e-01,\n",
      "         1.0452e-01,  2.3986e-02,  1.4015e-01, -3.9869e-02,  3.1962e-02,\n",
      "         1.2046e-01,  1.5372e-02,  7.4532e-02, -1.9316e-01,  6.1752e-02,\n",
      "        -7.3845e-02, -2.5231e-02,  1.5001e-01,  1.4532e-01, -8.4633e-01,\n",
      "         8.7073e-02,  1.0819e-01,  3.5081e-02,  8.5053e-02, -1.2216e-01,\n",
      "         1.2835e-01,  1.5607e-01, -3.7588e-02,  8.0178e-02,  1.6453e-01,\n",
      "         1.2252e-01, -6.7541e-04,  8.2943e-02, -3.9198e-02, -1.3526e-01,\n",
      "         2.6116e-03, -1.3416e-01,  1.7637e-01,  8.7944e-02,  7.6524e-03,\n",
      "         9.9815e-02,  6.9478e-02,  1.0368e-01, -2.8779e-03,  2.0655e-01,\n",
      "         5.8613e-02,  7.4368e-02,  8.9972e-02, -2.7691e-02, -4.9731e-02,\n",
      "        -6.9135e-02,  1.0868e-01,  2.6244e-02, -2.0210e-01,  4.7362e-02,\n",
      "         1.2374e-01, -5.4774e-03, -4.0313e-03, -3.0035e-02,  1.4077e-01,\n",
      "         1.2356e-01,  3.7340e-03,  2.6445e-01,  1.4917e-01,  7.8222e-02,\n",
      "        -4.3484e-01,  2.8827e-02,  5.4760e-02, -1.2365e-01, -3.0351e-01,\n",
      "         1.1207e-01,  7.1388e-02,  2.5808e-03,  9.7687e-02, -2.0770e-02,\n",
      "         7.6921e-02,  4.8066e-02, -3.5002e-02,  1.5971e-01,  6.8491e-02,\n",
      "         7.3245e-02,  7.8202e-02,  2.5484e-02,  1.3691e-01, -9.7701e-03,\n",
      "         1.0845e-01, -7.6161e-02,  7.7191e-04,  2.0376e-01, -9.9493e-02,\n",
      "        -9.3491e-02,  9.5678e-02, -6.8717e-03, -1.0968e-01,  8.6918e-02,\n",
      "         3.6534e-02,  3.3514e-01,  1.2181e-01,  1.8201e-01, -9.6818e-02,\n",
      "        -1.1485e-01,  1.2914e-01,  3.2308e-02,  1.1907e-01,  3.4547e-02,\n",
      "         1.9015e-01,  7.2986e-02,  3.9030e-02, -1.0509e-01, -9.8305e-03,\n",
      "        -1.5110e-01, -8.9721e-02,  3.7692e-01,  5.7211e-02,  9.9464e-03,\n",
      "         7.5426e-02,  1.5894e-02, -2.3518e-02,  1.6229e-02,  3.0174e-02,\n",
      "         1.4174e-01, -4.5873e-02, -3.2519e-02,  2.4360e-02, -5.1694e-02,\n",
      "         8.0766e-03,  1.4054e-01,  1.4740e-01,  6.7029e-02, -6.3782e-03,\n",
      "        -7.7158e-02,  6.2079e-02,  1.3730e-01, -3.6573e-01,  2.2208e-01,\n",
      "         5.3740e-02,  5.2301e-02,  2.0854e-02,  6.2967e-02,  2.2041e-01,\n",
      "        -4.5890e-02,  1.1650e-01, -6.4502e-02,  1.1856e-01,  1.0317e-01,\n",
      "         7.3146e-02,  1.6169e-01,  1.0085e-01,  9.5029e-02,  2.3691e-02,\n",
      "         4.7452e-02,  2.6965e-01,  3.0746e-02,  1.0556e-01,  6.5479e-02,\n",
      "         2.1520e-01, -2.6398e-01,  5.1941e-02,  4.3374e-02,  3.1432e-02,\n",
      "         7.8844e-02, -2.1496e-01, -3.1007e-02, -1.8203e-01, -1.3061e-01,\n",
      "         1.9984e-01,  9.4902e-02,  2.9525e-02,  1.2745e-02,  3.8509e-02,\n",
      "         6.0238e-02,  1.4807e-01,  1.6040e-01,  6.2494e-02,  1.5621e-01,\n",
      "         4.2483e-02, -1.8520e-01,  3.6974e-02,  3.2843e-02,  1.5007e-02,\n",
      "        -1.8008e-01,  1.7907e-01,  1.7162e-01, -1.2326e-02,  1.4968e-01,\n",
      "         4.9689e-02,  5.9230e-02,  1.1797e-01, -5.8377e-03,  1.4040e-01,\n",
      "        -3.3696e-01,  9.1060e-02, -1.2818e-02,  1.2552e-01,  1.4421e-01,\n",
      "         1.2493e-01, -1.3811e-02,  7.9634e-02, -1.8466e-01,  3.5309e-02,\n",
      "         4.8165e-02,  7.3057e-02,  1.0300e-01,  4.6092e-02,  1.1200e-01,\n",
      "        -9.1888e-03, -9.3984e-02, -1.1322e-01,  2.1226e-01,  1.0305e-01,\n",
      "         9.4777e-02,  5.3127e-02,  4.2190e-02,  4.2996e-02, -4.4030e-02,\n",
      "        -2.5095e-02, -5.5975e-02,  3.9855e-02,  7.2354e-02,  1.4146e-01,\n",
      "         1.7209e-01,  7.6174e-02,  3.1253e-02,  6.5290e-02, -1.0977e-01,\n",
      "        -3.1703e-02,  1.1302e-01,  2.8285e-02, -3.3151e-02,  1.7735e-01,\n",
      "         9.3526e-02,  2.2077e-01, -1.7418e-02, -1.5783e-02,  2.9759e-02,\n",
      "        -1.0274e-02,  2.8176e-02,  4.1800e-02,  5.3104e-02, -1.4859e-01,\n",
      "         5.3251e-02,  3.1860e-02,  1.9542e-01,  8.0312e-03,  1.4666e-03,\n",
      "         1.2945e-01,  1.3534e-01,  1.5359e-01,  9.7278e-02,  8.6149e-02,\n",
      "        -1.1137e-01, -1.7902e-02,  9.2563e-03,  1.6293e-01,  4.9443e-01,\n",
      "        -1.4069e-01,  6.1134e-02, -1.2497e-02, -9.6147e-02,  3.1645e-03,\n",
      "         4.2570e-02, -6.7952e-02, -2.3923e-02,  1.6651e-02,  7.4047e-03,\n",
      "        -5.4524e-02, -1.7130e-01,  8.0671e-02,  1.7044e-01, -1.6208e-01,\n",
      "        -2.6633e-02,  7.4453e-02,  2.4709e-01,  2.0264e-01, -1.9671e-02,\n",
      "         5.0530e-02,  1.5865e-01,  4.0015e-02,  1.7632e-01, -3.7870e-01,\n",
      "         1.4281e-01,  1.4696e-01,  1.0580e-01,  1.5323e-01,  9.4102e-02,\n",
      "         1.1278e-01, -1.3008e-01,  1.1962e-02, -1.6751e-01,  1.2249e-01,\n",
      "        -6.0301e-03,  3.4401e-02,  5.5904e-03,  1.4562e-01,  8.8877e-02,\n",
      "         1.3026e-01,  1.0785e-02, -4.0565e-02, -1.9766e-02, -2.1336e-01,\n",
      "         5.8849e-03,  1.4757e-01,  1.2280e-03,  7.3065e-02,  1.3179e-02,\n",
      "         1.5285e-01,  1.0500e-01,  1.3456e-01,  3.6927e-02,  1.2596e-01,\n",
      "         1.6769e-01, -2.0959e-03], device='cuda:0')), ('features.21.weight', tensor([[[[-3.4618e-02, -3.3801e-02, -2.2497e-02],\n",
      "          [-3.2275e-02, -2.8543e-02, -1.5026e-02],\n",
      "          [-3.1307e-02, -1.8263e-02, -1.1662e-02]],\n",
      "\n",
      "         [[-6.7787e-03, -5.1631e-03, -1.1498e-02],\n",
      "          [-3.1353e-03, -9.5856e-03, -1.1940e-02],\n",
      "          [-1.6923e-02, -1.5893e-02, -9.2058e-03]],\n",
      "\n",
      "         [[ 2.1721e-02,  1.6138e-03, -1.2762e-02],\n",
      "          [ 1.1541e-02,  3.9117e-03, -1.7966e-02],\n",
      "          [ 8.2566e-03, -7.2988e-03, -1.8711e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1666e-02,  5.8356e-03,  5.1317e-03],\n",
      "          [ 2.7172e-02,  3.0096e-02,  2.2107e-02],\n",
      "          [ 5.0745e-02,  5.0426e-02,  5.2568e-02]],\n",
      "\n",
      "         [[ 1.5641e-02,  6.1531e-03,  1.0435e-02],\n",
      "          [-4.9628e-03, -1.0472e-02, -9.7399e-03],\n",
      "          [-1.3043e-02, -1.1895e-02, -8.3080e-03]],\n",
      "\n",
      "         [[-7.5200e-03, -8.6918e-03, -7.7642e-03],\n",
      "          [-2.1090e-02, -1.2527e-02, -1.4423e-02],\n",
      "          [-1.5833e-02, -1.0271e-02, -6.5119e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9262e-02,  2.4535e-02,  9.8333e-03],\n",
      "          [ 1.3875e-02,  1.1888e-02,  1.5868e-03],\n",
      "          [ 3.2187e-02,  2.7896e-02,  2.1428e-02]],\n",
      "\n",
      "         [[-1.2907e-02, -1.6465e-02, -1.0769e-02],\n",
      "          [-1.2730e-02, -8.0963e-04, -9.7610e-03],\n",
      "          [-1.7824e-02, -1.9745e-03, -6.0412e-03]],\n",
      "\n",
      "         [[ 7.3908e-03,  1.3782e-03, -2.7653e-03],\n",
      "          [ 2.2362e-02,  3.1297e-03,  7.8103e-03],\n",
      "          [-3.6186e-03,  4.7948e-03, -3.9560e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8102e-03,  6.1981e-04, -9.2120e-04],\n",
      "          [-2.2606e-03, -2.2002e-02, -3.1097e-03],\n",
      "          [-9.4541e-03, -2.8003e-02, -2.2712e-02]],\n",
      "\n",
      "         [[ 2.0525e-03, -3.4167e-03,  1.0797e-02],\n",
      "          [ 8.3235e-03, -7.1854e-03,  8.9610e-03],\n",
      "          [ 1.1586e-02, -4.0099e-03,  1.9634e-02]],\n",
      "\n",
      "         [[ 7.4921e-03, -1.0478e-03,  1.5801e-02],\n",
      "          [ 7.9514e-04, -1.6881e-02, -2.4732e-04],\n",
      "          [ 1.5973e-02,  1.6192e-02,  3.7039e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3103e-02, -2.4085e-02, -2.1704e-02],\n",
      "          [ 1.0276e-02, -7.1129e-03,  6.8848e-03],\n",
      "          [ 8.5694e-03, -1.9288e-03, -2.8843e-03]],\n",
      "\n",
      "         [[-1.3841e-02, -1.0492e-02, -2.4102e-02],\n",
      "          [-2.7612e-02, -2.5791e-02, -1.2960e-02],\n",
      "          [-1.5598e-03,  3.6200e-04,  2.1741e-02]],\n",
      "\n",
      "         [[ 2.7855e-02,  2.6277e-02,  2.2290e-02],\n",
      "          [ 2.4780e-02,  2.5150e-02,  2.5566e-03],\n",
      "          [-1.9022e-03,  1.0823e-02, -8.6423e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.3089e-03,  1.8908e-03,  6.9918e-03],\n",
      "          [-6.9307e-03, -8.7947e-03, -7.2253e-03],\n",
      "          [-3.5385e-03, -4.9549e-03, -8.7845e-03]],\n",
      "\n",
      "         [[ 8.2309e-03,  1.8546e-04, -9.4308e-04],\n",
      "          [ 2.4796e-04, -1.3734e-03, -6.4844e-03],\n",
      "          [ 1.0330e-02, -6.3096e-03,  2.9899e-03]],\n",
      "\n",
      "         [[-3.2615e-03,  1.1206e-03,  2.0341e-03],\n",
      "          [ 3.0882e-03, -1.5877e-02, -3.2855e-03],\n",
      "          [-1.0955e-02, -5.5521e-03, -1.2025e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.7462e-02, -3.8714e-02, -3.6843e-02],\n",
      "          [-2.3918e-02, -3.9357e-02, -2.3753e-02],\n",
      "          [-6.3624e-03, -1.7850e-02,  1.0370e-03]],\n",
      "\n",
      "         [[ 2.8356e-02,  1.4364e-02,  8.2898e-03],\n",
      "          [ 1.7873e-02, -1.1615e-03,  5.5851e-03],\n",
      "          [-1.2643e-03, -8.9554e-03, -3.0568e-03]],\n",
      "\n",
      "         [[ 5.1422e-03,  4.6503e-04,  9.0143e-03],\n",
      "          [ 1.9823e-02,  3.4737e-02,  2.8242e-02],\n",
      "          [ 3.2088e-02,  2.3840e-02,  2.2072e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4983e-03,  9.9425e-03,  4.5399e-03],\n",
      "          [ 1.1027e-02,  4.5929e-03,  2.6449e-03],\n",
      "          [ 1.7532e-02, -1.0313e-03, -8.3937e-03]],\n",
      "\n",
      "         [[-1.0549e-02, -1.0171e-02, -5.7416e-03],\n",
      "          [-8.2740e-03, -8.3159e-03, -1.4377e-02],\n",
      "          [-1.1800e-02, -1.1000e-02, -1.6324e-03]],\n",
      "\n",
      "         [[-1.3096e-02, -3.1618e-02, -2.5536e-02],\n",
      "          [-4.8419e-03, -1.3772e-02, -1.3568e-02],\n",
      "          [-1.5098e-02, -8.9054e-03, -1.2804e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8384e-03, -6.2667e-03, -1.1664e-02],\n",
      "          [ 3.3901e-03, -1.1676e-02, -6.1101e-03],\n",
      "          [-1.7972e-02, -3.3468e-02, -9.4137e-03]],\n",
      "\n",
      "         [[ 1.0985e-03,  1.3939e-04,  5.5219e-03],\n",
      "          [-9.3755e-03, -3.6006e-03, -3.1602e-05],\n",
      "          [-2.7297e-03, -5.7176e-03, -3.4485e-03]],\n",
      "\n",
      "         [[ 1.9236e-02,  1.2842e-02,  8.1627e-03],\n",
      "          [ 1.5062e-02,  4.3942e-04,  1.0795e-03],\n",
      "          [ 6.7360e-03,  9.0229e-03,  2.8575e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.0815e-03, -4.9577e-03,  1.6272e-03],\n",
      "          [ 2.0418e-03, -8.2440e-03,  8.4400e-03],\n",
      "          [ 6.3961e-03, -5.5046e-03,  1.0984e-03]],\n",
      "\n",
      "         [[ 9.5378e-04, -1.1439e-02, -3.1516e-03],\n",
      "          [ 1.0669e-03, -1.8538e-02, -1.2831e-02],\n",
      "          [ 5.5736e-03, -1.1039e-02, -1.3992e-02]],\n",
      "\n",
      "         [[-1.9465e-02, -1.2852e-02, -1.8318e-02],\n",
      "          [-2.6698e-02, -1.8011e-02, -1.0662e-02],\n",
      "          [-1.6479e-02, -1.4482e-02, -1.6194e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3728e-02, -3.6695e-02, -3.7500e-02],\n",
      "          [-1.3462e-03, -3.9573e-04,  3.2643e-03],\n",
      "          [ 1.5174e-02,  2.6909e-02,  1.3840e-02]],\n",
      "\n",
      "         [[ 2.8536e-04, -1.5611e-02, -6.2689e-03],\n",
      "          [-4.9708e-04, -2.2292e-02, -2.0291e-02],\n",
      "          [ 1.2825e-02, -1.6755e-02, -2.1885e-02]],\n",
      "\n",
      "         [[ 8.5642e-03,  6.9444e-03,  9.6820e-03],\n",
      "          [ 3.2590e-03,  1.7821e-02,  7.3303e-03],\n",
      "          [ 1.2386e-02,  2.1082e-02, -7.5897e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6673e-03,  1.3758e-02,  1.1945e-02],\n",
      "          [ 8.6567e-03,  1.0310e-02, -1.6190e-03],\n",
      "          [ 1.7062e-02, -6.1529e-03, -4.0647e-03]],\n",
      "\n",
      "         [[ 1.5687e-02,  3.6550e-03, -1.1310e-02],\n",
      "          [-1.4527e-04,  8.9713e-04,  2.0525e-03],\n",
      "          [-1.0805e-02, -5.5566e-03,  8.8173e-03]],\n",
      "\n",
      "         [[-1.4262e-02, -1.7638e-02, -6.3932e-03],\n",
      "          [-2.4702e-03, -1.2362e-02, -2.2834e-02],\n",
      "          [-4.4622e-03, -9.5870e-03, -1.7204e-02]]]], device='cuda:0')), ('features.21.bias', tensor([ 5.3096e-02,  1.0494e-02,  2.3031e-01,  3.7629e-02,  8.6362e-02,\n",
      "        -5.3445e-02,  1.3858e-01, -7.1123e-02, -4.1582e-02, -6.0357e-02,\n",
      "         2.8702e-02,  3.9870e-02,  2.4511e-02, -2.9192e-02,  2.2518e-02,\n",
      "         1.5705e-01,  1.5073e-01, -3.4747e-02, -2.9308e-02,  1.6866e-01,\n",
      "        -7.8936e-02,  1.5662e-01,  6.9270e-02,  2.1940e-01,  8.5960e-03,\n",
      "         4.4231e-02,  5.8154e-03,  3.2049e-01,  2.1366e-01,  2.0677e-02,\n",
      "        -2.1056e-01,  2.3449e-01, -4.8404e-04,  1.2819e-01,  2.7670e-02,\n",
      "         1.3770e-02, -8.2480e-02,  1.1657e-01,  1.3776e-03, -6.9343e-02,\n",
      "        -4.2484e-02, -4.8676e-02,  1.5156e-01,  4.5194e-02,  9.5455e-02,\n",
      "         9.9230e-02, -4.9602e-02,  1.0385e-01, -1.9058e-01, -6.8478e-03,\n",
      "         1.2834e-01, -1.5414e-01, -8.2917e-02,  1.2840e-01,  1.0515e-01,\n",
      "        -3.4903e-03, -2.4074e-02,  2.7386e-01,  8.2506e-02,  2.6081e-02,\n",
      "         1.0385e-01,  1.2873e-01,  1.1904e-02,  3.2242e-01,  7.7528e-02,\n",
      "         1.5680e-01, -9.4496e-02,  6.5867e-02,  1.1608e-01,  2.9928e-02,\n",
      "         4.5040e-02,  6.6757e-02, -3.8690e-03,  4.5608e-02, -6.0798e-02,\n",
      "        -7.9031e-02,  1.8973e-01,  9.7177e-02,  2.8907e-02,  5.2512e-02,\n",
      "         8.9481e-02, -1.0245e-02, -3.3247e-02,  3.2455e-02,  1.7449e-01,\n",
      "         5.4149e-02,  3.5487e-02, -6.0035e-02,  1.0988e-01,  4.1636e-02,\n",
      "         1.0168e-01, -1.3880e-02, -2.2165e-02, -2.3697e-02, -2.0682e-02,\n",
      "        -7.4109e-02,  7.1141e-02,  2.8931e-01,  5.7430e-02,  2.6998e-01,\n",
      "         1.3690e-01,  1.2856e-01,  9.7829e-02, -3.3965e-02, -6.0774e-01,\n",
      "         1.3285e-01,  7.6127e-02,  1.8083e-03,  3.7983e-02,  3.1329e-02,\n",
      "         2.3151e-01,  1.7247e-01,  7.9159e-02,  2.0701e-02,  4.6385e-02,\n",
      "         1.1695e-02,  1.7603e-01,  8.7159e-03,  1.4734e-01, -1.6980e-01,\n",
      "         5.8873e-02,  4.5943e-03, -2.5116e-02, -1.0081e-02,  1.7245e-01,\n",
      "         5.0457e-02,  3.1419e-03,  1.9542e-01,  2.3010e-01,  1.4896e-02,\n",
      "         6.8453e-03,  6.4402e-02,  2.8297e-01, -1.9778e-02, -6.6403e-02,\n",
      "        -1.7974e-01,  1.1520e-01,  1.8115e-01,  6.7828e-02,  1.4529e-01,\n",
      "         9.5749e-02, -4.8107e-02,  1.7572e-01,  2.0596e-02,  2.0453e-01,\n",
      "         1.0453e-01,  2.7929e-03, -6.7208e-02,  1.1605e-01,  3.2382e-01,\n",
      "        -2.5631e-02, -1.0080e-01, -2.7476e-01, -4.3790e-02,  1.0209e-01,\n",
      "        -4.0674e-02,  1.4236e-01,  4.9621e-02,  1.3615e-02, -6.8988e-02,\n",
      "        -1.5604e-01, -5.6830e-02,  2.1956e-01, -3.9003e-02,  7.6721e-02,\n",
      "         1.7829e-01,  3.5841e-02, -1.6543e-01,  1.0653e-01,  1.2691e-01,\n",
      "         8.0850e-02,  3.5409e-02,  7.6336e-02,  1.8354e-01, -3.1974e-02,\n",
      "         1.0952e-01, -7.7806e-02, -1.8276e-02,  1.9917e-03, -5.3514e-02,\n",
      "         6.8031e-02,  1.3051e-01,  5.5512e-02, -2.2692e-01, -1.7514e-01,\n",
      "        -2.3241e-02, -8.0095e-02,  2.4215e-01, -9.3736e-02, -2.7950e-02,\n",
      "        -4.0031e-02, -8.9803e-04, -1.3281e-01,  1.6617e-02, -1.7896e-01,\n",
      "         2.2928e-03,  7.4135e-02,  7.4704e-02, -5.3855e-02,  3.5239e-03,\n",
      "         6.8048e-02, -1.7627e-02, -7.6305e-02, -3.0225e-02, -1.9956e-02,\n",
      "         7.6958e-02,  6.6637e-02,  7.5784e-02,  2.0265e-01,  8.2736e-02,\n",
      "         1.8189e-01,  1.5864e-01, -2.7969e-02,  1.2254e-01,  1.6273e-01,\n",
      "         7.0590e-02,  3.6348e-02,  7.5238e-02,  4.0113e-02,  1.7456e-01,\n",
      "         1.3055e-01, -2.3147e-01, -4.0592e-02, -9.2117e-02,  4.7834e-02,\n",
      "         5.8923e-02, -4.9228e-02,  2.3561e-01,  5.6799e-02,  2.6177e-03,\n",
      "         1.8197e-01,  2.4430e-01,  1.5937e-01,  1.2356e-01,  2.0870e-02,\n",
      "         2.2301e-01, -8.7270e-02,  2.1521e-03,  5.6075e-02,  5.3088e-02,\n",
      "         2.5135e-01, -2.5713e-02, -5.7987e-02,  1.2134e-01, -6.9332e-02,\n",
      "         1.7102e-01,  8.0538e-02, -2.1009e-02,  1.5748e-01,  1.3500e-01,\n",
      "         3.5484e-02,  1.9533e-02, -1.0588e-01, -1.1630e-02,  7.3210e-02,\n",
      "         6.1526e-02,  9.7647e-02,  1.2334e-01,  7.9605e-02, -1.5892e-02,\n",
      "         8.3292e-02,  1.1110e-01,  5.2385e-02,  1.5979e-01,  4.5474e-02,\n",
      "         1.3827e-01,  2.3116e-02, -1.3866e-01,  3.0925e-02, -1.9310e-02,\n",
      "         1.0778e-02,  2.7404e-02,  1.5212e-01, -2.1072e-02,  2.2597e-01,\n",
      "        -2.4462e-03, -4.5231e-02, -5.3727e-02,  6.5086e-02, -8.8079e-02,\n",
      "        -6.8959e-02,  1.5689e-01,  3.5168e-02,  1.4016e-02,  7.8228e-02,\n",
      "        -7.1301e-03,  7.0884e-02, -2.0291e-02, -4.3556e-02,  8.2587e-02,\n",
      "         1.0355e-01,  2.4044e-01,  1.5205e-03,  1.3740e-01,  1.0288e-01,\n",
      "         4.9636e-02,  6.0422e-02,  2.2115e-02,  4.1499e-02,  1.7964e-01,\n",
      "         8.9835e-02,  6.3780e-02,  4.4028e-02,  2.5870e-02,  2.6749e-01,\n",
      "        -8.6992e-02,  4.2132e-02,  4.5251e-02, -6.7016e-03,  1.2589e-01,\n",
      "         1.0735e-01,  1.4337e-02,  5.1316e-02,  3.7713e-03,  1.1460e-02,\n",
      "        -1.4947e-02, -1.3711e-02,  1.4697e-01,  9.2782e-02,  1.2916e-01,\n",
      "         1.7470e-01,  5.8596e-02,  1.1636e-01,  5.8924e-02, -1.4533e-01,\n",
      "         1.6085e-02,  5.6891e-02, -4.3371e-02,  2.0790e-02, -3.9939e-02,\n",
      "         4.3089e-04,  1.6872e-01,  1.7437e-01,  1.1686e-01, -1.2212e-03,\n",
      "         6.0886e-04,  1.0210e-01, -2.6895e-02, -1.5379e-01,  1.8642e-02,\n",
      "         1.4519e-01,  1.3723e-01,  1.6059e-01,  1.0188e-01,  1.5790e-01,\n",
      "         5.3370e-02, -9.6922e-03,  1.0662e-01, -3.2237e-02,  1.6459e-01,\n",
      "        -3.2802e-02,  9.4145e-02,  1.6049e-01,  3.3623e-02,  8.2616e-02,\n",
      "         1.2163e-02,  1.8475e-01, -1.5923e-01,  1.1078e-01,  4.3297e-02,\n",
      "         9.3649e-02, -5.2736e-03,  1.5716e-01,  1.7663e-01,  1.5766e-01,\n",
      "        -6.5356e-02,  4.1497e-02,  5.5715e-02, -5.0333e-02,  4.9138e-02,\n",
      "         5.1402e-02,  9.5557e-02,  2.9288e-02,  7.0810e-02,  2.3480e-01,\n",
      "         1.3228e-01, -2.3599e-02, -1.2055e-01,  2.6201e-02,  4.7531e-02,\n",
      "        -2.3009e-02,  1.6585e-02,  7.9533e-02,  3.5151e-01,  2.1487e-01,\n",
      "         3.2147e-02,  1.9151e-02,  2.6160e-01,  6.0619e-02, -2.7466e-02,\n",
      "         3.8685e-01,  2.6087e-01, -1.6858e-02,  3.9768e-02, -1.1643e-01,\n",
      "        -1.1088e-01, -2.6395e-01, -5.5512e-02,  2.3809e-01,  4.1467e-02,\n",
      "        -6.7768e-02,  7.4545e-02,  1.6406e-01,  4.1792e-02,  1.4026e-02,\n",
      "        -8.9575e-02,  4.0771e-02, -6.3659e-03,  1.6554e-01,  3.2879e-02,\n",
      "        -1.0687e-01,  2.1432e-01, -5.3219e-04, -4.8029e-02,  1.5006e-01,\n",
      "         2.5357e-02, -6.6046e-02, -3.5784e-03, -1.5199e-02, -1.5227e-01,\n",
      "         2.6880e-01,  1.4434e-01,  8.7642e-02,  1.4905e-01,  4.5407e-02,\n",
      "         6.8893e-02,  6.4361e-02,  3.1035e-01,  4.9365e-02, -9.4566e-03,\n",
      "        -1.7363e-02, -1.0042e-01,  8.5943e-02,  2.1078e-02, -5.3363e-02,\n",
      "        -2.8033e-02, -3.2484e-02,  8.7631e-03,  5.7897e-02,  6.6533e-02,\n",
      "         5.5471e-03,  1.6292e-01,  1.7233e-03,  3.3627e-01, -4.0299e-02,\n",
      "         4.1980e-02,  1.7569e-01,  6.0349e-03,  6.1534e-02,  1.0451e-02,\n",
      "         1.3474e-02,  6.5710e-02,  7.1867e-02,  4.9509e-02,  3.0298e-01,\n",
      "        -4.8346e-02,  1.5135e-01,  1.0070e-01,  2.2932e-02,  2.6473e-01,\n",
      "         9.3903e-02,  6.8277e-02,  2.1148e-01,  3.4836e-02,  1.9828e-01,\n",
      "         9.3527e-02,  4.0988e-02,  2.0483e-01,  2.4628e-02, -1.5936e-02,\n",
      "        -7.9222e-02,  1.7063e-02,  7.0228e-02,  5.1478e-02,  2.8280e-02,\n",
      "        -3.8762e-03, -1.0082e-01,  1.3170e-01,  1.7213e-01,  1.2682e-01,\n",
      "         1.2299e-01,  9.6196e-02,  1.4434e-01, -2.9454e-02,  1.2433e-01,\n",
      "        -1.8897e-01,  4.4738e-03,  6.6992e-02, -4.8120e-02,  6.5972e-02,\n",
      "        -1.9316e-01,  2.2723e-01,  5.6969e-02,  5.1578e-02,  6.0070e-02,\n",
      "         6.1307e-02,  1.0806e-01,  3.7007e-02,  8.3496e-02,  2.3447e-02,\n",
      "         4.9168e-02,  1.5781e-02,  1.1263e-02,  1.8551e-01,  1.1121e-01,\n",
      "         9.0919e-03, -1.7644e-02,  1.5611e-01, -3.9080e-02,  1.2658e-02,\n",
      "        -5.5652e-02,  8.2594e-02], device='cuda:0')), ('features.24.weight', tensor([[[[-2.9665e-02, -1.8004e-02, -2.0759e-02],\n",
      "          [-2.3392e-02, -8.0310e-03, -1.2426e-02],\n",
      "          [-1.7737e-02, -1.7743e-02, -2.7021e-02]],\n",
      "\n",
      "         [[-2.1687e-02, -2.5525e-02, -6.7156e-03],\n",
      "          [-1.3061e-02, -1.7542e-02, -1.5949e-02],\n",
      "          [-2.4782e-02, -1.0104e-02, -4.9635e-03]],\n",
      "\n",
      "         [[-4.2964e-03, -3.6401e-03, -6.3512e-03],\n",
      "          [ 1.0383e-02,  2.3713e-02,  1.4648e-02],\n",
      "          [-9.3529e-03, -1.2316e-03, -8.4364e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5568e-02,  3.8466e-02,  2.1158e-02],\n",
      "          [ 4.5726e-02,  5.0937e-02,  3.1546e-02],\n",
      "          [ 3.8903e-02,  4.3654e-02,  3.7143e-02]],\n",
      "\n",
      "         [[ 2.6901e-02,  1.0798e-02,  1.9648e-02],\n",
      "          [ 2.8889e-03, -8.7730e-03,  1.4934e-02],\n",
      "          [ 4.2627e-03, -8.3357e-03,  2.3783e-02]],\n",
      "\n",
      "         [[ 1.5674e-02,  1.1260e-02,  1.9177e-02],\n",
      "          [ 2.7215e-02,  9.9037e-03,  2.5009e-02],\n",
      "          [ 9.9336e-03,  7.7196e-03, -1.3929e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3820e-02, -2.3844e-02, -3.2966e-04],\n",
      "          [-1.2515e-02, -1.1827e-02,  2.5957e-03],\n",
      "          [ 5.6352e-04, -4.4090e-03,  9.8300e-03]],\n",
      "\n",
      "         [[ 9.0568e-03,  9.2629e-03,  1.4934e-02],\n",
      "          [ 2.8985e-03,  1.8503e-02,  1.6307e-02],\n",
      "          [-1.4100e-02,  2.3823e-03, -1.1177e-02]],\n",
      "\n",
      "         [[-1.1710e-02, -1.2035e-02, -9.6249e-03],\n",
      "          [ 3.7106e-03,  1.3383e-02,  1.1210e-02],\n",
      "          [ 2.5377e-04,  9.5491e-04,  2.6870e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3927e-03, -3.7516e-04,  3.2514e-03],\n",
      "          [ 2.4906e-02,  2.3891e-02,  1.4050e-03],\n",
      "          [ 2.8756e-02,  2.8597e-02,  6.6499e-03]],\n",
      "\n",
      "         [[-5.6646e-03,  1.5783e-02,  4.7909e-03],\n",
      "          [-1.4084e-02,  8.0757e-03, -2.0989e-03],\n",
      "          [-6.8815e-03, -1.7941e-03, -1.1487e-02]],\n",
      "\n",
      "         [[ 3.2968e-02,  5.8415e-02,  8.3329e-03],\n",
      "          [ 1.0411e-02,  3.5860e-02,  8.3363e-03],\n",
      "          [-1.5696e-02, -1.5042e-02,  1.7315e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1141e-02,  1.5798e-02,  1.6444e-02],\n",
      "          [ 1.4905e-02,  6.3904e-03,  2.6291e-03],\n",
      "          [ 3.3458e-02,  1.3344e-02,  1.3005e-02]],\n",
      "\n",
      "         [[ 1.1242e-02,  8.7495e-03,  2.7007e-03],\n",
      "          [ 2.2816e-02,  1.4478e-02,  4.8603e-03],\n",
      "          [-3.7791e-04, -4.8188e-03, -1.1555e-02]],\n",
      "\n",
      "         [[-2.8469e-02, -2.9225e-02, -3.5925e-02],\n",
      "          [-2.3655e-02, -1.7323e-02, -2.4310e-02],\n",
      "          [-2.7181e-02, -2.8016e-02, -2.4610e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.0945e-03, -1.1648e-02, -1.8368e-03],\n",
      "          [-9.1741e-03, -1.1730e-02, -5.2244e-03],\n",
      "          [-3.2614e-04, -3.2733e-03, -1.5314e-02]],\n",
      "\n",
      "         [[-5.3404e-03,  3.1406e-03, -4.0876e-03],\n",
      "          [-1.8448e-02, -1.4205e-02, -8.0051e-03],\n",
      "          [-4.1017e-02, -1.7671e-02, -1.6075e-02]],\n",
      "\n",
      "         [[-5.0619e-03, -3.8657e-02, -1.6724e-02],\n",
      "          [ 7.7710e-03, -4.6123e-02, -3.3794e-02],\n",
      "          [ 3.0187e-02, -4.1111e-03,  4.1263e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.4440e-03,  1.4478e-02,  2.0925e-03],\n",
      "          [-1.8277e-02,  9.9649e-03, -9.6685e-03],\n",
      "          [-2.7329e-02, -9.8696e-04, -7.9309e-03]],\n",
      "\n",
      "         [[ 2.2844e-02,  3.1802e-03,  1.7223e-02],\n",
      "          [ 7.9945e-03, -1.7438e-02, -1.8138e-02],\n",
      "          [ 5.6933e-03, -1.1354e-02,  3.0347e-03]],\n",
      "\n",
      "         [[-8.3175e-03, -3.1811e-02, -2.2094e-02],\n",
      "          [ 1.4638e-05, -1.5316e-02, -1.5267e-02],\n",
      "          [-7.2670e-03, -8.0666e-03, -5.5703e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2208e-03, -4.1981e-03,  2.4875e-03],\n",
      "          [ 1.2551e-02,  3.9157e-03,  3.4247e-03],\n",
      "          [ 9.6486e-03,  1.4965e-02,  7.2044e-03]],\n",
      "\n",
      "         [[-2.3419e-02, -2.4347e-02, -1.6248e-02],\n",
      "          [-1.9058e-02, -2.2891e-02, -1.8188e-02],\n",
      "          [-6.6299e-03, -2.0042e-02, -1.3563e-02]],\n",
      "\n",
      "         [[-1.7024e-02, -2.0971e-02, -3.7842e-02],\n",
      "          [-5.2446e-03, -2.0623e-02, -2.7047e-02],\n",
      "          [ 1.4369e-02, -1.0064e-02,  7.1109e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.4927e-03,  2.8716e-02,  1.7452e-02],\n",
      "          [ 1.3738e-02,  1.8917e-02,  5.4851e-03],\n",
      "          [ 1.4782e-02,  1.0775e-02, -2.3456e-03]],\n",
      "\n",
      "         [[ 8.8791e-03,  1.1923e-02,  2.7322e-02],\n",
      "          [ 2.5228e-02,  2.2188e-02,  3.0305e-02],\n",
      "          [ 3.5736e-02,  2.4427e-02,  2.1815e-02]],\n",
      "\n",
      "         [[-5.7071e-03, -8.7913e-03, -1.3530e-02],\n",
      "          [-5.4085e-03, -1.7407e-03,  2.3131e-03],\n",
      "          [ 8.3093e-03,  4.2748e-03,  1.2303e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.5613e-03,  1.1008e-02, -7.1487e-04],\n",
      "          [ 1.0556e-02,  2.2342e-02, -1.0048e-03],\n",
      "          [-7.6637e-03,  1.4437e-03, -8.7726e-03]],\n",
      "\n",
      "         [[-1.4743e-02, -3.4066e-02, -2.0108e-02],\n",
      "          [-5.4339e-03, -1.9609e-02, -1.5343e-02],\n",
      "          [-5.1284e-03, -1.1401e-02,  1.2394e-04]],\n",
      "\n",
      "         [[-1.6594e-02, -3.8284e-02, -7.5498e-03],\n",
      "          [-1.3931e-02, -1.7271e-02, -8.3798e-03],\n",
      "          [ 2.1377e-03, -2.7655e-03, -2.0783e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3254e-03,  9.9774e-03,  1.4181e-02],\n",
      "          [ 1.7003e-02,  1.4496e-02,  1.8798e-02],\n",
      "          [ 3.4987e-02,  3.2703e-02,  4.6225e-02]],\n",
      "\n",
      "         [[-5.5553e-03,  1.6191e-03, -8.5051e-03],\n",
      "          [-1.4465e-02, -7.8599e-05,  5.5291e-04],\n",
      "          [-3.7181e-02, -3.0638e-02, -2.9953e-02]],\n",
      "\n",
      "         [[ 4.4973e-02,  2.9909e-02,  3.9455e-02],\n",
      "          [ 4.1707e-02,  2.9728e-02,  3.0226e-02],\n",
      "          [ 3.2294e-02,  3.8331e-02,  5.5640e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5318e-03, -2.5768e-03, -1.9835e-02],\n",
      "          [-3.8708e-03, -6.0238e-03, -5.2313e-03],\n",
      "          [ 5.3449e-03,  1.9162e-02,  1.5444e-02]],\n",
      "\n",
      "         [[-4.0897e-03, -2.1466e-02, -3.2437e-02],\n",
      "          [-4.8543e-03, -8.3130e-03, -1.7764e-02],\n",
      "          [-4.6017e-03, -1.2160e-02, -1.6609e-02]],\n",
      "\n",
      "         [[-1.7130e-02, -1.9588e-02, -9.0539e-03],\n",
      "          [-1.5584e-02, -2.0674e-03, -1.0101e-02],\n",
      "          [ 6.5303e-03,  3.2189e-03,  8.5852e-04]]]], device='cuda:0')), ('features.24.bias', tensor([ 1.6997e-02, -8.7523e-02, -3.9945e-02,  1.1659e-01,  7.1463e-03,\n",
      "        -8.6225e-03,  3.5613e-03,  4.1200e-02,  7.9841e-02,  9.5307e-02,\n",
      "         7.8111e-02,  3.9813e-02,  6.8257e-02, -5.2504e-02,  4.3717e-01,\n",
      "         1.4831e-01,  3.0033e-02,  2.2733e-01,  9.5732e-02,  7.6517e-03,\n",
      "         9.7672e-02, -1.1207e-01,  1.8533e-02, -1.2867e-01, -5.7986e-02,\n",
      "         1.4702e-01, -1.0547e-02, -1.6095e-01,  1.2300e-01, -1.7012e-01,\n",
      "         1.2401e-01, -7.5310e-02,  3.1701e-02,  1.7607e-01, -1.7784e-01,\n",
      "         1.0113e-01, -2.4998e-01, -1.3779e-01,  5.3955e-02, -1.2948e-01,\n",
      "         4.8545e-03,  7.3792e-02, -1.4859e-01,  9.5392e-02, -2.4602e-02,\n",
      "         8.3897e-02, -6.5401e-02, -9.7681e-02,  4.4745e-02, -1.3100e-01,\n",
      "         4.8532e-02,  3.8608e-02,  1.3137e-01,  3.8055e-02,  4.1357e-02,\n",
      "         5.1061e-02, -4.0593e-02,  2.3771e-01, -5.6327e-02,  1.6970e-01,\n",
      "         3.0759e-02, -9.6201e-02, -6.4206e-02, -1.0849e-01,  2.6529e-02,\n",
      "        -2.1004e-01,  1.0225e-01, -7.0348e-02, -1.2984e-01,  7.1541e-02,\n",
      "        -7.2142e-02, -5.5398e-03,  1.7476e-01,  5.4846e-02,  2.1085e-01,\n",
      "        -5.7996e-02,  8.2948e-02,  2.7528e-01, -1.1895e-01,  4.2671e-02,\n",
      "         1.1413e-02,  9.5554e-03,  2.7650e-02,  8.3081e-02,  1.6358e-01,\n",
      "         1.5594e-01, -3.7932e-02, -9.6472e-03,  9.2585e-02, -4.8008e-02,\n",
      "         8.2199e-02, -3.2398e-01,  1.3381e-01,  1.1170e-01, -1.5708e-01,\n",
      "        -1.2178e-01,  7.3881e-02,  1.2439e-01, -1.1057e-01, -6.7567e-02,\n",
      "         1.3011e-01, -2.2576e-02,  4.3847e-02, -3.3202e-01, -9.6008e-02,\n",
      "        -1.5401e-02, -1.4233e-01,  1.7160e-01, -8.8213e-02,  2.2654e-02,\n",
      "        -1.2759e-02,  5.1638e-02,  4.1167e-02, -8.5116e-02, -1.7608e-02,\n",
      "         7.5914e-02, -1.1214e-03,  2.1244e-01,  2.1548e-02,  1.3191e-01,\n",
      "         1.0271e-02,  7.8493e-02,  1.5120e-01, -7.0706e-03, -4.5366e-02,\n",
      "        -6.8868e-02,  1.8619e-01, -1.5458e-02, -1.9538e-03,  5.6696e-02,\n",
      "         4.0297e-01, -1.1122e-01,  3.7485e-02,  1.2393e-01,  2.6619e-01,\n",
      "        -6.0331e-03,  4.3961e-02,  1.6793e-01, -4.6771e-02, -3.8935e-02,\n",
      "        -5.1440e-02, -9.7461e-02, -9.1474e-02,  1.2764e-01,  8.3977e-02,\n",
      "         7.4843e-02,  1.4122e-01, -2.8847e-02,  3.3013e-02,  1.4290e-01,\n",
      "         1.2551e-01,  1.5431e-02, -8.2567e-02, -4.7961e-02, -5.5157e-02,\n",
      "        -2.3662e-02, -1.2304e-02, -1.6172e-02, -1.3185e-01, -3.2622e-02,\n",
      "         8.5980e-03, -1.3255e-01,  4.9817e-02, -5.2902e-02,  3.7457e-02,\n",
      "        -2.0201e-01,  6.6079e-02,  2.7192e-02,  1.5407e-01,  1.0915e-01,\n",
      "        -2.1090e-01,  1.8848e-01,  2.1473e-01,  1.8386e-02,  1.0403e-01,\n",
      "         5.9797e-03,  1.2258e-02, -1.5531e-02, -1.2297e-01,  1.2950e-01,\n",
      "         1.7972e-01,  1.2616e-01,  9.6519e-02,  9.9225e-02, -3.7133e-02,\n",
      "        -1.1575e-01,  1.5435e-02, -5.3834e-02,  1.0502e-01, -2.0073e-02,\n",
      "         2.0620e-02, -1.9642e-02,  1.3522e-01,  4.4568e-02, -7.3237e-02,\n",
      "        -1.2374e-01, -3.1722e-02, -3.6039e-02,  3.0060e-02,  6.1620e-02,\n",
      "         3.3718e-02, -1.5714e-02, -3.4826e-02, -6.0854e-02,  8.3800e-02,\n",
      "         1.8769e-02,  1.5213e-01,  8.5224e-02,  7.5792e-02,  1.0706e-01,\n",
      "        -4.2495e-01,  1.1640e-01, -2.2343e-01,  1.1909e-01, -1.2814e-01,\n",
      "         8.9582e-03,  7.0755e-02, -2.2811e-01,  9.8118e-02, -1.3672e-01,\n",
      "         1.8078e-01,  5.5584e-02,  1.8741e-01,  2.5445e-02,  1.0880e-01,\n",
      "        -5.3879e-02,  1.8954e-03,  5.9263e-03,  2.0566e-01,  3.9427e-02,\n",
      "         1.5812e-01,  1.8293e-02,  2.8056e-01,  1.1011e-01,  1.5504e-01,\n",
      "         7.5534e-02,  7.3252e-02,  1.6881e-01,  6.6641e-02,  7.8446e-02,\n",
      "        -1.9303e-02,  1.3514e-01,  3.8848e-02, -7.8715e-02, -2.4682e-02,\n",
      "         9.8971e-02,  4.4270e-02, -5.8034e-02,  1.8438e-02, -8.4324e-02,\n",
      "        -7.2090e-02,  1.8305e-01,  9.3458e-02,  5.7189e-02,  6.8233e-02,\n",
      "         6.3328e-02,  7.2164e-02,  1.5698e-02,  9.2628e-02,  3.3019e-02,\n",
      "         3.2265e-03,  8.8894e-02, -1.3000e-01,  2.7636e-03,  5.7695e-02,\n",
      "        -3.6553e-02, -1.1188e-02,  1.6168e-01,  2.4410e-01,  3.2037e-02,\n",
      "        -3.2630e-02,  4.1609e-02,  1.6842e-01,  9.4469e-02, -1.3733e-01,\n",
      "        -2.3390e-02, -1.3076e-01, -2.7256e-02,  5.3831e-02, -1.4552e-02,\n",
      "         9.6054e-02,  3.9509e-02,  9.2404e-02,  5.2597e-02,  3.3529e-02,\n",
      "         2.5394e-03,  9.1736e-02, -1.8199e-01, -4.5320e-02,  5.5710e-02,\n",
      "         4.9833e-02, -1.6775e-01,  1.2425e-01,  3.6861e-02,  9.7389e-02,\n",
      "         1.4430e-01,  1.0937e-01, -2.1108e-02,  1.1777e-01,  1.3234e-01,\n",
      "         1.4809e-01,  4.0667e-02,  3.2418e-03,  1.4640e-02, -2.7107e-01,\n",
      "         2.4108e-02,  2.8035e-02,  4.6187e-02, -8.8954e-03,  8.0967e-02,\n",
      "        -1.0782e-01, -2.7225e-01, -2.9722e-02,  1.0527e-01,  8.1967e-02,\n",
      "        -3.9744e-02, -1.6479e-02,  1.4692e-01, -4.0941e-02,  1.6848e-01,\n",
      "         1.2172e-03, -3.2054e-02, -2.5082e-02, -5.3606e-02,  6.2650e-02,\n",
      "        -1.8099e-01, -4.2285e-02, -1.1222e-01, -3.0463e-02, -7.6558e-02,\n",
      "         1.2961e-01, -6.6143e-02,  1.2919e-01, -2.2140e-01,  7.8037e-02,\n",
      "         8.3968e-03, -5.4351e-02, -5.6294e-02, -5.7976e-02,  2.6422e-02,\n",
      "         1.6429e-01,  1.9992e-02, -6.0836e-02,  4.7631e-02,  9.5938e-02,\n",
      "         9.8480e-02,  1.8134e-01, -1.5124e-01,  4.3854e-03,  1.9267e-01,\n",
      "        -3.4172e-02, -1.7238e-01,  5.9281e-02,  2.1720e-01,  3.8778e-02,\n",
      "         3.1199e-02,  3.3372e-02, -7.8134e-02, -1.0782e-01, -7.7580e-02,\n",
      "        -5.3064e-02, -2.7654e-03,  2.1045e-02, -5.0244e-02, -1.2194e-01,\n",
      "        -9.0225e-02,  1.6694e-01, -7.0426e-02, -2.5195e-01, -4.0610e-02,\n",
      "         2.0970e-01,  6.8482e-02, -1.4830e-01,  5.4409e-02, -9.6297e-02,\n",
      "         7.5046e-02,  4.1459e-02, -1.8434e-02,  5.1478e-02,  3.1844e-02,\n",
      "         7.9317e-02, -2.4072e-02, -1.9615e-03,  1.0515e-01, -3.3585e-02,\n",
      "        -9.9882e-02,  1.9406e-01, -1.6366e-01, -1.5509e-01, -9.7908e-02,\n",
      "         1.4446e-02,  1.1277e-01, -1.0612e-01,  4.6881e-02, -2.9975e-02,\n",
      "         2.2594e-01, -5.8458e-02, -1.3480e-01,  1.1511e-02,  2.8530e-02,\n",
      "         1.3362e-01,  4.2482e-02,  3.1533e-02,  1.1483e-01,  1.7400e-02,\n",
      "        -5.4461e-02,  9.5280e-02,  2.7508e-02, -1.2620e-01,  1.2727e-01,\n",
      "         2.7821e-02,  8.9579e-02,  9.6470e-03, -1.5670e-01, -9.6572e-02,\n",
      "        -2.1230e-01,  8.0168e-02,  2.3270e-01,  6.8078e-02, -4.8857e-02,\n",
      "        -5.6181e-02,  1.1939e-01,  8.5138e-02,  9.6112e-03,  1.5150e-01,\n",
      "        -2.0642e-01, -5.2131e-02,  1.7484e-01, -4.6232e-02, -1.1997e-01,\n",
      "         8.2968e-02,  3.6806e-02, -4.7271e-02, -4.3440e-02,  1.4251e-01,\n",
      "         1.0247e-01, -1.9491e-01,  4.2062e-02, -4.0442e-02,  1.0779e-01,\n",
      "         1.6921e-01,  5.9144e-02,  2.4255e-01,  4.7628e-02, -3.3757e-02,\n",
      "         1.4118e-01, -6.5160e-02,  1.2729e-01,  4.3777e-02,  4.9147e-03,\n",
      "        -3.7822e-02,  8.1458e-02,  1.0107e-01,  9.7378e-02,  1.0344e-01,\n",
      "        -2.4163e-05,  1.1313e-01, -1.9346e-01,  1.2787e-01,  2.3269e-01,\n",
      "         2.0879e-02, -2.5601e-02, -3.5052e-02,  1.7041e-01, -2.5763e-02,\n",
      "         2.3870e-02,  8.5637e-02,  7.6319e-02, -9.1085e-02, -2.7452e-01,\n",
      "        -1.0142e-01, -1.6270e-01,  1.1200e-01, -2.8779e-02,  1.1195e-01,\n",
      "        -2.2108e-02, -7.1684e-02,  5.6318e-02,  4.0374e-02, -5.7313e-02,\n",
      "         5.3727e-02, -4.0019e-02,  1.5735e-01, -7.2448e-02, -2.5735e-02,\n",
      "        -2.1199e-02,  2.0688e-01,  1.3733e-02, -1.0036e-01,  3.5409e-03,\n",
      "         6.1670e-02,  4.9499e-02,  2.2640e-03,  1.5324e-01,  1.0493e-01,\n",
      "         3.2033e-02,  8.2300e-02, -4.6450e-02, -2.3301e-02,  1.4094e-01,\n",
      "         1.8280e-02,  4.5977e-02,  8.3666e-02,  2.0596e-02,  2.5313e-02,\n",
      "         8.9128e-02,  1.4856e-01, -2.9706e-01, -7.6075e-02,  8.2314e-03,\n",
      "         7.8032e-02, -4.7001e-01], device='cuda:0')), ('features.26.weight', tensor([[[[ 5.3396e-03, -2.6011e-03,  2.0471e-03],\n",
      "          [-5.5203e-04, -5.6705e-03, -1.6622e-02],\n",
      "          [-5.3414e-03, -4.3450e-03, -1.1729e-02]],\n",
      "\n",
      "         [[ 2.8564e-02,  2.7208e-02,  3.0957e-02],\n",
      "          [ 2.9747e-02,  2.6193e-02,  3.5095e-02],\n",
      "          [ 2.9610e-02,  4.1583e-02,  3.3541e-02]],\n",
      "\n",
      "         [[-4.8096e-03,  3.1882e-03,  1.0270e-03],\n",
      "          [ 6.3651e-03,  1.7796e-02,  1.4464e-02],\n",
      "          [-2.8096e-03, -5.9703e-03,  2.8339e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8245e-03,  8.2978e-03, -4.4093e-04],\n",
      "          [ 3.4736e-04, -7.0685e-03, -1.1561e-02],\n",
      "          [-8.2451e-03, -2.0998e-02, -1.2935e-02]],\n",
      "\n",
      "         [[ 1.1445e-02,  1.9142e-02,  1.2391e-02],\n",
      "          [ 5.1714e-03,  1.4061e-02,  1.2852e-02],\n",
      "          [-2.2861e-03,  3.0864e-03,  2.8760e-03]],\n",
      "\n",
      "         [[ 4.0615e-03,  1.2981e-02,  3.9028e-03],\n",
      "          [ 1.0133e-02,  2.2851e-02,  1.2542e-02],\n",
      "          [-1.8526e-02,  4.0812e-03, -7.3445e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6611e-03,  1.6469e-02,  1.8038e-02],\n",
      "          [ 4.2513e-03,  1.3071e-02,  1.3559e-02],\n",
      "          [ 5.8119e-05, -5.8924e-03,  2.7461e-03]],\n",
      "\n",
      "         [[-1.9168e-02, -1.1762e-02, -6.3617e-03],\n",
      "          [-4.4906e-03,  5.5111e-03,  2.2184e-02],\n",
      "          [ 1.5402e-02,  3.0761e-02,  2.4692e-02]],\n",
      "\n",
      "         [[ 2.4585e-02,  1.4311e-03,  1.1614e-02],\n",
      "          [ 3.0728e-03,  3.2102e-03, -2.3297e-03],\n",
      "          [ 8.8638e-03,  2.1141e-04, -6.4401e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1725e-03, -1.5327e-02, -9.5785e-03],\n",
      "          [-3.2860e-03, -1.0098e-02, -9.1001e-03],\n",
      "          [-8.7265e-03, -1.0286e-02, -1.2795e-02]],\n",
      "\n",
      "         [[-2.2210e-03, -1.1368e-02, -1.6937e-02],\n",
      "          [-4.1622e-03, -1.7335e-02, -1.9301e-02],\n",
      "          [ 1.7208e-02, -5.8893e-03, -3.5251e-03]],\n",
      "\n",
      "         [[ 4.2934e-04, -3.1749e-02, -1.1264e-02],\n",
      "          [-1.3598e-02, -2.6306e-02, -1.2232e-02],\n",
      "          [-1.0754e-02, -6.1461e-03,  1.9349e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.4869e-03, -1.0894e-02, -2.3739e-02],\n",
      "          [ 1.2003e-02, -4.4158e-03, -2.6271e-02],\n",
      "          [ 1.0297e-02, -1.4211e-02, -2.0285e-02]],\n",
      "\n",
      "         [[-7.8340e-03, -2.3295e-02, -2.0594e-02],\n",
      "          [-4.7429e-03, -1.5618e-02, -1.8468e-02],\n",
      "          [ 2.5025e-03, -1.0162e-02,  2.7711e-03]],\n",
      "\n",
      "         [[ 8.0493e-03, -1.5987e-02,  4.0480e-03],\n",
      "          [ 5.0285e-04, -1.5592e-02, -9.4860e-04],\n",
      "          [ 1.8756e-03, -1.6222e-03,  2.6918e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.0127e-03, -4.9466e-03,  9.5168e-03],\n",
      "          [-5.3006e-03, -7.0202e-03,  6.6488e-03],\n",
      "          [ 2.5722e-03, -5.2046e-03,  7.1014e-04]],\n",
      "\n",
      "         [[-2.1340e-02, -1.3918e-02, -1.2257e-02],\n",
      "          [-1.9682e-02, -2.2466e-02, -1.6505e-02],\n",
      "          [ 1.6370e-03, -1.8450e-03, -1.6151e-02]],\n",
      "\n",
      "         [[-6.9218e-03, -9.6376e-03, -6.8654e-03],\n",
      "          [-2.6699e-02, -8.4984e-03, -1.5467e-02],\n",
      "          [-2.1957e-02, -3.2741e-03, -1.0307e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-9.1366e-03, -6.9445e-03, -1.6918e-03],\n",
      "          [-1.4680e-02, -7.3195e-03, -1.8997e-03],\n",
      "          [-1.7819e-02, -6.0907e-03, -3.8606e-03]],\n",
      "\n",
      "         [[-2.6625e-03, -4.5790e-03, -5.2848e-03],\n",
      "          [ 2.7805e-03,  1.2579e-02, -3.2661e-03],\n",
      "          [ 1.6539e-02,  1.5941e-02,  2.5934e-03]],\n",
      "\n",
      "         [[-1.7372e-02, -1.5669e-02, -1.7184e-02],\n",
      "          [-1.0523e-02, -8.0881e-03, -3.5002e-03],\n",
      "          [ 2.0012e-02,  1.3992e-02,  2.2567e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8450e-03,  1.4391e-03, -4.8037e-03],\n",
      "          [ 3.1779e-03, -2.1945e-03, -1.8111e-03],\n",
      "          [-8.2320e-04, -5.2492e-03,  5.9751e-03]],\n",
      "\n",
      "         [[-1.8042e-02, -1.9381e-02, -2.0262e-02],\n",
      "          [-1.2160e-02, -1.6965e-02, -1.1955e-02],\n",
      "          [-1.2115e-02, -2.2049e-02, -7.6491e-03]],\n",
      "\n",
      "         [[-1.5930e-02, -1.5632e-02, -1.4184e-02],\n",
      "          [-2.6613e-02, -2.4581e-02, -2.5748e-02],\n",
      "          [-4.3730e-02, -2.4319e-02, -3.5868e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5428e-02,  1.7873e-02,  3.8022e-03],\n",
      "          [ 3.0997e-02,  2.7097e-02,  1.3571e-02],\n",
      "          [ 4.2717e-02,  3.4481e-02,  1.6175e-02]],\n",
      "\n",
      "         [[-1.5489e-02, -5.0627e-03,  1.2652e-03],\n",
      "          [-1.0676e-02, -1.4705e-04,  6.0551e-03],\n",
      "          [-1.5833e-02, -1.6241e-02, -8.2176e-03]],\n",
      "\n",
      "         [[ 5.4370e-03, -9.6808e-03, -1.1396e-02],\n",
      "          [ 8.2531e-03,  3.7010e-03,  1.4806e-02],\n",
      "          [ 2.5946e-02,  3.4422e-02,  2.8250e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0576e-02,  4.6424e-02,  6.3164e-03],\n",
      "          [ 2.3792e-02,  3.9974e-02,  1.2829e-02],\n",
      "          [-2.2258e-02, -1.0163e-02, -2.6070e-02]],\n",
      "\n",
      "         [[ 3.2659e-02,  3.8465e-02,  5.0303e-02],\n",
      "          [ 1.5540e-02,  2.3043e-02,  2.1985e-02],\n",
      "          [ 6.8735e-04, -1.1371e-02, -8.7360e-03]],\n",
      "\n",
      "         [[-2.5060e-02, -2.7326e-02, -2.7092e-02],\n",
      "          [-1.7381e-02, -2.3803e-02, -2.5497e-02],\n",
      "          [-3.5137e-02, -3.5637e-02, -4.1381e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4722e-03,  2.6112e-02,  1.4285e-02],\n",
      "          [ 1.5717e-02,  1.4589e-02,  1.0102e-02],\n",
      "          [ 3.1282e-04,  1.3287e-02, -1.4117e-03]],\n",
      "\n",
      "         [[-3.0626e-02, -1.7090e-02, -1.8398e-02],\n",
      "          [-1.3602e-02, -1.3641e-02, -1.7517e-05],\n",
      "          [-4.3749e-03, -1.6990e-02, -5.9113e-03]],\n",
      "\n",
      "         [[ 3.5263e-02,  6.0833e-02,  4.4315e-02],\n",
      "          [ 2.2339e-02,  6.8715e-02,  2.7959e-02],\n",
      "          [-3.1752e-03,  2.2407e-02,  1.5560e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.8860e-04, -3.1928e-03,  1.3426e-02],\n",
      "          [-3.6923e-03, -3.4468e-03,  3.3096e-02],\n",
      "          [-1.2766e-02, -1.6451e-02,  8.1307e-03]],\n",
      "\n",
      "         [[-7.9840e-03,  3.2893e-02,  4.4818e-02],\n",
      "          [ 1.8329e-02,  3.8900e-02,  3.9412e-02],\n",
      "          [-1.0024e-02,  5.2262e-03, -1.6413e-03]],\n",
      "\n",
      "         [[ 7.7319e-03,  1.6902e-02, -3.2354e-03],\n",
      "          [ 6.6349e-03, -1.1266e-02,  1.1672e-03],\n",
      "          [ 3.5068e-03,  2.4610e-03,  4.2446e-02]]]], device='cuda:0')), ('features.26.bias', tensor([-1.8666e-03,  5.7095e-02,  2.9342e-01, -4.1835e-02, -1.4559e-01,\n",
      "         9.7580e-02,  2.3287e-03, -4.6849e-02, -1.1053e-01,  3.6631e-02,\n",
      "        -2.3670e-02,  1.9662e-01,  6.2942e-03,  1.0368e-01, -1.2430e-01,\n",
      "        -5.5525e-02,  1.0667e-01,  2.8836e-01,  7.5442e-02,  4.5309e-02,\n",
      "         7.1352e-02,  9.4569e-02, -1.0453e-01, -3.0553e-01, -1.4769e-01,\n",
      "         1.5424e-01, -3.6026e-02, -1.6674e-02,  5.0073e-02, -1.0362e-01,\n",
      "         1.6252e-01,  3.6867e-02, -5.6979e-02, -8.1772e-02,  2.0144e-01,\n",
      "         7.0015e-02, -2.2859e-01,  1.3822e-01,  2.6113e-01,  2.1136e-02,\n",
      "         1.0234e-01,  8.6473e-02,  6.1111e-02,  7.2767e-02,  6.9773e-03,\n",
      "        -4.2054e-02,  1.0137e-01,  1.8389e-01,  9.8832e-02,  2.6407e-01,\n",
      "         5.3378e-02,  1.6710e-01,  2.5089e-01,  1.1613e-01,  2.1970e-01,\n",
      "         1.3894e-01, -4.7889e-02, -9.7952e-02,  1.0368e-01,  1.6410e-01,\n",
      "         1.9025e-01,  7.4526e-02,  2.2013e-01,  9.4355e-02, -4.7882e-02,\n",
      "         4.6833e-02, -3.9320e-03,  1.8785e-01, -2.2729e-02,  1.4750e-01,\n",
      "         1.4188e-01,  1.8834e-01,  2.4944e-02,  2.1748e-01,  1.0304e-01,\n",
      "         1.5125e-01,  1.7675e-01,  6.0383e-02,  1.6431e-01,  3.4881e-02,\n",
      "         3.8004e-02, -6.8401e-02,  6.2248e-03,  1.3423e-02, -1.3956e-01,\n",
      "         7.8097e-02,  1.9550e-01, -1.2594e-01,  9.6037e-02, -2.0711e-03,\n",
      "         6.9357e-02, -1.6091e-01,  8.9944e-02,  2.5616e-01, -9.8200e-02,\n",
      "         2.6589e-01, -2.3143e-02, -1.7001e-01, -2.4942e-04,  2.9673e-02,\n",
      "         1.0278e-01,  1.5479e-01,  1.9948e-01, -2.8051e-01,  1.0574e-01,\n",
      "         7.8208e-02,  6.1702e-02,  7.9237e-02,  1.7736e-03, -9.6903e-02,\n",
      "         2.1890e-01, -3.3631e-02,  3.0116e-02,  2.6728e-01,  7.2655e-02,\n",
      "         3.8347e-02,  4.4684e-02,  2.9473e-01,  2.6413e-02,  2.6462e-01,\n",
      "         2.2294e-01, -1.7687e-01,  1.4487e-01,  2.5277e-01,  9.5677e-02,\n",
      "         7.3535e-02,  1.2854e-01,  3.4688e-01,  1.1824e-01,  3.1590e-01,\n",
      "        -8.2523e-02, -2.8264e-01,  2.5187e-01, -4.4773e-02,  8.9053e-02,\n",
      "         2.1587e-03,  1.8896e-01,  1.6210e-01, -1.9770e-01,  1.5449e-01,\n",
      "        -1.7553e-02, -1.6512e-02,  1.8990e-01,  6.1404e-02,  1.6946e-01,\n",
      "        -2.7088e-02,  5.3145e-02,  1.0964e-01,  1.3800e-01,  6.7332e-02,\n",
      "        -5.0629e-03, -1.7180e-01,  7.6077e-02, -1.2958e-02,  1.3120e-01,\n",
      "        -8.2870e-02,  1.0818e-01,  1.1670e-01,  1.9102e-01, -2.6032e-01,\n",
      "         1.2425e-01, -6.4174e-01, -9.4544e-02,  1.4883e-01, -2.2177e-02,\n",
      "         1.9388e-01,  2.2708e-01, -3.0475e-02,  4.3636e-02,  2.5054e-02,\n",
      "         4.8016e-02,  2.4943e-01,  8.6237e-02,  9.5355e-03,  6.0247e-03,\n",
      "         1.5412e-01,  1.5840e-01,  1.3796e-01, -1.2680e-01,  1.3226e-01,\n",
      "         4.6432e-02,  2.2256e-01,  2.6363e-01, -3.5001e-03,  1.8687e-01,\n",
      "        -3.5546e-02,  2.9883e-04,  7.7087e-02,  7.4261e-02,  1.9941e-01,\n",
      "        -2.8899e-02,  2.8666e-02,  2.2292e-03,  6.0504e-02,  1.2704e-01,\n",
      "        -1.9055e-01,  1.4168e-01,  5.8124e-02,  2.5609e-02,  1.1290e-01,\n",
      "         3.1867e-01, -6.8704e-02,  2.2565e-01,  1.5933e-01,  3.9752e-02,\n",
      "         1.2825e-01,  1.4174e-01,  4.1308e-01,  4.6752e-02,  1.2245e-01,\n",
      "         2.1968e-01,  4.9856e-02,  7.1631e-02, -3.9455e-02, -2.3028e-01,\n",
      "         1.3458e-01, -4.2816e-02,  1.5429e-02, -6.6889e-01,  1.6270e-01,\n",
      "         2.2208e-02, -1.7758e-01,  1.2783e-01,  2.1327e-02, -5.5212e-01,\n",
      "         2.6010e-01,  8.0355e-02,  9.4295e-02, -7.3130e-02,  1.6812e-01,\n",
      "         5.4281e-02,  1.4536e-01,  1.9376e-01,  3.5577e-01,  5.1165e-02,\n",
      "         2.2360e-01,  2.3526e-01,  1.6229e-01,  9.5042e-03, -2.0074e-01,\n",
      "         1.4703e-02, -2.0507e-01,  1.5991e-01, -1.1455e-01,  2.4596e-01,\n",
      "         6.5557e-02,  1.0167e-01, -8.4635e-02, -3.6976e-01,  1.2340e-03,\n",
      "        -5.0580e-02,  8.3523e-02, -2.8552e-01,  1.3614e-01,  1.2556e-01,\n",
      "         2.7155e-01, -1.1871e-01,  1.4263e-02,  8.3877e-02, -2.1675e-02,\n",
      "        -1.0315e-01,  4.0777e-02,  1.6204e-02, -6.4240e-02, -8.4088e-03,\n",
      "         1.0339e-01, -3.2666e-02, -7.4288e-02, -5.5998e-02,  1.3324e-01,\n",
      "        -1.2704e-01,  2.5314e-01,  2.7311e-01, -7.6727e-02,  1.6360e-01,\n",
      "         1.4462e-01,  4.8776e-02,  1.2075e-01, -3.1966e-01,  6.8700e-02,\n",
      "        -3.0422e-01,  5.1718e-02,  6.9389e-02, -5.4538e-03,  1.4129e-01,\n",
      "        -2.4315e-01,  1.3872e-01,  7.0531e-02, -1.9635e-01,  2.3215e-01,\n",
      "         5.3497e-02,  1.2996e-01,  2.3196e-01,  5.3783e-02, -3.2011e-01,\n",
      "         9.7505e-02,  6.9466e-02,  1.2734e-01, -6.5295e-02,  1.3896e-01,\n",
      "         9.7967e-02,  3.6168e-03, -4.9335e-02,  2.2809e-01, -1.8391e-01,\n",
      "         8.4771e-02, -4.9345e-02,  3.6355e-02, -1.4925e-02, -3.3247e-02,\n",
      "        -2.8801e-02,  7.3432e-02,  1.0934e-01,  2.1105e-01,  7.4307e-02,\n",
      "        -3.3863e-02, -9.7055e-03, -4.4074e-02,  5.2093e-02,  7.3870e-02,\n",
      "         2.2864e-01,  4.4315e-01, -2.6606e-01,  2.4656e-01,  8.8123e-03,\n",
      "         2.6059e-01,  2.6270e-02,  4.9199e-03, -2.0948e-02,  2.3407e-01,\n",
      "         4.6750e-02, -1.8637e-01, -6.0074e-02,  1.9932e-02,  1.2411e-01,\n",
      "         6.9108e-02,  8.7628e-02,  6.0595e-02,  1.9305e-02,  7.3282e-03,\n",
      "         2.7907e-01,  1.5810e-01,  1.4193e-01,  7.2068e-02,  1.2330e-01,\n",
      "         2.2972e-01,  3.7316e-02,  2.7085e-01,  2.6735e-01,  2.9073e-01,\n",
      "        -1.2664e-01, -1.7979e-01,  1.4586e-01, -1.6734e-01,  3.0067e-01,\n",
      "         5.5059e-02,  3.3035e-02, -1.1998e-01,  9.2903e-02,  1.1212e-01,\n",
      "         3.7626e-03,  1.4395e-01,  6.1938e-02, -1.2140e-02, -6.1718e-02,\n",
      "         2.5250e-01,  1.3300e-01,  1.6234e-01,  8.2953e-02,  2.6083e-02,\n",
      "         1.3916e-01,  2.0513e-01,  6.7912e-04, -1.7945e-01,  1.5764e-01,\n",
      "        -3.8579e-02, -1.9392e-02,  1.2502e-01,  2.6850e-01,  1.0506e-01,\n",
      "         5.5868e-03,  1.6505e-02,  6.3682e-03,  8.1427e-02,  6.6729e-02,\n",
      "         5.5360e-02,  8.7517e-02, -4.0046e-02,  1.6139e-01,  7.1919e-02,\n",
      "        -5.6358e-03,  2.1568e-01, -7.4366e-02,  5.8069e-02,  2.6335e-01,\n",
      "         2.8281e-02,  2.4417e-01,  2.4759e-01, -2.9013e-02,  3.2379e-01,\n",
      "         1.6893e-01,  1.3746e-01, -1.0394e-01,  9.3580e-02, -5.1710e-02,\n",
      "         3.5181e-02,  1.4746e-01,  5.3799e-02,  4.1372e-02,  1.6984e-01,\n",
      "         1.4468e-01, -1.4703e-01,  6.0515e-02,  6.3167e-02,  1.2524e-01,\n",
      "         5.3194e-02,  7.6026e-02,  1.0579e-01,  9.8491e-02,  1.9020e-01,\n",
      "         5.5204e-02,  3.1727e-01, -5.2387e-02,  1.3097e-01,  8.2818e-03,\n",
      "         2.9184e-01,  5.8782e-02, -5.1021e-02, -4.2194e-02, -1.1820e-02,\n",
      "        -1.4751e-02,  1.3293e-02, -5.1917e-02,  8.3116e-03,  5.2255e-02,\n",
      "        -7.9446e-02,  1.5422e-01,  5.6511e-02, -1.6342e-01, -2.6140e-02,\n",
      "        -1.4222e-01,  1.4183e-01,  1.5884e-02, -3.7037e-01,  1.0357e-01,\n",
      "        -2.5953e-02,  2.1196e-03,  1.2330e-01, -2.9095e-01,  4.5272e-01,\n",
      "         1.1890e-02,  5.3951e-02,  1.3336e-01,  1.4885e-01, -2.5333e-01,\n",
      "         2.7634e-01,  1.9910e-01,  7.1031e-02, -4.5542e-02,  4.1901e-01,\n",
      "         2.3511e-02,  9.1463e-02,  2.2576e-01, -7.0693e-02,  9.5964e-02,\n",
      "         3.7641e-02,  3.4062e-02,  7.1019e-02,  3.3747e-02, -7.6930e-02,\n",
      "         6.1839e-02,  9.1188e-02,  2.7430e-01,  7.1650e-02,  2.7827e-02,\n",
      "         2.2714e-01,  9.9219e-02,  1.3663e-01,  1.4738e-01,  1.8030e-01,\n",
      "         6.9251e-02,  2.0696e-02,  2.6268e-02,  7.3633e-02,  2.6631e-03,\n",
      "         3.2248e-02,  2.3134e-01,  7.9280e-02,  5.9423e-02, -2.7435e-01,\n",
      "         1.0282e-01, -3.1731e-01,  1.0250e-01,  7.7823e-02,  7.4229e-02,\n",
      "         2.7291e-01,  2.0422e-01,  2.9676e-01,  1.1259e-01,  4.3181e-01,\n",
      "         6.7201e-04,  1.2159e-02, -1.0741e-01, -1.4713e-01,  1.4593e-01,\n",
      "         5.3302e-02,  2.0966e-01,  7.4471e-02,  1.6401e-01,  8.4423e-02,\n",
      "         2.0856e-01, -1.4974e+00], device='cuda:0')), ('features.28.weight', tensor([[[[ 2.7768e-02,  1.5296e-02,  2.1911e-02],\n",
      "          [ 2.5202e-02,  2.3223e-02,  2.0005e-02],\n",
      "          [ 3.0154e-02,  8.7023e-03,  1.7728e-02]],\n",
      "\n",
      "         [[-1.0682e-02, -9.5476e-03, -9.1195e-03],\n",
      "          [-3.5036e-03, -1.2508e-02, -1.4557e-02],\n",
      "          [-1.3689e-02, -1.8028e-02, -2.1646e-02]],\n",
      "\n",
      "         [[-8.5565e-03, -7.2054e-03, -6.3846e-03],\n",
      "          [ 2.0408e-03, -2.1947e-03, -6.8919e-04],\n",
      "          [-1.6638e-03, -9.0286e-04,  4.9448e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4711e-03,  3.3385e-03,  2.6684e-03],\n",
      "          [-9.6592e-03, -1.1543e-02, -8.2975e-03],\n",
      "          [ 3.4230e-03,  5.5182e-03,  1.2600e-02]],\n",
      "\n",
      "         [[-6.8517e-03, -4.8486e-03, -8.5124e-03],\n",
      "          [ 1.0570e-03,  1.1698e-02, -1.0812e-03],\n",
      "          [ 6.2322e-03,  7.0932e-04, -1.5733e-03]],\n",
      "\n",
      "         [[-2.1647e-02,  2.5883e-03,  1.1418e-02],\n",
      "          [-2.7891e-02,  1.8448e-03,  1.1855e-02],\n",
      "          [-1.2538e-02, -1.8912e-03,  9.2639e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1915e-02, -2.5141e-02, -5.7179e-03],\n",
      "          [-1.0882e-02, -2.0027e-02, -1.1911e-02],\n",
      "          [-1.1790e-02, -2.5523e-03, -9.7380e-03]],\n",
      "\n",
      "         [[ 4.7855e-03,  1.2190e-02,  2.7961e-03],\n",
      "          [ 1.0504e-03,  1.1996e-02,  4.9763e-03],\n",
      "          [-8.5489e-03,  7.1493e-03, -1.0951e-03]],\n",
      "\n",
      "         [[ 2.2856e-02, -2.7013e-04, -1.2531e-02],\n",
      "          [ 2.3324e-02, -4.0162e-03, -6.5110e-03],\n",
      "          [ 2.1377e-02, -8.4313e-03, -1.5131e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5753e-03, -9.9031e-03, -8.8476e-03],\n",
      "          [-5.7730e-03, -5.1446e-04, -7.1723e-03],\n",
      "          [-2.2436e-02, -9.8933e-03, -1.9306e-02]],\n",
      "\n",
      "         [[ 2.5404e-03,  8.9606e-03, -5.4400e-03],\n",
      "          [ 1.3366e-02,  2.0605e-02,  6.6010e-03],\n",
      "          [ 1.8054e-02,  3.1267e-02,  2.4730e-02]],\n",
      "\n",
      "         [[-1.4774e-03,  1.2404e-02,  8.4087e-03],\n",
      "          [ 1.2018e-02,  1.7658e-02,  1.7988e-02],\n",
      "          [-3.6130e-04,  1.8112e-02,  1.8274e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.2360e-03,  7.4191e-04,  2.9408e-03],\n",
      "          [ 2.4742e-03, -4.0349e-03, -2.9401e-03],\n",
      "          [-1.5432e-03, -5.3605e-03, -5.8344e-03]],\n",
      "\n",
      "         [[-1.3595e-02, -3.1718e-02, -2.3710e-02],\n",
      "          [-2.1746e-02, -2.5402e-02, -2.3455e-02],\n",
      "          [-1.5045e-02, -3.1418e-02, -2.8699e-02]],\n",
      "\n",
      "         [[ 3.2991e-03, -4.9208e-03,  1.4358e-03],\n",
      "          [-7.7625e-04,  6.4103e-03,  3.9225e-03],\n",
      "          [ 1.0592e-02,  5.9198e-03,  1.5063e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8337e-03, -1.5062e-02, -1.1133e-02],\n",
      "          [ 4.8897e-03,  3.7414e-03, -6.6763e-03],\n",
      "          [ 1.0834e-02,  1.6787e-02,  6.9389e-03]],\n",
      "\n",
      "         [[-2.0545e-02, -2.2203e-02, -1.7161e-02],\n",
      "          [-2.5112e-02, -3.0551e-02, -1.5765e-02],\n",
      "          [-2.4664e-02, -2.2903e-02, -5.8698e-03]],\n",
      "\n",
      "         [[-3.2173e-02, -2.9189e-02, -8.3404e-03],\n",
      "          [-2.5504e-02, -1.6742e-02,  1.7872e-03],\n",
      "          [-3.1295e-02, -1.2420e-02,  1.1523e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.9429e-02, -2.4556e-02, -1.7622e-02],\n",
      "          [-3.5300e-02, -3.0947e-02, -2.4672e-02],\n",
      "          [-2.4305e-02, -2.5179e-02, -7.1441e-03]],\n",
      "\n",
      "         [[ 2.9619e-02,  1.2602e-02, -1.9829e-02],\n",
      "          [ 9.1760e-03, -8.5109e-04, -3.0802e-02],\n",
      "          [-2.7310e-03, -1.7747e-02, -3.2944e-02]],\n",
      "\n",
      "         [[-3.7120e-03, -1.0129e-02,  1.1997e-02],\n",
      "          [-5.0915e-03, -1.4651e-02,  1.0667e-02],\n",
      "          [-4.8322e-03, -9.9947e-03,  1.8547e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4648e-02, -1.5231e-02,  1.0567e-03],\n",
      "          [-8.6118e-03, -3.1389e-02, -1.3612e-02],\n",
      "          [-1.7457e-02, -1.7559e-02, -1.1778e-02]],\n",
      "\n",
      "         [[-1.4624e-02, -8.1732e-03, -2.6069e-03],\n",
      "          [-1.8911e-02, -2.5938e-02, -1.7402e-02],\n",
      "          [-3.9192e-03, -1.7547e-02, -2.6254e-02]],\n",
      "\n",
      "         [[-5.1161e-02, -1.9841e-02,  1.4722e-02],\n",
      "          [-4.5486e-02, -1.1310e-02,  1.3356e-02],\n",
      "          [-5.4183e-02, -2.0307e-02, -2.4845e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.0532e-03, -1.0636e-02,  7.1217e-04],\n",
      "          [ 1.4047e-02,  1.0330e-02,  1.1886e-02],\n",
      "          [ 1.9057e-02,  7.6312e-03,  1.1955e-02]],\n",
      "\n",
      "         [[-5.0939e-04,  2.6748e-03,  3.8110e-03],\n",
      "          [-1.6356e-02, -2.5871e-03, -9.2277e-03],\n",
      "          [-5.9132e-03, -3.3246e-03, -2.0477e-02]],\n",
      "\n",
      "         [[ 1.0108e-03,  1.5062e-02,  2.3413e-02],\n",
      "          [ 4.2264e-05,  6.6031e-03,  3.2643e-02],\n",
      "          [-2.8598e-03,  4.1518e-03,  2.0333e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1414e-03, -6.4583e-03, -1.4588e-02],\n",
      "          [-1.0115e-02, -1.0200e-02, -2.1285e-02],\n",
      "          [-6.3856e-03, -7.5624e-03, -2.0476e-02]],\n",
      "\n",
      "         [[-1.0839e-02,  6.7214e-03,  5.8918e-03],\n",
      "          [-9.5600e-04,  1.6651e-03,  7.1670e-03],\n",
      "          [-1.8902e-02, -7.4955e-03, -9.8708e-04]],\n",
      "\n",
      "         [[-4.4182e-02, -2.7011e-02, -1.5440e-02],\n",
      "          [-4.1249e-02, -2.9579e-02, -1.0295e-02],\n",
      "          [-1.9288e-02, -9.9171e-03,  5.1636e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9454e-02, -2.0776e-02, -1.4369e-02],\n",
      "          [-8.1482e-03, -1.6480e-02, -1.4024e-02],\n",
      "          [-8.4481e-03, -2.4206e-02, -1.5236e-02]],\n",
      "\n",
      "         [[ 5.7170e-03,  1.4719e-02,  8.7575e-03],\n",
      "          [ 7.4073e-03, -8.5165e-03, -1.1737e-02],\n",
      "          [-2.1247e-03, -1.4506e-02, -1.4657e-02]],\n",
      "\n",
      "         [[ 3.0560e-02,  4.0275e-02,  5.0865e-02],\n",
      "          [-2.9477e-03,  2.0548e-02,  4.3352e-02],\n",
      "          [-1.6921e-02,  4.7982e-03,  2.1169e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9884e-02, -2.8676e-02, -1.7745e-02],\n",
      "          [-1.8820e-02, -2.7692e-02, -3.7976e-02],\n",
      "          [-7.1567e-03, -1.6576e-02, -6.9290e-03]],\n",
      "\n",
      "         [[-3.3155e-03, -8.4667e-03,  4.0157e-03],\n",
      "          [ 1.9905e-02, -1.0356e-02, -4.5904e-04],\n",
      "          [ 3.1526e-02,  1.0053e-02,  1.1222e-02]],\n",
      "\n",
      "         [[-2.6271e-02, -8.1591e-03, -2.9560e-02],\n",
      "          [-3.3923e-02, -2.4079e-02, -2.2005e-02],\n",
      "          [-3.4229e-02, -2.6150e-02, -1.4213e-02]]]], device='cuda:0')), ('features.28.bias', tensor([ 1.2299e-01,  1.9062e-02,  2.3202e-01,  5.8209e-02,  1.6951e-01,\n",
      "         9.3987e-02,  1.5288e-01,  3.5992e-02, -1.0673e-02,  4.5524e-02,\n",
      "        -3.5247e-02,  2.5516e-02,  3.7165e-01,  7.4319e-02, -5.5337e-02,\n",
      "         1.8086e-01,  9.7370e-03,  2.6187e-01,  1.8216e-01,  8.2105e-02,\n",
      "         1.6739e-01,  1.6799e-02, -7.1030e-02,  2.5600e-01,  1.1929e-01,\n",
      "        -6.0356e-02, -7.9072e-02,  2.1399e-02,  1.5857e-01,  1.0256e-01,\n",
      "         1.5698e-01,  1.0011e-01, -3.1958e-02,  1.2926e-01,  6.9638e-02,\n",
      "        -6.4992e-02, -2.9777e-02,  1.4160e-01,  1.9333e-01, -5.3614e-02,\n",
      "         1.7314e-02,  3.4937e-01,  5.4955e-01,  5.8277e-02,  1.8567e-01,\n",
      "        -5.6476e-02,  5.7856e-02, -3.3354e-01,  1.4938e-01, -4.4627e-02,\n",
      "         2.2324e-01, -1.3016e-01,  6.6589e-03,  1.7766e-01,  6.1969e-02,\n",
      "        -2.4899e-01,  7.3821e-02,  9.5302e-02,  1.0045e-02, -5.1411e-02,\n",
      "         1.2429e-01,  1.0792e-01, -4.1483e-02,  9.6371e-02, -1.0660e-01,\n",
      "         7.5465e-02,  2.5620e-01,  1.4411e-01, -2.2501e-02,  1.0363e-01,\n",
      "         7.0449e-02,  1.1813e-01,  3.5013e-02, -1.6152e-01,  7.5051e-02,\n",
      "         1.4182e-01,  2.1379e-01,  4.5386e-02,  2.3022e-01,  1.0673e-01,\n",
      "        -2.7411e-01, -8.0965e-03,  1.5953e-01,  1.0124e-01,  1.3451e-01,\n",
      "         6.2137e-02, -6.4873e-02,  5.2526e-02,  7.6597e-02,  4.9359e-02,\n",
      "         6.2304e-02, -3.2635e-02, -4.7491e-02,  1.3554e-01, -1.8428e-02,\n",
      "         6.4935e-03,  3.0955e-02,  3.1089e-01,  7.0068e-02, -1.8541e-02,\n",
      "        -1.3481e-01, -1.2601e-01,  1.9559e-01,  3.4075e-02,  1.6061e-01,\n",
      "         5.2857e-02,  7.6637e-02,  2.2150e-01,  3.9940e-02,  6.1567e-02,\n",
      "         7.4801e-02,  1.4435e-01, -6.7993e-02, -2.0014e-01,  3.0571e-01,\n",
      "        -4.5313e-02,  2.4059e-01,  5.3480e-01,  1.7807e-01,  4.9351e-01,\n",
      "         7.4024e-03,  3.5002e-02,  2.4675e-01,  3.1102e-01,  5.3972e-02,\n",
      "         1.4723e-01, -2.9065e-02,  4.0776e-01,  1.9019e-01, -6.0330e-02,\n",
      "        -1.7002e-02,  2.4975e-01,  2.1960e-01,  3.6960e-01,  3.0740e-02,\n",
      "         4.3709e-01,  8.8497e-02, -2.7574e-01, -6.6411e-03,  1.4975e-01,\n",
      "         1.9137e-01,  1.3468e-01,  1.9793e-02,  7.0597e-02, -1.0223e-04,\n",
      "         6.3679e-02,  6.4095e-02, -4.9774e-02,  1.3181e-01,  1.3314e-01,\n",
      "        -1.1899e-02, -3.5992e-03, -7.3270e-02,  1.5903e-02,  2.0310e-02,\n",
      "         1.2016e-01,  1.5365e-01, -1.3392e-01,  2.9884e-01,  6.2440e-02,\n",
      "         2.6438e-01,  6.6528e-02,  2.2115e-02, -6.3780e-02,  1.2955e-01,\n",
      "        -1.1588e-01,  1.5341e-02,  1.8381e-01, -7.1448e-02,  6.3515e-02,\n",
      "         7.3416e-02,  3.3285e-01,  2.4135e-01,  1.2293e-01, -3.6733e-02,\n",
      "        -2.2642e-01,  9.4244e-02,  6.4020e-02,  6.4169e-02,  1.6127e-01,\n",
      "         1.1205e-01,  2.3402e-01,  4.0610e-02, -1.0696e-01, -8.1177e-02,\n",
      "         6.2745e-02, -2.9593e-02,  9.2280e-02, -9.8356e-02,  4.2653e-02,\n",
      "        -7.1865e-02,  7.6488e-02,  2.9805e-02,  1.6318e-01,  2.2079e-01,\n",
      "         2.2230e-01, -5.1637e-04,  7.1988e-02, -4.2184e-03,  2.3270e-01,\n",
      "         2.0941e-01,  7.9699e-02, -8.6314e-02,  1.7086e-02,  5.4669e-02,\n",
      "        -8.9527e-03,  5.0897e-01,  7.7975e-03,  1.8228e-01,  6.4333e-02,\n",
      "         7.2739e-01,  4.5106e-02,  1.4373e-01, -3.7722e-02, -5.4909e-02,\n",
      "        -1.2010e-02,  2.0435e-01,  1.7225e-01,  4.0681e-02,  1.9134e-02,\n",
      "         6.2492e-02,  1.3200e-02,  1.3521e-01,  8.0993e-02,  9.5284e-02,\n",
      "         2.5035e-01, -2.1631e-02,  4.1494e-02,  3.2249e-02,  1.2096e-01,\n",
      "        -4.0207e-03,  4.0679e-02,  3.6975e-01,  1.5898e-02, -2.2886e-02,\n",
      "         2.4626e-02, -2.7666e-01, -2.3504e-02,  1.0643e-01, -1.2430e-02,\n",
      "         1.7485e-01,  5.4469e-02,  8.5420e-02,  1.9319e-01,  9.9808e-02,\n",
      "         4.6577e-02,  2.5018e-01,  1.4844e-01,  2.0588e-01, -3.0332e-03,\n",
      "         2.9574e-02,  1.3161e-01,  2.5354e-02,  1.0219e-01,  1.3147e-01,\n",
      "        -7.8081e-02,  2.3178e-02, -1.8245e-01, -2.0426e-02,  5.6247e-02,\n",
      "         2.0667e-02, -1.6488e-01, -1.0449e-01, -2.4995e-02, -1.4024e-02,\n",
      "         1.5887e-02,  1.3549e-01,  1.7865e-01,  6.9024e-02,  2.0019e-01,\n",
      "         8.3336e-02,  2.3189e-01,  1.1164e-01,  5.2018e-02,  5.4957e-02,\n",
      "         8.3962e-03,  3.8536e-02,  1.2274e-01,  1.1808e-01,  4.2507e-01,\n",
      "         9.5482e-02, -2.2675e-02,  7.5627e-02,  1.8008e-01, -1.0889e-01,\n",
      "         4.2092e-02,  1.9957e-01, -2.4369e-01, -2.8168e-02,  4.5333e-02,\n",
      "         4.4138e-02,  3.6140e-01, -4.1163e-02,  1.2387e-01,  3.3204e-02,\n",
      "         2.3844e-01, -1.0794e-02,  6.9760e-02,  1.5946e-01,  8.4266e-02,\n",
      "         5.7439e-02, -4.1239e-02, -5.9942e-02,  1.3035e-02, -3.6432e-02,\n",
      "        -5.6892e-02,  9.5882e-02, -1.7123e-01,  1.8914e-01,  1.2670e-01,\n",
      "        -4.2537e-02, -1.0869e-02,  5.0380e-02,  1.9144e-01,  2.9454e-01,\n",
      "        -5.7837e-02,  9.6131e-02,  1.9973e-01,  6.1776e-02,  2.4677e-01,\n",
      "         2.4367e-01, -3.3549e-02,  6.4847e-02,  1.4388e-01, -3.6591e-02,\n",
      "         4.4307e-02,  3.0094e-02,  2.3947e-02, -6.4356e-02,  1.8527e-01,\n",
      "        -2.0822e-01, -3.5492e-02,  1.3414e-01,  4.5296e-02, -2.8097e-02,\n",
      "         1.3039e-01,  1.0102e-02, -6.0756e-03,  9.2639e-02,  1.7997e-01,\n",
      "         1.2552e-01,  1.1525e-02,  1.3936e-01,  9.2723e-03, -1.2091e-01,\n",
      "        -2.0337e-02,  1.3993e-01,  1.4385e-01,  1.8340e-01,  1.0171e-01,\n",
      "         4.5209e-02,  7.4639e-02, -1.0024e-01,  7.0049e-02,  7.4891e-02,\n",
      "         5.7438e-02,  2.0400e-01,  1.2844e-01,  8.0494e-02,  8.6971e-02,\n",
      "         5.5280e-04, -1.5109e-01,  1.0077e-02,  2.4397e-01,  3.6528e-02,\n",
      "         5.3695e-02,  1.1937e-01,  9.8878e-02, -4.1363e-02, -6.1172e-03,\n",
      "         1.0696e-01,  1.0583e-01,  3.1789e-01,  1.2105e-02,  3.6966e-02,\n",
      "         3.8884e-02,  1.3207e-05, -1.8045e-01,  9.2949e-02,  3.5579e-01,\n",
      "         1.7562e-01,  5.2235e-02,  2.8717e-01,  8.8601e-02,  1.0816e-01,\n",
      "        -2.2063e-02,  3.6931e-02,  3.1340e-02, -1.8423e-02,  1.6814e-01,\n",
      "        -4.6887e-04,  1.9825e-01,  1.3459e-01,  4.2007e-02,  9.2315e-03,\n",
      "         8.7292e-02, -3.2945e-02,  3.2598e-01,  1.0763e-01,  6.9619e-04,\n",
      "         1.0203e-02,  6.9988e-02, -1.1367e-02,  1.4867e-01, -2.0369e-01,\n",
      "         5.6526e-02, -9.1067e-02,  1.9459e-02,  1.0080e-01,  1.8429e-01,\n",
      "         1.6015e-01,  1.8134e-01,  1.1695e-01,  6.5061e-02,  9.7136e-02,\n",
      "         1.9571e-01,  1.8977e-01,  5.2180e-02, -1.0870e-01,  1.3085e-01,\n",
      "         4.5247e-02,  1.2772e-02, -3.9641e-02, -1.8610e-01, -7.0604e-02,\n",
      "         1.2044e-01, -4.8821e-02, -2.8440e-02, -1.0632e-02,  1.0908e-01,\n",
      "         5.3787e-02,  1.1652e-01, -2.9447e-02,  4.0321e-01, -6.4734e-02,\n",
      "         2.2914e-02,  8.8240e-02,  3.1470e-02,  3.6577e-03,  3.0137e-01,\n",
      "         6.8193e-02, -6.1503e-02,  7.1662e-02,  2.6561e-02,  3.5378e-01,\n",
      "        -1.0535e-01,  1.1304e-01,  9.0590e-02,  3.2702e-03,  5.7275e-02,\n",
      "         5.1514e-01,  4.9554e-02,  1.0499e-01,  9.2485e-04,  2.9589e-01,\n",
      "        -6.7953e-02,  7.7629e-02, -1.7351e-01, -2.4828e-01,  2.9132e-01,\n",
      "         1.0269e-01, -2.5470e-02,  4.2276e-01,  5.6362e-02, -2.1826e-02,\n",
      "         2.7908e-01,  2.4711e-01, -2.0559e-02,  4.1033e-01,  1.0646e-01,\n",
      "        -1.0769e-01,  3.2404e-02,  7.8538e-03,  2.2381e-02,  8.8990e-02,\n",
      "         9.1920e-02,  4.2402e-02,  1.6965e-01,  1.5932e-01,  5.8500e-01,\n",
      "         4.4016e-02,  8.4680e-02,  1.5562e-02,  5.3686e-02,  7.5615e-03,\n",
      "        -1.7018e-02,  6.9369e-02,  1.9750e-01,  2.6956e-02, -4.0056e-02,\n",
      "        -4.6108e-03,  1.8972e-01,  1.3781e-02,  8.0803e-02, -1.0054e-02,\n",
      "         2.1246e-01,  1.3612e-01, -7.6917e-01,  4.1772e-02,  5.9762e-02,\n",
      "         1.0543e-03, -1.5168e-02,  2.7847e-01,  5.2689e-02,  1.2394e-01,\n",
      "         3.0762e-02,  1.4299e-01,  1.2184e-02,  3.3403e-02, -1.4907e-02,\n",
      "        -6.7975e-02,  3.4594e-01], device='cuda:0')), ('classifier.0.weight', tensor([[-0.0051,  0.0025,  0.0020,  ...,  0.0053, -0.0119, -0.0025],\n",
      "        [ 0.0055,  0.0057,  0.0084,  ...,  0.0077, -0.0179, -0.0073],\n",
      "        [-0.0011,  0.0016, -0.0071,  ..., -0.0073, -0.0213,  0.0125],\n",
      "        ...,\n",
      "        [-0.0075, -0.0096, -0.0025,  ..., -0.0079, -0.0106, -0.0036],\n",
      "        [-0.0004,  0.0014, -0.0019,  ...,  0.0036,  0.0021,  0.0038],\n",
      "        [ 0.0161,  0.0090,  0.0081,  ..., -0.0122, -0.0006,  0.0134]],\n",
      "       device='cuda:0')), ('classifier.0.bias', tensor([ 3.4547e-02, -2.3083e-05,  2.1853e-02,  ..., -6.6586e-03,\n",
      "         4.7635e-02,  1.0321e-03], device='cuda:0')), ('classifier.3.weight', tensor([[-0.0128,  0.0197, -0.0005,  ..., -0.0161,  0.0121,  0.0007],\n",
      "        [ 0.0035, -0.0023,  0.0063,  ..., -0.0047,  0.0107, -0.0102],\n",
      "        [-0.0179, -0.0137, -0.0124,  ..., -0.0036,  0.0032, -0.0207],\n",
      "        ...,\n",
      "        [ 0.0154, -0.0212, -0.0006,  ..., -0.0018,  0.0088,  0.0052],\n",
      "        [ 0.0067,  0.0056, -0.0158,  ...,  0.0041, -0.0011, -0.0065],\n",
      "        [ 0.0243,  0.0037,  0.0008,  ...,  0.0244,  0.0066, -0.0112]],\n",
      "       device='cuda:0')), ('classifier.3.bias', tensor([0.0335, 0.0564, 0.0239,  ..., 0.0462, 0.0381, 0.0532], device='cuda:0')), ('classifier.6.weight', tensor([[ 0.0208,  0.0213, -0.0049,  ..., -0.0362, -0.0100,  0.0033],\n",
      "        [-0.0033, -0.0174, -0.0283,  ..., -0.0242, -0.0189, -0.0065],\n",
      "        [-0.0120, -0.0252,  0.0168,  ...,  0.0133, -0.0061,  0.0048],\n",
      "        ...,\n",
      "        [ 0.0019, -0.0177, -0.0357,  ..., -0.0096, -0.0162, -0.0122],\n",
      "        [ 0.0036, -0.0283, -0.0043,  ..., -0.0307,  0.0119, -0.0072],\n",
      "        [ 0.0127, -0.0087, -0.0122,  ...,  0.0026, -0.0055,  0.0002]],\n",
      "       device='cuda:0')), ('classifier.6.bias', tensor([-0.0053, -0.0160,  0.0247, -0.0112,  0.0204,  0.0249, -0.0041, -0.0142,\n",
      "        -0.0076, -0.0152, -0.0283,  0.0072,  0.0057,  0.0183,  0.0034,  0.0008,\n",
      "         0.0158, -0.0119, -0.0060, -0.0011, -0.0082, -0.0036, -0.0249,  0.0120,\n",
      "        -0.0200,  0.0124, -0.0358,  0.0288, -0.0281, -0.0079,  0.0168,  0.0097,\n",
      "         0.0100, -0.0098,  0.0110,  0.0119,  0.0127,  0.0223,  0.0243, -0.0237,\n",
      "        -0.0005,  0.0005,  0.0223,  0.0101,  0.0226,  0.0112, -0.0041, -0.0017,\n",
      "        -0.0170, -0.0267,  0.0082, -0.0069, -0.0144,  0.0004, -0.0053,  0.0008,\n",
      "        -0.0057,  0.0002, -0.0154, -0.0046, -0.0279, -0.0127, -0.0082, -0.0071,\n",
      "         0.0008, -0.0019, -0.0116,  0.0066, -0.0175,  0.0090, -0.0165, -0.0023,\n",
      "         0.0028, -0.0133,  0.0121,  0.0133, -0.0193,  0.0347, -0.0141, -0.0131,\n",
      "         0.0355,  0.0266, -0.0039, -0.0140, -0.0043,  0.0118, -0.0046,  0.0181,\n",
      "         0.0188,  0.0296,  0.0204, -0.0010, -0.0202,  0.0083,  0.0059, -0.0008,\n",
      "        -0.0138,  0.0309,  0.0178, -0.0265], device='cuda:0'))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./checkpoint/vgg16_adam_3e-05_64.pth\")\n",
    "print(checkpoint['model_state_dict'])\n",
    "pre_vgg16.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     pre_weight = pre_vgg16.features[0].weight.data\n",
    "#     print(pre_weight.shape, type(pre_weight))\n",
    "#     zero_tensor = torch.zeros((64,1,3,3))\n",
    "#     new_weight = torch.concat([pre_weight, zero_tensor], dim=1)\n",
    "#     print(new_weight.shape)\n",
    "#     new_parameter = torch.nn.Parameter(new_weight)\n",
    "#     print(new_parameter.shape)\n",
    "#     new_layer = torch.nn.Conv2d(4,64,3,1,1)\n",
    "#     new_layer.weight = new_parameter\n",
    "#     pre_vgg16.features[0] = new_layer\n",
    "#     print(pre_vgg16.features[0].weight.data.shape)\n",
    "#     print(pre_vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre_vgg와 Float,Int model 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0\n",
      "features.2\n",
      "features.5\n",
      "features.7\n",
      "features.10\n",
      "features.12\n",
      "features.14\n",
      "features.17\n",
      "features.19\n",
      "features.21\n",
      "features.24\n",
      "features.26\n",
      "features.28\n",
      "classifier.0\n",
      "classifier.3\n",
      "classifier.6\n",
      "----------------------------------------------------------\n",
      "features.0\n",
      "features.2\n",
      "features.5\n",
      "features.7\n",
      "features.10\n",
      "features.12\n",
      "features.14\n",
      "features.17\n",
      "features.19\n",
      "features.21\n",
      "features.24\n",
      "features.26\n",
      "features.28\n",
      "classifier.0\n",
      "classifier.2\n",
      "classifier.4\n"
     ]
    }
   ],
   "source": [
    "for name, module in pre_vgg16.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "        # print(type(module))\n",
    "        print(name)\n",
    "        # print(module.weight().int_repr())\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "int_model = vgg.int_vgg16(bias=bias_option)\n",
    "for name, module in int_model.named_modules():\n",
    "    if isinstance(module, layers.IntConv2d) or isinstance(module, layers.IntLinear):\n",
    "        # print(type(module))\n",
    "        print(name)\n",
    "        # print(module.weight().int_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomCrop(224,padding=16),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=(0.5071, 0.4867, 0.4408), std= (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "     transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=(0.5071, 0.4867, 0.4408), std= (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "# train_data = torchvision.datasets.CIFAR100(root=\"./dataset\", train=True, transform=transform)\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "#                                           shuffle=True,pin_memory=True,num_workers=4)\n",
    "val_data = torchvision.datasets.CIFAR100(root=\"./dataset\", train=False, transform=test_transform)\n",
    "# val_loader = torch.utils.data.DataLoader(val_data, batch_size=32,\n",
    "#                                           shuffle=False,pin_memory=True,num_workers=4)\n",
    "# val_data = torchvision.datasets.ImageNet(root=\"./dataset/ImageNet\", split='val', transform=test_transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32,\n",
    "                                          shuffle=False,pin_memory=True,num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) tensor(1.) tensor(0.)\n",
      "torch.Size([32, 4, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "next_data = next(iter(val_loader))[0]\n",
    "print(next_data.shape, next_data.max(), next_data.min())\n",
    "imgs = torch.cat([next_data, torch.zeros((next_data.size(0),1,224,224))], dim=1)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:36<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START  ACC 39.12\n"
     ]
    }
   ],
   "source": [
    "pre_vgg16.eval()\n",
    "pre_vgg16.cuda()\n",
    "def validate(model, test_loader, num_calib=None, cpu_device=False):\n",
    "    model.eval()\n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(tqdm(test_loader,leave=True)):\n",
    "            imgs = torch.cat([data[0], torch.zeros((data[0].size(0),1,224,224))], 1)\n",
    "            if cpu_device:\n",
    "                target = data[1]\n",
    "            else:\n",
    "                imgs, target = imgs.to(device), data[1].to(device)\n",
    "            output = model(imgs)\n",
    "\n",
    "            _, preds = torch.max(output.data, 1)\n",
    "            val_acc += (preds==target).sum().item()\n",
    "            if num_calib and (i > num_calib):\n",
    "                break\n",
    "\n",
    "    val_acc = 100. * val_acc/len(test_loader.dataset)\n",
    "\n",
    "    return val_acc\n",
    "start_acc = validate(pre_vgg16, val_loader)\n",
    "pre_vgg16.to('cpu')\n",
    "print(f\"START  ACC {start_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Float 모델에 실험 해보기 NHWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "conv pre_weight shape : torch.Size([64, 4, 3, 3]) (36, 9, 3, 1)\n",
      "after_weight shape : torch.Size([64, 3, 3, 4]), (36, 12, 4, 1)\n",
      "bias shape : torch.Size([64])\n",
      "True\n",
      "2 \n",
      "conv pre_weight shape : torch.Size([64, 64, 3, 3]) (576, 9, 3, 1)\n",
      "after_weight shape : torch.Size([64, 3, 3, 64]), (576, 192, 64, 1)\n",
      "bias shape : torch.Size([64])\n",
      "True\n",
      "5 \n",
      "conv pre_weight shape : torch.Size([128, 64, 3, 3]) (576, 9, 3, 1)\n",
      "after_weight shape : torch.Size([128, 3, 3, 64]), (576, 192, 64, 1)\n",
      "bias shape : torch.Size([128])\n",
      "True\n",
      "7 \n",
      "conv pre_weight shape : torch.Size([128, 128, 3, 3]) (1152, 9, 3, 1)\n",
      "after_weight shape : torch.Size([128, 3, 3, 128]), (1152, 384, 128, 1)\n",
      "bias shape : torch.Size([128])\n",
      "True\n",
      "10 \n",
      "conv pre_weight shape : torch.Size([256, 128, 3, 3]) (1152, 9, 3, 1)\n",
      "after_weight shape : torch.Size([256, 3, 3, 128]), (1152, 384, 128, 1)\n",
      "bias shape : torch.Size([256])\n",
      "True\n",
      "12 \n",
      "conv pre_weight shape : torch.Size([256, 256, 3, 3]) (2304, 9, 3, 1)\n",
      "after_weight shape : torch.Size([256, 3, 3, 256]), (2304, 768, 256, 1)\n",
      "bias shape : torch.Size([256])\n",
      "True\n",
      "14 \n",
      "conv pre_weight shape : torch.Size([256, 256, 3, 3]) (2304, 9, 3, 1)\n",
      "after_weight shape : torch.Size([256, 3, 3, 256]), (2304, 768, 256, 1)\n",
      "bias shape : torch.Size([256])\n",
      "True\n",
      "17 \n",
      "conv pre_weight shape : torch.Size([512, 256, 3, 3]) (2304, 9, 3, 1)\n",
      "after_weight shape : torch.Size([512, 3, 3, 256]), (2304, 768, 256, 1)\n",
      "bias shape : torch.Size([512])\n",
      "True\n",
      "19 \n",
      "conv pre_weight shape : torch.Size([512, 512, 3, 3]) (4608, 9, 3, 1)\n",
      "after_weight shape : torch.Size([512, 3, 3, 512]), (4608, 1536, 512, 1)\n",
      "bias shape : torch.Size([512])\n",
      "True\n",
      "21 \n",
      "conv pre_weight shape : torch.Size([512, 512, 3, 3]) (4608, 9, 3, 1)\n",
      "after_weight shape : torch.Size([512, 3, 3, 512]), (4608, 1536, 512, 1)\n",
      "bias shape : torch.Size([512])\n",
      "True\n",
      "24 \n",
      "conv pre_weight shape : torch.Size([512, 512, 3, 3]) (4608, 9, 3, 1)\n",
      "after_weight shape : torch.Size([512, 3, 3, 512]), (4608, 1536, 512, 1)\n",
      "bias shape : torch.Size([512])\n",
      "True\n",
      "26 \n",
      "conv pre_weight shape : torch.Size([512, 512, 3, 3]) (4608, 9, 3, 1)\n",
      "after_weight shape : torch.Size([512, 3, 3, 512]), (4608, 1536, 512, 1)\n",
      "bias shape : torch.Size([512])\n",
      "True\n",
      "28 \n",
      "conv pre_weight shape : torch.Size([512, 512, 3, 3]) (4608, 9, 3, 1)\n",
      "after_weight shape : torch.Size([512, 3, 3, 512]), (4608, 1536, 512, 1)\n",
      "bias shape : torch.Size([512])\n",
      "True\n",
      "0 \n",
      "linaer pre_weight shape : torch.Size([4096, 25088]) (25088, 1)\n",
      "after_weight shape : torch.Size([25088, 4096]) (4096, 1)\n",
      "linaer pre_bias shape : torch.Size([4096]) (1,)\n",
      "after_bias shape : torch.Size([4096]) (1,)\n",
      "\n",
      "3 \n",
      "linaer pre_weight shape : torch.Size([4096, 4096]) (4096, 1)\n",
      "after_weight shape : torch.Size([4096, 4096]) (4096, 1)\n",
      "linaer pre_bias shape : torch.Size([4096]) (1,)\n",
      "after_bias shape : torch.Size([4096]) (1,)\n",
      "\n",
      "6 \n",
      "linaer pre_weight shape : torch.Size([100, 4096]) (4096, 1)\n",
      "after_weight shape : torch.Size([4096, 100]) (100, 1)\n",
      "linaer pre_bias shape : torch.Size([100]) (1,)\n",
      "after_bias shape : torch.Size([100]) (1,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "float_model = vgg.float_vgg16(bias=bias_option) \n",
    "\n",
    "# bias 가 없는 모델 사용함\n",
    "with torch.no_grad():\n",
    "    conv_list = [0,2,5,7,10,12,14,17,19,21,24,26,28]\n",
    "\n",
    "    for i in conv_list:\n",
    "        pre_weight = pre_vgg16.features[i].weight.data.contiguous()\n",
    "        print(f\"{i} \\nconv pre_weight shape : {pre_weight.shape} {pre_weight.stride()}\")\n",
    "        # convert_channel = pre_weight.to(memory_format=torch.channels_last)\n",
    "        # print(f\"convert channel last {convert_channel.shape} {convert_channel.stride()}\")\n",
    "\n",
    "        # convert_channel = convert_channel.permute(0,2,3,1).to(memory_format=torch.channels_last)\n",
    "        # print(f\"{convert_channel.shape} {convert_channel.stride()}\")\n",
    "\n",
    "        float_model.features[i].weight = pre_weight.permute(0,2,3,1).contiguous()\n",
    "        print(f\"after_weight shape : {float_model.features[i].weight.shape}, {(float_model.features[i].weight.stride())}\")\n",
    "        if bias_option:\n",
    "            pre_bias = pre_vgg16.features[i].bias.data.contiguous()\n",
    "            print(f\"bias shape : {pre_vgg16.features[i].bias.shape}\")\n",
    "            \n",
    "            float_model.features[i].bias = pre_bias.contiguous()\n",
    "            print(torch.equal(pre_weight, float_model.features[i].weight.permute(0,3,1,2)))\n",
    "        # print()\n",
    "\n",
    "    linear_list = [(0,0), (3,2), (6,4)]\n",
    "\n",
    "    for p_i, int_i in linear_list:\n",
    "        pre_weight = pre_vgg16.classifier[p_i].weight.data\n",
    "        print(f\"{p_i} \\nlinaer pre_weight shape : {pre_weight.shape} {pre_weight.stride()}\")\n",
    "        \n",
    "        float_model.classifier[int_i].weight = pre_weight.permute(1,0).contiguous()\n",
    "        print(f\"after_weight shape : {float_model.classifier[int_i].weight.shape} {float_model.classifier[int_i].weight.stride()}\")\n",
    "        \n",
    "        if bias_option:\n",
    "            pre_bias = pre_vgg16.classifier[p_i].bias.data\n",
    "            print(f\"linaer pre_bias shape : {pre_bias.shape} {pre_bias.stride()}\")\n",
    "            \n",
    "            float_model.classifier[int_i].bias = pre_bias.contiguous()\n",
    "            print(f\"after_bias shape : {float_model.classifier[int_i].bias.shape} {float_model.classifier[int_i].bias.stride()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:34<00:00,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float model test result : 39.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "float_model.eval()\n",
    "float_model.cuda()\n",
    "val_acc = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(tqdm(val_loader,leave=True)):\n",
    "        # imgs = torch.tensor(data[0].clone().detach()-128, dtype=torch.int8)\n",
    "        imgs = torch.cat([data[0], torch.zeros((data[0].size(0),1,224,224))], dim=1)\n",
    "        imgs = imgs.permute(0,2,3,1)\n",
    "        imgs = imgs.contiguous()\n",
    "        imgs, target = imgs.to(device), data[1].to(device)\n",
    "        \n",
    "        output = float_model(imgs)\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        val_acc += (preds==target).sum().item()\n",
    "\n",
    "val_acc = 100. * val_acc/len(val_loader.dataset)\n",
    "print(f\"float model test result : {val_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Float type weight 를 Integer type으로 변경하기    \n",
    "MinMax를 사용하여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1683340/1006822924.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  quant_weight = torch.tensor(quant_weight/scale.view(-1,1,1,1) + zero_tensor.view(-1,1,1,1), dtype=torch.int8)\n",
      "/tmp/ipykernel_1683340/1006822924.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  quant_bias = torch.tensor(pre_bias/scale + zero_tensor, dtype=torch.int8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "conv pre_weight shape : torch.Size([64, 4, 3, 3]) (36, 9, 3, 1)\n",
      "pre_weight tensor([[[[ 0.0088, -0.0178, -0.0959],\n",
      "          [ 0.1229,  0.0205, -0.0342],\n",
      "          [ 0.0236,  0.1382,  0.0203]],\n",
      "\n",
      "         [[-0.0419,  0.0439,  0.0065],\n",
      "          [-0.1620,  0.0823,  0.0110],\n",
      "          [-0.0216,  0.0952,  0.0605]],\n",
      "\n",
      "         [[-0.1239,  0.1539,  0.0574],\n",
      "          [ 0.1103,  0.0528, -0.1128],\n",
      "          [ 0.1326, -0.1258, -0.0360]],\n",
      "\n",
      "         [[-0.1210,  0.0103, -0.1533],\n",
      "          [-0.0023,  0.1015,  0.0797],\n",
      "          [-0.1425, -0.1219, -0.0327]]],\n",
      "\n",
      "\n",
      "        [[[-0.1381, -0.0145, -0.1343],\n",
      "          [-0.1463, -0.1411,  0.0838],\n",
      "          [ 0.0225, -0.0231,  0.1605]],\n",
      "\n",
      "         [[ 0.0207,  0.0834, -0.0976],\n",
      "          [-0.0444, -0.1356, -0.1069],\n",
      "          [-0.1590, -0.0449,  0.1114]],\n",
      "\n",
      "         [[ 0.0404,  0.0889,  0.0159],\n",
      "          [-0.0699,  0.1607, -0.0762],\n",
      "          [ 0.0506, -0.1206,  0.0825]],\n",
      "\n",
      "         [[ 0.1037,  0.0541, -0.0952],\n",
      "          [-0.1022, -0.0776,  0.0323],\n",
      "          [ 0.0259,  0.0098,  0.1579]]],\n",
      "\n",
      "\n",
      "        [[[-0.0707, -0.0866, -0.0642],\n",
      "          [-0.1151, -0.0519,  0.1227],\n",
      "          [ 0.0886, -0.0435, -0.0869]],\n",
      "\n",
      "         [[-0.0134, -0.0062,  0.0206],\n",
      "          [ 0.0105,  0.0856, -0.0408],\n",
      "          [-0.0592,  0.1277, -0.0903]],\n",
      "\n",
      "         [[-0.1394,  0.0996, -0.0335],\n",
      "          [ 0.1151, -0.1086,  0.0772],\n",
      "          [ 0.0332,  0.0377, -0.0759]],\n",
      "\n",
      "         [[-0.0849,  0.0125, -0.1179],\n",
      "          [-0.0406, -0.1552,  0.1014],\n",
      "          [-0.1387, -0.1572,  0.0812]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1327,  0.1064, -0.1350],\n",
      "          [-0.0445,  0.1287,  0.1426],\n",
      "          [-0.1582,  0.0674, -0.1192]],\n",
      "\n",
      "         [[-0.0084, -0.1207,  0.0892],\n",
      "          [ 0.1142,  0.0544,  0.1280],\n",
      "          [-0.0643,  0.1474, -0.0309]],\n",
      "\n",
      "         [[ 0.1567,  0.1633,  0.0584],\n",
      "          [-0.0213,  0.0320, -0.1621],\n",
      "          [ 0.0024, -0.0201, -0.0208]],\n",
      "\n",
      "         [[-0.0755,  0.0472,  0.0672],\n",
      "          [-0.1249,  0.1338,  0.0330],\n",
      "          [-0.0788,  0.0646,  0.1532]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0140, -0.1285, -0.0982],\n",
      "          [-0.0979,  0.1142,  0.0805],\n",
      "          [-0.0469, -0.1388,  0.0213]],\n",
      "\n",
      "         [[ 0.1310, -0.0628, -0.1320],\n",
      "          [-0.1116,  0.0691, -0.1366],\n",
      "          [-0.1352, -0.1377, -0.1145]],\n",
      "\n",
      "         [[ 0.0184,  0.0595,  0.0758],\n",
      "          [-0.0485, -0.0502,  0.0876],\n",
      "          [ 0.1375,  0.0588,  0.0570]],\n",
      "\n",
      "         [[ 0.0240, -0.1261,  0.1605],\n",
      "          [ 0.1266,  0.0684,  0.0531],\n",
      "          [-0.1399, -0.1216,  0.0307]]],\n",
      "\n",
      "\n",
      "        [[[-0.0824, -0.0953,  0.1062],\n",
      "          [ 0.1031,  0.0692, -0.1592],\n",
      "          [-0.1220,  0.0115,  0.1367]],\n",
      "\n",
      "         [[ 0.0366,  0.0529, -0.0268],\n",
      "          [-0.0633,  0.0591, -0.1235],\n",
      "          [-0.0958, -0.0064,  0.0942]],\n",
      "\n",
      "         [[ 0.1381, -0.1604,  0.1231],\n",
      "          [-0.0949,  0.0858, -0.1202],\n",
      "          [ 0.0645, -0.1235,  0.0797]],\n",
      "\n",
      "         [[-0.1639,  0.0115,  0.0798],\n",
      "          [ 0.1552, -0.0823,  0.0081],\n",
      "          [ 0.1596, -0.0576,  0.0009]]]])\n",
      "scale torch.Size([64]) tensor([0.0012, 0.0013, 0.0011, 0.0012, 0.0013, 0.0012, 0.0012, 0.0013, 0.0012,\n",
      "        0.0013, 0.0013, 0.0012, 0.0013, 0.0013, 0.0013, 0.0013, 0.0012, 0.0013,\n",
      "        0.0012, 0.0013, 0.0012, 0.0013, 0.0013, 0.0013, 0.0012, 0.0012, 0.0012,\n",
      "        0.0013, 0.0012, 0.0012, 0.0013, 0.0013, 0.0012, 0.0013, 0.0012, 0.0012,\n",
      "        0.0012, 0.0013, 0.0013, 0.0012, 0.0012, 0.0012, 0.0013, 0.0012, 0.0012,\n",
      "        0.0013, 0.0012, 0.0012, 0.0012, 0.0011, 0.0011, 0.0013, 0.0013, 0.0013,\n",
      "        0.0012, 0.0010, 0.0012, 0.0013, 0.0013, 0.0013, 0.0012, 0.0013, 0.0012,\n",
      "        0.0013]), \n",
      "zero_tensor torch.Size([64]) tensor([  3,  -1,  13,  -3,   1,  -8,   0,  -1,   0,  -1,   1,   6,  -4,  -4,\n",
      "         -2,   0,   5,   2,   3,   4, -13,   2,  -1,  -3,   7, -12,   0,  -1,\n",
      "          1,   2,  -2,  -1,   5,   1,  -2,   0, -16,   3,  -3,   2,  -2,  -7,\n",
      "         -3,  -5,  -4,   0,   2,   2,   0, -15,   3,   3,   0,   3,  11,  17,\n",
      "          0,   2,  -2,   1,   1,  -1,  -9,   1], dtype=torch.int32)\n",
      "quant weight tensor([[[[  10,  -11,  -74],\n",
      "          [ 102,   19,  -24],\n",
      "          [  22,  114,   19]],\n",
      "\n",
      "         [[ -30,   38,    8],\n",
      "          [-127,   69,   11],\n",
      "          [ -14,   79,   51]],\n",
      "\n",
      "         [[ -97,  127,   49],\n",
      "          [  91,   45,  -88],\n",
      "          [ 110,  -98,  -26]],\n",
      "\n",
      "         [[ -94,   11, -120],\n",
      "          [   1,   84,   67],\n",
      "          [-112,  -95,  -23]]],\n",
      "\n",
      "\n",
      "        [[[-111,  -12, -108],\n",
      "          [-117, -113,   65],\n",
      "          [  16,  -19,  127]],\n",
      "\n",
      "         [[  15,   65,  -78],\n",
      "          [ -36, -109,  -86],\n",
      "          [-127,  -36,   87]],\n",
      "\n",
      "         [[  31,   69,   11],\n",
      "          [ -56,  127,  -61],\n",
      "          [  39,  -97,   64]],\n",
      "\n",
      "         [[  81,   42,  -76],\n",
      "          [ -82,  -62,   24],\n",
      "          [  19,    6,  124]]],\n",
      "\n",
      "\n",
      "        [[[ -50,  -64,  -44],\n",
      "          [ -90,  -33,  122],\n",
      "          [  92,  -25,  -64]],\n",
      "\n",
      "         [[   1,    7,   31],\n",
      "          [  22,   89,  -23],\n",
      "          [ -39,  127,  -67]],\n",
      "\n",
      "         [[-111,  102,  -17],\n",
      "          [ 116,  -84,   82],\n",
      "          [  42,   46,  -54]],\n",
      "\n",
      "         [[ -62,   24,  -92],\n",
      "          [ -23, -125,  103],\n",
      "          [-111, -127,   85]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 102,   82, -106],\n",
      "          [ -35,   99,  110],\n",
      "          [-125,   51,  -94]],\n",
      "\n",
      "         [[  -7,  -95,   68],\n",
      "          [  88,   41,   99],\n",
      "          [ -51,  114,  -25]],\n",
      "\n",
      "         [[ 121,  126,   44],\n",
      "          [ -17,   24, -128],\n",
      "          [   0,  -16,  -17]],\n",
      "\n",
      "         [[ -60,   36,   51],\n",
      "          [ -98,  103,   24],\n",
      "          [ -62,   49,  119]]],\n",
      "\n",
      "\n",
      "        [[[   2, -118,  -92],\n",
      "          [ -92,   87,   59],\n",
      "          [ -48, -126,    9]],\n",
      "\n",
      "         [[ 102,  -62, -121],\n",
      "          [-103,   49, -124],\n",
      "          [-123, -125, -106]],\n",
      "\n",
      "         [[   6,   41,   55],\n",
      "          [ -50,  -51,   65],\n",
      "          [ 107,   40,   39]],\n",
      "\n",
      "         [[  11, -116,  127],\n",
      "          [  98,   49,   36],\n",
      "          [-127, -112,   17]]],\n",
      "\n",
      "\n",
      "        [[[ -63,  -74,   84],\n",
      "          [  82,   55, -124],\n",
      "          [ -95,   10,  108]],\n",
      "\n",
      "         [[  29,   42,  -20],\n",
      "          [ -48,   47,  -96],\n",
      "          [ -74,   -4,   75]],\n",
      "\n",
      "         [[ 109, -125,   98],\n",
      "          [ -73,   68,  -93],\n",
      "          [  51,  -96,   63]],\n",
      "\n",
      "         [[-128,   10,   63],\n",
      "          [ 123,  -63,    7],\n",
      "          [ 126,  -44,    1]]]], dtype=torch.int8)\n",
      "tensor(-128, dtype=torch.int8) tensor(127, dtype=torch.int8)\n",
      "pre bias \t Parameter containing:\n",
      "tensor([-0.1466,  0.0587, -0.0155,  0.0434,  0.0622, -0.1552,  0.1071,  0.0120,\n",
      "        -0.1275, -0.0767,  0.0724,  0.1414, -0.1074,  0.0540, -0.0494, -0.1203,\n",
      "        -0.1500, -0.0217,  0.1141,  0.0851, -0.1277,  0.1019,  0.0264,  0.0421,\n",
      "        -0.1191,  0.1432, -0.0470, -0.0160, -0.0173,  0.0216,  0.0560, -0.0034,\n",
      "        -0.0385, -0.1230, -0.1539,  0.0532,  0.0920, -0.0545, -0.1577, -0.0766,\n",
      "        -0.0834, -0.0456, -0.0675, -0.0849,  0.0843,  0.0920, -0.0672,  0.1603,\n",
      "        -0.0549,  0.0356,  0.1170,  0.1209,  0.0125,  0.0041, -0.1162,  0.0013,\n",
      "         0.1133, -0.0847,  0.0776,  0.0218, -0.0643, -0.1204,  0.1652,  0.1292],\n",
      "       requires_grad=True)\n",
      "quant_bias \ttensor([-115,   45,    0,   32,   49,  118,   87,    8, -102,  -61,   58,  120,\n",
      "         -89,   38,  -41,  -92, -117,  -15,   99,   71, -122,   82,   19,   29,\n",
      "         -89,  107,  -39,  -13,  -13,   19,   42,   -3,  -25,  -95,  126,   43,\n",
      "          63,  -40, -126,  -62,  -68,  -43,  -56,  -73,   66,   71,  -52, -120,\n",
      "         -44,   16,  104,   99,    9,    6,  -86,   18,   94,  -64,   58,   17,\n",
      "         -54,  -95, -125,  102], dtype=torch.int8)\n",
      "0 \n",
      "linaer pre_weight shape : torch.Size([4096, 25088]) (25088, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1683340/1006822924.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  quant_weight = torch.tensor(quant_weight/scale.view(-1,1) + zero_tensor.view(-1,1), dtype=torch.int8)\n",
      "/tmp/ipykernel_1683340/1006822924.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  quant_bias = torch.tensor(pre_bias/scale + zero_tensor, dtype=torch.int8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-128, dtype=torch.int8) tensor(127, dtype=torch.int8)\n",
      "3 \n",
      "linaer pre_weight shape : torch.Size([4096, 4096]) (4096, 1)\n",
      "tensor(-128, dtype=torch.int8) tensor(127, dtype=torch.int8)\n",
      "6 \n",
      "linaer pre_weight shape : torch.Size([100, 4096]) (4096, 1)\n",
      "tensor(-128, dtype=torch.int8) tensor(127, dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# bias 가 있는\n",
    "from torch.ao.quantization.observer import PerChannelMinMaxObserver\n",
    "\n",
    "int_model = vgg.int_vgg16(bias=bias_option)\n",
    "count = 0\n",
    "\n",
    "# 전체 conv_weight의 분포\n",
    "# 전체 linear weight의 분포\n",
    "\n",
    "conv_weights = []\n",
    "linear_weights = []\n",
    "with torch.no_grad():\n",
    "    quant_min = -128\n",
    "    quant_max = 127\n",
    "\n",
    "\n",
    "    conv_list = [0,2,5,7,10,12,14,17,19,21,24,26,28]\n",
    "    for i in conv_list:\n",
    "        observer = PerChannelMinMaxObserver(quant_max=127,quant_min=-128)\n",
    "    \n",
    "        pre_weight = pre_vgg16.features[i].weight.data.contiguous()\n",
    "        conv_weights.append(pre_weight.view(-1).tolist())\n",
    "\n",
    "        quant_weight = observer(pre_weight)\n",
    "        # pre_weight랑 quant_weigth랑 차이가 없음\n",
    "        # print(\"--------------check diff------------------\")\n",
    "        # print(pre_weight[0])\n",
    "        # print(quant_weight[0])\n",
    "        # print(\"--------------check diff------------------\")\n",
    "        # print(f\"quant_weight {quant_weight.shape}\")\n",
    "        scale, zero_tensor = observer.calculate_qparams()\n",
    "\n",
    "        quant_weight = torch.tensor(quant_weight/scale.view(-1,1,1,1) + zero_tensor.view(-1,1,1,1), dtype=torch.int8)\n",
    "        \n",
    "        int_model.features[i].weight = quant_weight.permute(0,2,3,1).contiguous()\n",
    "\n",
    "        if bias_option:\n",
    "            pre_bias = pre_vgg16.features[i].bias\n",
    "            quant_bias = torch.tensor(pre_bias/scale + zero_tensor, dtype=torch.int8)\n",
    "            int_model.features[i].bias = quant_bias.contiguous()\n",
    "\n",
    "        if count < 1:\n",
    "            print(f\"{i} \\nconv pre_weight shape : {pre_weight.shape} {pre_weight.stride()}\")\n",
    "            print(f\"pre_weight {pre_weight}\")\n",
    "            print(f\"scale {scale.shape} {scale}, \\nzero_tensor {zero_tensor.shape} {zero_tensor}\")\n",
    "            print(f\"quant weight {quant_weight}\")\n",
    "            print(quant_weight.min(), quant_weight.max())\n",
    "            print(f\"pre bias \\t {pre_bias}\")\n",
    "            print(f\"quant_bias \\t{quant_bias}\")\n",
    "        count += 1\n",
    "    count = 0 \n",
    "\n",
    "    linear_list = [(0,0), (3,2), (6,4)]\n",
    "\n",
    "    for p_i, int_i in linear_list:\n",
    "        observer = PerChannelMinMaxObserver(quant_max=127,quant_min=-128)\n",
    "\n",
    "        pre_weight = pre_vgg16.classifier[p_i].weight.data.contiguous()\n",
    "        linear_weights.append(pre_weight.view(-1).tolist())\n",
    "        print(f\"{p_i} \\nlinaer pre_weight shape : {pre_weight.shape} {pre_weight.stride()}\")\n",
    "\n",
    "\n",
    "        quant_weight = observer(pre_weight)\n",
    "        scale, zero_tensor = observer.calculate_qparams()\n",
    "        quant_weight = torch.tensor(quant_weight/scale.view(-1,1) + zero_tensor.view(-1,1), dtype=torch.int8)\n",
    "\n",
    "        print(quant_weight.min(), quant_weight.max())\n",
    "\n",
    "        int_model.classifier[int_i].weight = quant_weight.permute(1,0).contiguous()\n",
    "        if bias_option:\n",
    "            pre_bias = pre_vgg16.classifier[p_i].bias\n",
    "            quant_bias = torch.tensor(pre_bias/scale + zero_tensor, dtype=torch.int8)\n",
    "            int_model.classifier[int_i].bias = quant_bias.contiguous()\n",
    "\n",
    "\n",
    "    torch.save({\n",
    "        'model':int_model,\n",
    "        'model_state_dict':int_model.state_dict(),\n",
    "        'pre_acc': val_acc\n",
    "    }, f\"./checkpoint/minmax_bias.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## floating type으로 학습한 모델을 가지고 quantization 하기   \n",
    "위에 꺼랑 비교해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantized(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        _log_api_usage_once(self)\n",
    "        \n",
    "        self.model = model\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.model(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q config :\n",
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n",
      "fbgemm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization import observer\n",
    "from torch.ao.quantization.backend_config import BackendConfig, BackendPatternConfig, DTypeConfig, DTypeWithConstraints\n",
    "quant_model = Quantized(pre_vgg16)\n",
    "\n",
    "\n",
    "quant_model.cpu()\n",
    "quant_model.eval()\n",
    "backend = 'fbgemm'\n",
    "qconfig = torch.ao.quantization.get_default_qconfig(backend)\n",
    "\n",
    "# new_qconfig = torch.ao.quantization.QConfig(\n",
    "#     activation=observer.HistogramObserver.with_args(reduce_range=True),\n",
    "#     weight=observer.PerChannelMinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_channel_symmetric),\n",
    "#     bias=observer.MinMaxObserver.with_args(dtype=torch.qint32)  # Bias를 qint32로 설정\n",
    "# )\n",
    "print(f\"q config :\\n{qconfig}\")\n",
    "\n",
    "# new_qconfig_dict = qconfig._asdict()\n",
    "# new_qconfig_dict['bias'] = new_qconfig.bias\n",
    "# print(new_qconfig)\n",
    "# new_qconfig = torch.\n",
    "\n",
    "quant_model.qconfig = qconfig\n",
    "# print(f\"defualt qconfig ; {quant_model.qconfig}\")\n",
    "torch.backends.quantized.engine = backend\n",
    "print(torch.backends.quantized.engine)\n",
    "model_static_quantized = torch.ao.quantization.prepare(quant_model, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/313 [02:07<58:29, 11.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Quantized(\n",
       "  (model): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): QuantizedConv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.018216310068964958, zero_point=78, padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.022390827536582947, zero_point=68, padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.036442290991544724, zero_point=65, padding=(1, 1))\n",
       "      (6): ReLU()\n",
       "      (7): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.06950325518846512, zero_point=77, padding=(1, 1))\n",
       "      (8): ReLU()\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.10467969626188278, zero_point=76, padding=(1, 1))\n",
       "      (11): ReLU()\n",
       "      (12): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.1381770521402359, zero_point=72, padding=(1, 1))\n",
       "      (13): ReLU()\n",
       "      (14): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.1921708732843399, zero_point=68, padding=(1, 1))\n",
       "      (15): ReLU()\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1618671417236328, zero_point=58, padding=(1, 1))\n",
       "      (18): ReLU()\n",
       "      (19): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.13486984372138977, zero_point=69, padding=(1, 1))\n",
       "      (20): ReLU()\n",
       "      (21): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.12746703624725342, zero_point=85, padding=(1, 1))\n",
       "      (22): ReLU()\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08677437901496887, zero_point=66, padding=(1, 1))\n",
       "      (25): ReLU()\n",
       "      (26): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.06656719744205475, zero_point=77, padding=(1, 1))\n",
       "      (27): ReLU()\n",
       "      (28): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.06189636513590813, zero_point=76, padding=(1, 1))\n",
       "      (29): ReLU()\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): QuantizedLinear(in_features=25088, out_features=4096, scale=0.1129966452717781, zero_point=100, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): QuantizedDropout(p=0.5, inplace=False)\n",
       "      (3): QuantizedLinear(in_features=4096, out_features=4096, scale=0.06577900797128677, zero_point=71, qscheme=torch.per_channel_affine)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): QuantizedDropout(p=0.5, inplace=False)\n",
       "      (6): QuantizedLinear(in_features=4096, out_features=100, scale=0.5314950942993164, zero_point=115, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calibration\n",
    "validate(model_static_quantized,val_loader,10,cpu_device=True)\n",
    "\n",
    "# make quantized model\n",
    "torch.ao.quantization.convert(model_static_quantized, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'model':model_static_quantized,\n",
    "#     'model_state_dict' : model_static_quantized.state_dict(),\n",
    "#     },\"./checkpoint/static_quant_fbegmm_test.pth\")\n",
    "\n",
    "# # # torch.jit.save(torch.jit.script(model_static_quantized),\"./checkpoint/static_quant_fbegmm_test.pth\")\n",
    "# # model_static_quantized = torch.jit.load(\"./checkpoint/static_quant_fbegmm_test.pth\")\n",
    "# # print(model_static_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [12:16<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test result : 36.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc = validate(model_static_quantized, val_loader, cpu_device=True)\n",
    "print(f\"test result : {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.features.0\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.2\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.5\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.7\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.10\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.12\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.14\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.17\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.19\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.21\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.24\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.26\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.features.28\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.classifier.0\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.classifier.3\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "model.classifier.6\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(103, dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "torch_static_conv_scale = []\n",
    "torch_static_conv_zero = []\n",
    "\n",
    "for name, module in model_static_quantized.named_modules():\n",
    "    if isinstance(module, torch.ao.nn.quantized.modules.conv.Conv2d) or isinstance(module, torch.ao.nn.quantized.modules.linear.Linear):\n",
    "        # print(type(module))\n",
    "        print(name)\n",
    "        # print(module.weight().int_repr().permute(0,2,3,1))\n",
    "        print(module.weight().int_repr().min())\n",
    "        print(module.weight().int_repr().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_model = vgg.int_vgg16()\n",
    "# for name, module in int_model.named_modules():\n",
    "#     if isinstance(module, layers.IntConv2d) or isinstance(module, layers.IntLinear):\n",
    "#         # print(type(module))\n",
    "#         print(name)\n",
    "#         # print(module.weight().int_repr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch quantization으로 만든 Intger weight를 Int_model에 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     conv_list = [0,2,5,7,10,12,14,17,19,21,24,26,28]\n",
    "\n",
    "#     for i in conv_list:\n",
    "#         pre_weight = model_static_quantized.model.features[i].weight().int_repr()\n",
    "#         print(f\"{i} conv pre_weight shape : {pre_weight.shape}\")\n",
    "\n",
    "#         int_model.features[i].weight = pre_weight.permute(0,2,3,1).contiguous()\n",
    "#         print(f\"after_weight shape : {int_model.features[i].weight.shape}, {(int_model.features[i].weight.stride())}\")\n",
    "#         # int_model.features[i].bias = pre_bias.contiguous()\n",
    "#     linear_list = [(0,0), (3,2), (6,4)]\n",
    "\n",
    "#     for p_i, int_i in linear_list:\n",
    "#         pre_weight = model_static_quantized.model.classifier[p_i].weight().int_repr()\n",
    "#         print(f\"{p_i} linaer pre_weight shape : {pre_weight.shape}\")\n",
    "        \n",
    "#         int_model.classifier[int_i].weight = pre_weight.transpose(1,0).contiguous()\n",
    "#         print(f\"after_weight shape : {int_model.classifier[int_i].weight.shape}\")\n",
    "\n",
    "# torch.save({\n",
    "#     'model':int_model,\n",
    "#     'model_state_dict':int_model.state_dict(),\n",
    "#     'pre_acc': val_acc\n",
    "# }, f\"./checkpoint/int_model_no_bias.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_model = vgg.int_vgg16(bias=bias_option)\n",
    "\n",
    "int_model.load_state_dict(torch.load('./checkpoint/minmax_bias.pth')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intmodel quantization ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.2\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.5\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.7\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.10\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.12\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.14\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.17\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.19\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.21\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.24\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.26\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "features.28\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "classifier.0\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "classifier.2\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n",
      "classifier.4\n",
      "tensor(-128, dtype=torch.int8)\n",
      "tensor(127, dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "for name, module in int_model.named_modules():\n",
    "    if isinstance(module, layers.IntConv2d) or isinstance(module, layers.IntLinear):\n",
    "        # print(type(module))\n",
    "        print(name)\n",
    "        # print(module.weight)\n",
    "        print(module.weight.min())\n",
    "        print(module.weight.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "int_transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor()\n",
    "    # transforms.ConvertImageDtype(torch.int8)\n",
    "    # NHWC 로 해야한다.\n",
    "])\n",
    "\n",
    "val_data = torchvision.datasets.CIFAR100(root=\"./dataset\", train=False, transform=int_transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=False,pin_memory=True,num_workers=4)\n",
    "next_data = next(iter(val_loader))[0]\n",
    "print(next_data.shape, next_data.max(), next_data.min())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale shape torch.Size([1]), zero_tensor shape torch.Size([1])\n",
      "tensor([[[[ 71,  71,  71,  ...,  96,  96,  96],\n",
      "          [ 71,  71,  71,  ...,  96,  96,  96],\n",
      "          [ 71,  71,  71,  ...,  96,  96,  96],\n",
      "          ...,\n",
      "          [-47, -47, -47,  ...,  48,  48,  48],\n",
      "          [-47, -47, -47,  ...,  48,  48,  48],\n",
      "          [-47, -47, -47,  ...,  48,  48,  48]],\n",
      "\n",
      "         [[ 87,  87,  87,  ..., 106, 106, 106],\n",
      "          [ 87,  87,  87,  ..., 106, 106, 106],\n",
      "          [ 87,  87,  87,  ..., 106, 106, 106],\n",
      "          ...,\n",
      "          [-42, -42, -42,  ...,  36,  36,  36],\n",
      "          [-42, -42, -42,  ...,  36,  36,  36],\n",
      "          [-42, -42, -42,  ...,  36,  36,  36]],\n",
      "\n",
      "         [[121, 121, 121,  ..., 124, 124, 124],\n",
      "          [121, 121, 121,  ..., 124, 124, 124],\n",
      "          [121, 121, 121,  ..., 124, 124, 124],\n",
      "          ...,\n",
      "          [ -9,  -9,  -9,  ...,  55,  55,  55],\n",
      "          [ -9,  -9,  -9,  ...,  55,  55,  55],\n",
      "          [ -9,  -9,  -9,  ...,  55,  55,  55]]],\n",
      "\n",
      "\n",
      "        [[[-14, -14, -14,  ..., -64, -64, -64],\n",
      "          [-14, -14, -14,  ..., -64, -64, -64],\n",
      "          [-14, -14, -14,  ..., -64, -64, -64],\n",
      "          ...,\n",
      "          [ 40,  40,  40,  ..., -43, -43, -43],\n",
      "          [ 40,  40,  40,  ..., -43, -43, -43],\n",
      "          [ 40,  40,  40,  ..., -43, -43, -43]],\n",
      "\n",
      "         [[  2,   2,   2,  ..., -45, -45, -45],\n",
      "          [  2,   2,   2,  ..., -45, -45, -45],\n",
      "          [  2,   2,   2,  ..., -45, -45, -45],\n",
      "          ...,\n",
      "          [ 22,  22,  22,  ..., -35, -35, -35],\n",
      "          [ 22,  22,  22,  ..., -35, -35, -35],\n",
      "          [ 22,  22,  22,  ..., -35, -35, -35]],\n",
      "\n",
      "         [[-29, -29, -29,  ..., -72, -72, -72],\n",
      "          [-29, -29, -29,  ..., -72, -72, -72],\n",
      "          [-29, -29, -29,  ..., -72, -72, -72],\n",
      "          ...,\n",
      "          [  7,   7,   7,  ..., -60, -60, -60],\n",
      "          [  7,   7,   7,  ..., -60, -60, -60],\n",
      "          [  7,   7,   7,  ..., -60, -60, -60]]],\n",
      "\n",
      "\n",
      "        [[[-66, -66, -66,  ..., -63, -63, -63],\n",
      "          [-66, -66, -66,  ..., -63, -63, -63],\n",
      "          [-66, -66, -66,  ..., -63, -63, -63],\n",
      "          ...,\n",
      "          [-55, -55, -55,  ...,   6,   6,   6],\n",
      "          [-55, -55, -55,  ...,   6,   6,   6],\n",
      "          [-55, -55, -55,  ...,   6,   6,   6]],\n",
      "\n",
      "         [[-37, -37, -37,  ..., -39, -39, -39],\n",
      "          [-37, -37, -37,  ..., -39, -39, -39],\n",
      "          [-37, -37, -37,  ..., -39, -39, -39],\n",
      "          ...,\n",
      "          [-66, -66, -66,  ..., -29, -29, -29],\n",
      "          [-66, -66, -66,  ..., -29, -29, -29],\n",
      "          [-66, -66, -66,  ..., -29, -29, -29]],\n",
      "\n",
      "         [[ -7,  -7,  -7,  ...,  -8,  -8,  -8],\n",
      "          [ -7,  -7,  -7,  ...,  -8,  -8,  -8],\n",
      "          [ -7,  -7,  -7,  ...,  -8,  -8,  -8],\n",
      "          ...,\n",
      "          [-80, -80, -80,  ..., -38, -38, -38],\n",
      "          [-80, -80, -80,  ..., -38, -38, -38],\n",
      "          [-80, -80, -80,  ..., -38, -38, -38]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          ...,\n",
      "          [127, 127, 127,  ...,  93,  93,  93],\n",
      "          [127, 127, 127,  ...,  93,  93,  93],\n",
      "          [127, 127, 127,  ...,  93,  93,  93]],\n",
      "\n",
      "         [[127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          ...,\n",
      "          [127, 127, 127,  ...,  36,  36,  36],\n",
      "          [127, 127, 127,  ...,  36,  36,  36],\n",
      "          [127, 127, 127,  ...,  36,  36,  36]],\n",
      "\n",
      "         [[127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          ...,\n",
      "          [127, 127, 127,  ..., -10, -10, -10],\n",
      "          [127, 127, 127,  ..., -10, -10, -10],\n",
      "          [127, 127, 127,  ..., -10, -10, -10]]],\n",
      "\n",
      "\n",
      "        [[[127, 127, 127,  ...,  87,  87,  87],\n",
      "          [127, 127, 127,  ...,  87,  87,  87],\n",
      "          [127, 127, 127,  ...,  87,  87,  87],\n",
      "          ...,\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127]],\n",
      "\n",
      "         [[127, 127, 127,  ...,  57,  57,  57],\n",
      "          [127, 127, 127,  ...,  57,  57,  57],\n",
      "          [127, 127, 127,  ...,  57,  57,  57],\n",
      "          ...,\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127]],\n",
      "\n",
      "         [[127, 127, 127,  ...,  28,  28,  28],\n",
      "          [127, 127, 127,  ...,  28,  28,  28],\n",
      "          [127, 127, 127,  ...,  28,  28,  28],\n",
      "          ...,\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127],\n",
      "          [127, 127, 127,  ..., 127, 127, 127]]],\n",
      "\n",
      "\n",
      "        [[[-65, -65, -65,  ..., -40, -40, -40],\n",
      "          [-65, -65, -65,  ..., -40, -40, -40],\n",
      "          [-65, -65, -65,  ..., -40, -40, -40],\n",
      "          ...,\n",
      "          [-76, -76, -76,  ..., -45, -45, -45],\n",
      "          [-76, -76, -76,  ..., -45, -45, -45],\n",
      "          [-76, -76, -76,  ..., -45, -45, -45]],\n",
      "\n",
      "         [[-67, -67, -67,  ..., -27, -27, -27],\n",
      "          [-67, -67, -67,  ..., -27, -27, -27],\n",
      "          [-67, -67, -67,  ..., -27, -27, -27],\n",
      "          ...,\n",
      "          [-69, -69, -69,  ..., -29, -29, -29],\n",
      "          [-69, -69, -69,  ..., -29, -29, -29],\n",
      "          [-69, -69, -69,  ..., -29, -29, -29]],\n",
      "\n",
      "         [[-42, -42, -42,  ..., -16, -16, -16],\n",
      "          [-42, -42, -42,  ..., -16, -16, -16],\n",
      "          [-42, -42, -42,  ..., -16, -16, -16],\n",
      "          ...,\n",
      "          [-53, -53, -53,  ..., -14, -14, -14],\n",
      "          [-53, -53, -53,  ..., -14, -14, -14],\n",
      "          [-53, -53, -53,  ..., -14, -14, -14]]]], dtype=torch.int8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1632564/1080809384.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  quant_data = torch.tensor(next_data/scale + zero_tensor, dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization.observer import HistogramObserver\n",
    "\n",
    "activation_observer = HistogramObserver(quant_max=127, quant_min=-128)\n",
    "quant_data = activation_observer(next_data)\n",
    "\n",
    "scale, zero_tensor = activation_observer.calculate_qparams()\n",
    "# print(next_data[0])\n",
    "print(f\"scale shape {scale.shape}, zero_tensor shape {zero_tensor.shape}\")\n",
    "# print(scale)\n",
    "# print(quant_data[0])\n",
    "quant_data = torch.tensor(next_data/scale + zero_tensor, dtype=torch.int8)\n",
    "print(quant_data)\n",
    "# quantized_data = torch.quantize_per_tensor(next_data, scale=scale, zero_point=zero_tensor, dtype=torch.quint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]/tmp/ipykernel_1632564/161881618.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  imgs = torch.tensor(data[0].clone().detach()*256-128, dtype=torch.int8)\n",
      "/workspace/int_infer/models/layers.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x/scale + zero_tensor, dtype=torch.int8)\n",
      "100%|██████████| 313/313 [22:08<00:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test result : 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "int_model.eval()\n",
    "int_model.cuda()\n",
    "val_acc = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(tqdm(val_loader,leave=True)):\n",
    "        # imgs = torch.tensor(data[0].clone().detach()*256-128, dtype=torch.int8)\n",
    "        # imgs = torch.tensor(data[0].clone().detach(), dtype=torch.int8)\n",
    "        imgs = torch.tensor(data[0].clone().detach()/0.0079, dtype=torch.int8)\n",
    "        # print(f\"{imgs.shape} {imgs.max()} {imgs.min()}\\n{imgs[0]}\")\n",
    "        # break\n",
    "        imgs = imgs.permute(0,2,3,1)\n",
    "        imgs = torch.cat([imgs, torch.zeros((data[0].size(0),224,224,1), dtype=torch.int8)], dim=-1)\n",
    "        imgs, target = imgs.to(device), data[1].to(device)\n",
    "        imgs = imgs.contiguous()\n",
    "        output = int_model(imgs)\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        val_acc += (preds==target).sum().item()\n",
    "\n",
    "val_acc = 100. * val_acc/len(val_loader.dataset)\n",
    "print(f\"test result : {val_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[0.008759161457419395, -0.0178440622985363, -0.09593403339385986, 0.12288951873779297, 0.020521938800811768, -0.03415032476186752, 0.02355372905731201, 0.13821575045585632, 0.020333409309387207, -0.041939061135053635, 0.04385018348693848, 0.0065469942055642605, -0.1620417684316635, 0.082347571849823, 0.011041621677577496, -0.021648269146680832, 0.0951804518699646, 0.06051504611968994, -0.12392546981573105, 0.15390729904174805, 0.05739015340805054, 0.11025568097829819, 0.05284913629293442, -0.11278872191905975, 0.13263504207134247, -0.12580464780330658, -0.03596339747309685, -0.12103458493947983, 0.010289093479514122, -0.15330931544303894, -0.0022844872437417507, 0.10146620124578476, 0.07966969907283783, -0.14248761534690857, -0.12187262624502182, -0.03265492245554924, -0.13812756538391113, -0.014480113983154297, -0.13433854281902313, -0.1463301181793213, -0.1411084234714508, 0.0837610587477684, 0.02245241403579712, -0.023088812828063965, 0.16052953898906708, 0.020677050575613976, 0.08343921601772308, -0.09759672731161118, -0.044395964592695236, -0.13563470542430878, -0.10690095275640488, -0.1590108573436737, -0.04487546533346176, 0.11135511100292206, 0.04039263725280762, 0.0889388918876648, 0.01594589278101921, -0.06985406577587128, 0.16069605946540833, -0.07616490125656128, 0.050551991909742355, -0.12063956260681152, 0.08251281827688217, 0.10372859239578247, 0.05412229150533676, -0.0952419638633728, -0.10222941637039185, -0.07760654389858246, 0.032252829521894455, 0.025858184322714806, 0.009751757606863976, 0.157865971326828, -0.07068628072738647, -0.08658605813980103, -0.06415790319442749, -0.11509235948324203, -0.051878493279218674, 0.12267212569713593, 0.08863411843776703, -0.04347715899348259, -0.08694332838058472, -0.013371090404689312, -0.006189306732267141, 0.02060435339808464, 0.010474225506186485, 0.08564184606075287, -0.040765803307294846, -0.05920104309916496, 0.12769965827465057, -0.09028375148773193, -0.13935326039791107, 0.09955476224422455, -0.03354179859161377, 0.11512657254934311, -0.10861007869243622, 0.07716546952724457, 0.03319285437464714, 0.03770514577627182, -0.07586395740509033, -0.08485263586044312, 0.012515723705291748, -0.11788105964660645, -0.04055223986506462, -0.1551637053489685, 0.10138857364654541, -0.1387280523777008, -0.15715733170509338, 0.0812150090932846, -0.03502067178487778, 0.026261111721396446, -0.034197114408016205, -0.11665932834148407, 0.05772026628255844, 0.014785210601985455, 0.14107763767242432, -0.12848713994026184, -0.0674351304769516, 0.12441925704479218, -0.06305577605962753, -0.14493036270141602, 0.15761318802833557, -0.15503647923469543, -0.0941401943564415, -0.06836265325546265, -0.009708642959594727, -0.10155316442251205, 0.061740975826978683, 0.05204731225967407, 0.02459542080760002, -0.05757421255111694, 0.007947444915771484, 0.030999919399619102, 0.13542704284191132, 0.09169334173202515, 0.16102854907512665, 0.06360729783773422, 0.13519227504730225, -0.15000101923942566, -0.042758744210004807, -0.10336756706237793, -0.14029471576213837, 0.06137877702713013, -0.10767817497253418, -0.04604834318161011, 0.14454147219657898, 0.030976474285125732, 0.1617097556591034, -0.04133770987391472, 0.05393326282501221, 0.10582506656646729, -0.014378389343619347, 0.1533002257347107, -0.16148284077644348, -0.11097007989883423, 0.07352417707443237, -0.16489335894584656, 0.057263314723968506, -0.13599878549575806, -0.10133987665176392, -0.14794956147670746, 0.145809143781662, -0.12260574102401733, -0.16651396453380585, 0.06821169704198837, -0.12329018115997314, 0.0014655392151325941, 0.11479544639587402, -0.13172858953475952, -0.13713327050209045, 0.07189717143774033, -0.030691903084516525, 0.06094614788889885, -0.08341120183467865, -0.05175779387354851, 0.11430972814559937, 0.026352684944868088, -0.04963837191462517, 0.09201016277074814, 0.07871447503566742, -0.14549624919891357, -0.10138394683599472, -0.015560667030513287, -0.020618360489606857, 0.14799532294273376, 0.11913027614355087, -0.049125611782073975, -0.08223267644643784, 0.06274561583995819, 0.13549160957336426, -0.07766088098287582, 0.006074031349271536, 0.010250985622406006, 0.07351994514465332, 0.15946784615516663, 0.08056171983480453, 0.12325962632894516, 0.07505445182323456, 0.1384892463684082, 0.04141785949468613, 0.006297191139310598, -0.09829890727996826, 0.08465292304754257, -0.1384156346321106, -0.07620768249034882, 0.1563752293586731, 0.09891321510076523, 0.15683816373348236, 0.019275188446044922, -0.01569509506225586, -0.012376110069453716, -0.008472880348563194, 0.019112547859549522, -0.02716219425201416, -0.019838135689496994, -0.14278152585029602, -0.09203958511352539, 0.07946693897247314, 0.14111201465129852, 0.01277885865420103, 0.14775517582893372, -0.0870589017868042, -0.03363591432571411, 0.047269344329833984, 0.017932435497641563, -0.01699727773666382, -0.13197430968284607, -0.07657557725906372, -0.09288432449102402, -0.010073463432490826, 0.038928329944610596, -0.10232280194759369, -0.1216576099395752, -0.03675917908549309, 0.00030795735074207187, -0.07384364306926727, 0.09299510717391968, -0.028810879215598106, -0.13194796442985535, 0.06587740033864975, 0.023216765373945236, -0.031086286529898643, 0.05206231400370598, -0.15693484246730804, -0.0575503334403038, -0.1400206983089447, 0.0036846399307250977, 0.13278917968273163, 0.06240646168589592, 0.15295857191085815, 0.03180494159460068, 0.07081566751003265, 0.15683645009994507, -0.14041689038276672, 0.09722521156072617, -0.09112636744976044, 0.1241709440946579, -0.0688418596982956, 0.08994068950414658, 0.028386157006025314, -0.08518978208303452, 0.16246943175792694, -0.1621883362531662, 0.14025245606899261, 0.1348644345998764, -0.04375886917114258, -0.14612048864364624, 0.05685073137283325, 0.13467100262641907, 0.15068446099758148, -0.10300978273153305, -0.0023327271919697523, 0.14332333207130432, -0.10144166648387909, 0.10952238738536835, 0.014478246681392193, 0.05333225056529045, -0.06860264390707016, -0.153685063123703, 0.006133993621915579, -0.09207036346197128, -0.005502760410308838, 0.060899317264556885, 0.12844938039779663, 0.14812207221984863, 0.04049241542816162, -0.007304152008146048, -0.15561547875404358, 0.13332605361938477, -0.056614916771650314, -0.02654663845896721, -0.1055738553404808, -0.059911273419857025, 0.05308143422007561, -0.052950501441955566, 0.016848742961883545, -0.12349957227706909, 0.06628173589706421, 0.04737623780965805, -0.0928909182548523, -0.15657109022140503, 0.0472949743270874, -0.017973443493247032, 0.1346098780632019, -0.030691247433423996, -0.011661073192954063, -0.09499143064022064, -0.07491996139287949, -0.09802123159170151, 0.051615159958601, 0.03031015396118164, -0.10599648952484131, -0.017383813858032227, -0.08796954154968262, -0.1213366836309433, 0.09023424237966537, -0.03497551009058952, 0.041752319782972336, 0.155784010887146, -0.15918515622615814, 0.15248124301433563, 0.07403826713562012, 0.07645724713802338, 0.15692882239818573, -0.013017972931265831, 0.12016686052083969, 0.026269039139151573, 0.044596634805202484, -0.0856817364692688, -0.05024212598800659, -0.12382354587316513, 0.06903158128261566, -0.09959660470485687, -0.08721822500228882, -0.09181563556194305, -0.1471347212791443, -0.046445708721876144, -0.07559865713119507, 0.08842580020427704, 0.0350126251578331, 0.08094042539596558, -0.0015707015991210938, -0.16036543250083923, -0.16040024161338806, 0.12182275950908661, 0.03800821304321289, -0.030032694339752197, 0.05592789500951767, -0.1314442753791809, 0.07892948389053345, -0.11715175956487656, 0.1616773009300232, -0.037414949387311935, -0.008249660953879356, 0.10021039098501205, -0.1354626715183258, 0.10130858421325684, 0.040523987263441086, -0.03703395649790764, 0.07723268121480942, 0.04869475215673447, 0.0829341858625412, -0.06732289493083954, 0.08620484918355942, -0.08830293267965317, 0.05434030294418335, 0.157909095287323, -0.16254159808158875, -0.069497250020504, -0.0906836986541748, 0.13541507720947266, 0.04046442359685898, -0.08222943544387817, 0.1504378616809845, -0.001621206640265882, 0.0540793351829052, 0.07342662662267685, -0.09549850225448608, -0.025050899013876915, -0.1343669295310974, 0.03966526314616203, 0.02881191298365593, -0.10487034171819687, -0.024214308708906174, -0.15063315629959106, 0.04256115481257439, -0.011359035968780518, -0.04833569377660751, 0.1367187350988388, -0.09918145835399628, -0.060803912580013275, 0.01967102289199829, 0.1155719980597496, -0.13227753341197968, 0.06700321286916733, 0.04099458456039429, -0.05018129199743271, -0.11118364334106445, -0.1412935107946396, 0.02867060899734497, -0.0420471653342247, 0.12486320734024048, -0.00389484572224319, 0.12161435931921005, 0.14678317308425903, -0.11970214545726776, -0.12725238502025604, -0.022360622882843018, 0.14926086366176605, -0.03937767073512077, -0.0860084742307663, -0.11870793998241425, 0.025350650772452354, -0.12395702302455902, 0.12067749351263046, -0.07963564246892929, 0.05874814838171005, 0.021171510219573975, -0.16081926226615906, 0.0016570886364206672, -0.1639954298734665, -0.14653033018112183, 0.12444095313549042, 0.0031618475914001465, 0.041163407266139984, -0.07894548028707504, -0.16556769609451294, 0.0316675528883934, 0.13215979933738708, -0.06624462455511093, 0.14540722966194153, 0.05963744968175888, -0.030071895569562912, 0.16238075494766235, -0.09514105319976807, -0.11033906787633896, 0.10042107105255127, 0.021266957744956017, -0.15616756677627563, 0.09425034373998642, 0.059085946530103683, 0.1349916160106659, -0.12990687787532806, -0.14699135720729828, 0.10193799436092377, -0.004748523235321045, -0.07243543863296509, 0.08397110551595688, -0.015682538971304893, 0.06082288548350334, 0.09079480171203613, -0.1279815435409546, -0.07833296060562134, 0.11501225084066391, -0.07361327111721039, 0.16412663459777832, 0.0454542450606823, -0.03779196739196777, 0.06937830150127411, 0.09448133409023285, 0.06585311889648438, 0.014097988605499268, 0.11393134295940399, -0.11121588945388794, -0.13225007057189941, -0.06017933413386345, 0.015880465507507324, 0.13610753417015076, 0.11006945371627808, -0.05944514274597168, -0.07686901092529297, 0.16014400124549866, 0.04925283044576645, 0.05887749046087265, -0.06336408853530884, 0.1180240735411644, 0.14042560756206512, 0.05433199927210808, -0.02525518462061882, -0.1257481426000595, -0.061443131417036057, 0.026652416214346886, 0.05376472324132919, 0.10962831974029541, 0.05674831196665764, -0.14812086522579193, 0.16302303969860077, -0.15616118907928467, 0.09016134589910507, -0.06383174657821655, 0.0737079381942749, 0.11937958002090454, -0.14416097104549408, 0.16621528565883636, -0.11951076984405518, 0.006350298877805471, 0.14008943736553192, 0.1525869369506836, -0.07867246866226196, 0.0665016621351242, -0.07390745729207993, -0.07419558614492416, 0.10597946494817734, -0.0166538767516613, -0.07842352241277695, 0.04467654228210449, 0.14891807734966278, 0.018032550811767578, 0.09594827890396118, 0.05647744983434677, 0.07874932140111923, -0.07673095166683197, 0.1494363248348236, -0.017927031964063644, 0.01581730507314205, -0.06873029470443726, 0.13708093762397766, -0.14289407432079315, -0.08001933991909027, 0.1562677025794983, -0.052322130650281906, 0.13304173946380615, -0.0506715402007103, 0.051684003323316574, 0.010068854317069054, 0.06924138963222504, 0.07426087558269501, -0.10884269326925278, -0.08561760187149048, -0.15927091240882874, 0.13044242560863495, -0.13411018252372742, 0.09092170000076294, 0.1606108844280243, -0.15115663409233093, -0.07065260410308838, 0.11482733488082886, 0.16325339674949646, -0.01856641098856926, 0.0036860904656350613, -0.09175523370504379, 0.12476897239685059, 0.05028150603175163, -0.08481290191411972, -0.07781227678060532, -0.028643548488616943, -0.1274896264076233, -0.09900407493114471, 0.12864476442337036, -0.14263281226158142, -0.038293879479169846, 0.1651187241077423, -0.14238229393959045, 0.034978192299604416, 0.04966394230723381, -0.07071717828512192, -0.16605937480926514, -0.12609253823757172, -0.07856154441833496, -0.09971915185451508, -0.02075704000890255, -0.16133016347885132, -0.1084180474281311, -0.07536940276622772, 0.017117321491241455, 0.04371333122253418, 0.07052620500326157, -0.08855706453323364, 0.04503719136118889, -0.16460219025611877, 0.08010061830282211, 0.13496121764183044, -0.11475571244955063, 0.1026405543088913, -0.15911409258842468, -0.08780010789632797, 0.04023643583059311, 0.11822056770324707, 0.06048216670751572, 0.09092708677053452, 0.1438767910003662, -0.08504732698202133, -0.12324472516775131, -0.044082045555114746, 0.02661607787013054, -0.054122112691402435, 0.1338445395231247, -0.019528549164533615, 0.1495048850774765, 0.06917967647314072, 0.12250488996505737, 0.08345162868499756, 0.14927339553833008, -0.16336505115032196, -0.06051647663116455, -0.13765963912010193, 0.11545827239751816, -0.14340156316757202, 0.09245821088552475, 0.08698713779449463, -0.12085972726345062, -0.0815083384513855, 0.018396973609924316, -0.09860508143901825, -0.0025666356086730957, 0.01916172169148922, -0.09484146535396576, 0.026651781052350998, 0.12038572877645493, 0.022564690560102463, -0.14214538037776947, -0.14962634444236755, -0.15033017098903656, 0.0448840856552124, -0.13615421950817108, -0.09295203536748886, 0.017023107036948204, 0.12954966723918915, -0.09094224870204926, 0.12258084863424301, -0.14260688424110413, -0.10344760119915009, -0.09042771905660629, -0.10268636792898178, -0.09545104205608368, -0.05172368139028549, 0.15667055547237396, -0.03584979102015495, -0.13119840621948242, -0.14968165755271912, -0.01176120899617672, -0.14636635780334473, 0.12099039554595947, 0.08246026933193207, -0.1633416712284088, -0.1306007355451584, 0.020286520943045616, -0.10045351833105087, 0.13497281074523926, 0.012816986069083214, -0.10517480224370956, 0.05662773177027702, 0.003617803333327174, -0.04334060475230217, 0.03985937684774399, 0.08031606674194336, 0.014877697452902794, 0.07536475360393524, -0.032558463513851166, 0.01088599395006895, 0.14515982568264008, -0.07490704953670502, 0.11371153593063354, 0.07557427883148193, 0.016180019825696945, 0.0880785807967186, 0.04785321280360222, -0.04015431925654411, -0.005178987979888916, -0.07556083053350449, -0.02323216199874878, 0.05960094928741455, 0.09328190982341766, -0.13232102990150452, -0.09064622968435287, 0.1452716439962387, 0.1325235217809677, -0.12587414681911469, -0.012597898952662945, 0.14662957191467285, 0.10497087240219116, 0.11386426538228989, -0.012098371982574463, 0.00947610568255186, -0.04611041396856308, 0.06365489959716797, -0.07402028888463974, 0.10253989696502686, -0.15593478083610535, 0.012647530063986778, -0.09808611869812012, 0.1090119481086731, 0.1185688003897667, 0.13975712656974792, -0.10089822858572006, -0.12442537397146225, -0.1008116826415062, 0.08909374475479126, 0.023013055324554443, 0.042672932147979736, 0.07477639615535736, 0.11103551089763641, -0.16225704550743103, 0.11143191903829575, -0.030601363629102707, 0.04472001641988754, 0.14219383895397186, -0.14327262341976166, -0.08118587732315063, 0.055709682404994965, 0.009573201648890972, 0.02944405935704708, 0.08300362527370453, 0.14017555117607117, -0.16485324501991272, -0.11857213824987411, 0.04921136423945427, -0.12069650739431381, -0.122903011739254, -0.13204368948936462, 0.024206578731536865, -0.004895707126706839, 0.06272413581609726, 0.15420770645141602, -0.1652517020702362, 0.05315643548965454, 0.054154299199581146, 0.09762036800384521, 0.056459926068782806, 0.04694974422454834, 0.07847084850072861, -0.07135321944952011, 0.16346994042396545, 0.09050236642360687, -0.06299799680709839, -0.01338738203048706, -0.06660483777523041, -0.01966937445104122, -0.13396427035331726, 0.10728184878826141, -0.033956609666347504, 0.08934646844863892, -0.12106090784072876, -0.1174723356962204, -0.032450221478939056, -0.006320357322692871, 0.05682351440191269, 0.02431597374379635, -0.10125013440847397, -0.06828071922063828, -0.05331047624349594, 0.1032569408416748, -0.04784119129180908, -0.01800559088587761, -0.07041847705841064, -0.029096942394971848, 0.09754540771245956, -0.03187219426035881, 0.07327556610107422, 0.05703437328338623, 0.01931653544306755, -0.12728196382522583, 0.10064604133367538, 0.14823168516159058, -0.02995864674448967, -0.015969952568411827, 0.15598975121974945, 0.07232445478439331, -0.16154149174690247, 0.025971531867980957, -0.0352381095290184, 0.08108294010162354, -0.07145857810974121, 0.13056433200836182, 0.08596597611904144, 0.06159764528274536, 0.09236916154623032, 0.047120850533246994, -0.14124009013175964, 0.1042584627866745, 0.13404792547225952, -0.024857740849256516, -0.1436251997947693, 0.01975737139582634, 0.03483983129262924, 0.033635299652814865, 0.08667188882827759, -0.16481797397136688, 0.08606021106243134, 0.15755224227905273, 0.02902344986796379, 0.03145643323659897, -0.07951883971691132, -0.09150522947311401, -0.08094775676727295, -0.14673539996147156, 0.12215475738048553, -0.036591850221157074, 0.08954974263906479, 0.05695875734090805, -0.06273563951253891, -0.08992932736873627, -0.10923425853252411, 0.04153186082839966, -0.0907847136259079, -0.10406899452209473, 0.09990628808736801, 0.09523048251867294, -0.1096830815076828, 0.021276971325278282, 0.14163222908973694, -0.10652904212474823, -0.15519008040428162, -0.04784474894404411, -0.1397087574005127, 0.1115286573767662, 0.15068498253822327, 0.0521976575255394, -0.03997129201889038, 0.03722425550222397, 0.0503365620970726, 0.07192270457744598, 0.15216341614723206, 0.14505599439144135, -0.13296793401241302, -0.11500229686498642, -0.11330827325582504, 0.011120498180389404, -0.0428253635764122, -0.0340319499373436, 0.16447733342647552, 0.10595135390758514, -0.16399604082107544, 0.023809513077139854, -0.018764059990644455, -0.0937679260969162, 0.15228287875652313, 0.11072421073913574, 0.030169367790222168, 0.05254092067480087, -0.06578247249126434, -0.06438889354467392, 0.056774359196424484, -0.022763073444366455, -0.12204977124929428, 0.010047058574855328, -0.10574029386043549, -0.03129921481013298, 0.1631735861301422, 0.14991313219070435, 0.16567134857177734, -0.0929800495505333, 0.013888697139918804, 0.15187734365463257, 0.13487890362739563, -0.13189446926116943, 0.03586975857615471, 0.004206041805446148, 0.1629456877708435, -0.07020314782857895, 0.028174620121717453, -0.0910281389951706, 0.1555013507604599, 0.07362943887710571, -0.06656180322170258, -0.16018550097942352, 0.13675731420516968, -0.08355897665023804, -0.13264861702919006, 0.057641349732875824, -0.03296780586242676, -0.11109580844640732, -0.13446079194545746, -0.11500672996044159, -0.026767035946249962, -0.04798301309347153, -0.06826861947774887, 0.032348595559597015, 0.06765719503164291, -0.16578267514705658, -0.07243712991476059, -0.09912004321813583, 0.10095125436782837, 0.13527804613113403, -0.021906932815909386, 0.1473219096660614, 0.14135363698005676, 0.10673606395721436, -0.11794297397136688, -0.04898182675242424, 0.10063070058822632, -0.14835022389888763, 0.13330504298210144, -0.08996737003326416, 0.06518413871526718, 0.03642910718917847, -0.002376874443143606, 0.07666905969381332, -0.05987773463129997, 0.09665614366531372, -0.014451822265982628, 0.11284603923559189, 0.020889639854431152, -0.01598568819463253, 0.0732913464307785, 0.08002617210149765, 0.06929372251033783, -0.002412955043837428, 0.03473168611526489, -0.01554665993899107, -0.07324483245611191, -0.06298649311065674, -0.13505880534648895, 0.160301074385643, -0.12321186065673828, -0.006748855113983154, 0.16659888625144958, -0.012408971786499023, 0.009760062210261822, 0.11828701198101044, 0.07359318435192108, 0.16137203574180603, -0.0022322337608784437, -0.009437164291739464, -0.05770919844508171, 0.08964284509420395, -0.09944359958171844, 0.14281266927719116, -0.022017579525709152, 0.129287451505661, -0.13932523131370544, -0.10814323276281357, -0.08531628549098969, -0.09882986545562744, 0.017899494618177414, 0.004398365970700979, 0.10351397842168808, 0.011898200027644634, 0.144768625497818, -0.09143024682998657, 0.05814508721232414, 0.08704966306686401, -0.04434593766927719, -0.02949325367808342, 0.040037911385297775, 0.027692656964063644, -0.07944347709417343, -0.15220706164836884, -0.0289164986461401, 0.006178935524076223, -0.06844314187765121, 0.023507755249738693, 0.06434272229671478, 0.15151672065258026, -0.016717275604605675, -0.03307992219924927, -0.08313848823308945, -0.15154781937599182, -0.060669660568237305, 0.04383277893066406, -0.07585243880748749, -0.1506529450416565, 0.10589127242565155, 0.10422629117965698, 0.032606761902570724, 0.15078583359718323, -0.07086245715618134, -0.09119898080825806, 0.13148073852062225, 0.024758677929639816, -0.04051254317164421, 0.025267740711569786, -0.10078956931829453, 0.0801582932472229, 0.10576361417770386, 0.033949851989746094, 0.13005052506923676, 0.09584828466176987, 0.13145259022712708, -0.14070849120616913, -0.11467069387435913, 0.003457109211012721, 0.03980795666575432, -0.1494768112897873, 0.09676407277584076, 0.07470391690731049, 0.165128692984581, -0.06656605005264282, -0.11260581016540527, 0.1421719193458557, 0.010991713032126427, 0.09380042552947998, -0.07103794813156128, 0.12745694816112518, -0.013389031402766705, -0.0395122766494751, -0.019578974694013596, 0.013244092464447021, 0.06561118364334106, -0.0746464729309082, -0.16244417428970337, 0.07898398488759995, 0.1611398458480835, -0.11559820175170898, 0.08245265483856201, -0.12500959634780884, -0.10567202419042587, -0.06407736241817474, -0.08507995307445526, 0.118852898478508, -0.053530674427747726, -0.1464891880750656, -0.1205677017569542, 0.0354280099272728, -0.16381405293941498, 0.16492512822151184, -0.009230813011527061, -0.05000343173742294, -0.011220475658774376, 0.09079957008361816, -0.04156790301203728, -0.11609910428524017, 0.1221848577260971, 0.06904064118862152, 0.05273115634918213, 0.10115741193294525, -0.08480332791805267, 0.08626663684844971, -0.1475953310728073, -0.055780213326215744, 0.15504895150661469, -0.15808795392513275, -0.15965962409973145, 0.00011316935706418008, 0.07579581439495087, 0.07186748832464218, 0.08610379695892334, -0.06866761296987534, -0.028180083259940147, -0.15011940896511078, 0.0648566335439682, 0.1157606691122055, -0.0562996082007885, -0.0973673090338707, -0.08081173896789551, 0.05875033140182495, 0.12223953008651733, -0.11458911746740341, 0.11569565534591675, -0.14017146825790405, 0.019456028938293457, -0.06636369228363037, -0.02659263275563717, -0.10693087428808212, 0.02023226022720337, 0.0012770891189575195, -0.12787532806396484, -0.10919559001922607, 0.10520970821380615, -0.11945565789937973, 0.02955029532313347, 0.0439167246222496, 0.057453595101833344, -0.004274964332580566, 0.07289791107177734, -0.07190495729446411, 0.11797937005758286, -0.1469748318195343, -0.13009941577911377, -0.04666892811655998, -0.10741561651229858, 0.14149561524391174, -0.027753353118896484, 0.07884865999221802, 0.10819286108016968, -0.0998571515083313, 0.12421777099370956, 0.07294370979070663, -0.15988042950630188, -0.031715452671051025, -0.10932493209838867, -0.042477987706661224, 0.056512437760829926, 0.08339675515890121, 0.08289897441864014, -0.0026942293625324965, -0.06448523700237274, 0.135725200176239, -0.08990614116191864, 0.15422531962394714, -0.16067048907279968, 0.04437025636434555, 0.011909942142665386, 0.03306514024734497, 0.10659746825695038, 0.13214805722236633, 0.13613806664943695, 0.03184690326452255, 0.1108556017279625, 0.1595877707004547, -0.11827286332845688, -0.14033186435699463, -0.0492449626326561, -0.07082796096801758, -0.06195225566625595, -0.06847524642944336, -0.1379523128271103, -0.1414194107055664, -0.002974828239530325, 0.16297921538352966, 0.01748524233698845, -0.1600409597158432, -0.10148994624614716, 0.0024208426475524902, -0.10480409860610962, -0.02804633043706417, 0.15842096507549286, 0.14124201238155365, -0.07154606282711029, -0.08379590511322021, -0.09926585853099823, -0.07383130490779877, 0.03044937178492546, -0.08670556545257568, 0.10957776010036469, 0.08993544429540634, -0.05911242961883545, -0.11836346238851547, 0.06294149160385132, -0.15767955780029297, 0.02120065689086914, 0.042720358818769455, 0.030927419662475586, 0.05217454954981804, -0.1551123857498169, -0.07651524245738983, 4.653136056731455e-05, -0.16251173615455627, -0.15676693618297577, -0.08163559436798096, 0.16156348586082458, 0.16378162801265717, 0.01422456931322813, -0.13263027369976044, 0.09666141122579575, -0.022178232669830322, 0.020931443199515343, -0.062372706830501556, -0.02886698767542839, -0.025488337501883507, -0.1571696400642395, -0.12488073110580444, 0.06818054616451263, 0.04966960474848747, 0.10827028751373291, 0.08439958095550537, 0.06194518133997917, 0.07025818526744843, 0.15510228276252747, 0.022836586460471153, -0.049448490142822266, 0.1529441922903061, 0.030702194198966026, -0.013179361820220947, -0.15402023494243622, 0.13416384160518646, 0.15201762318611145, -0.12213589996099472, 0.13505588471889496, 0.1257900446653366, -0.06463025510311127, -0.038228850811719894, 0.012126704677939415, -0.15486252307891846, 0.05645974725484848, 0.14595311880111694, -0.1647728681564331, 0.14285211265087128, 0.006693542003631592, 0.08889371156692505, 0.012177607044577599, 0.08969789743423462, -0.05031400918960571, 0.03402825444936752, -0.10196511447429657, -0.07738077640533447, 0.13896048069000244, 0.07812021672725677, 0.09750646352767944, 0.0006037752027623355, -0.0035164952278137207, -0.13571427762508392, 0.03521716594696045, -0.06081897020339966, 0.13853663206100464, 0.05453455448150635, 0.08693423122167587, 0.07646028697490692, 0.10031794011592865, -0.04656122252345085, -0.04857047647237778, 0.00862071942538023, -0.15842032432556152, 0.15253888070583344, 0.029383063316345215, 0.15602950751781464, 0.06572318077087402, 0.13791200518608093, 0.1607164591550827, -0.005753259174525738, -0.09682735055685043, -0.1611044853925705, 0.0007326205959543586, -0.07167170941829681, -0.1224026083946228, 0.11335806548595428, -0.049213211983442307, 0.08053362369537354, -0.03909701108932495, -0.09177204221487045, 0.12269105762243271, 0.14619523286819458, -0.03260773420333862, 0.09559746831655502, 0.05741669982671738, -0.06280750036239624, 0.11154230684041977, 0.15966551005840302, 0.05251403898000717, 0.11687952280044556, -0.03220721334218979, -0.1641722172498703, 0.0071667833253741264, 0.0869680643081665, 0.08141698688268661, 0.1500520408153534, 0.13661304116249084, -0.10587470233440399, -0.1516190618276596, -0.12750068306922913, -0.009339829906821251, -0.14623233675956726, -0.03330361843109131, 0.0965304970741272, 0.05691772699356079, 0.15479624271392822, 0.08422502130270004, -0.09359978139400482, -0.09896060079336166, -0.03990723937749863, 0.12627586722373962, -0.1386873573064804, -0.05188123509287834, -0.11815333366394043, 0.09555566310882568, 0.08929048478603363, -0.15034106373786926, 0.09227796643972397, -0.11825267970561981, -0.06378432363271713, -0.1262710690498352, 0.11117389053106308, -0.03788314387202263, 0.05294283479452133, 0.012549340724945068, 0.052137017250061035, 0.036006372421979904, -0.14759115874767303, -0.07023519277572632, 0.07511234283447266, 0.06936734914779663, -0.102658711373806, 0.01734318397939205, -0.023909887298941612, -0.003336489200592041, -0.05732905864715576, 0.11841726303100586, 0.07782423496246338, -0.014168858528137207, -0.12455481290817261, -0.12013189494609833, 0.15301001071929932, 0.09437114000320435, -0.09181185811758041, -0.12184280157089233, -0.09636902809143066, 0.156352698802948, -0.07573523372411728, -0.03772252798080444, 0.013383905403316021, -0.13892239332199097, 0.15352974832057953, 0.06715407222509384, -0.006304045673459768, 0.1342555284500122, -0.049256205558776855, -0.15687164664268494, 0.06271964311599731, 0.09767323732376099, -0.04493590444326401, -0.12198793888092041, 0.03367652744054794, -0.06913428008556366, -0.14254961907863617, 0.09770230948925018, 0.026493053883314133, 0.03285137936472893, 0.025066157802939415, -0.11518311500549316, 0.023868581280112267, -0.1265784502029419, 0.031396351754665375, -0.11378902196884155, -0.052055101841688156, -0.0255536250770092, -0.029175063595175743, 0.08238361775875092, -0.05276775360107422, -0.01581684872508049, -0.07548433542251587, -0.11838378757238388, 0.07121177762746811, -0.0028811097145080566, 0.05566108226776123, -0.01574883982539177, 0.1598602533340454, -0.1029844731092453, 0.02629276178777218, 0.08979421854019165, 0.07932251691818237, 0.0947950929403305, -0.08090768754482269, 0.1661597341299057, -0.08352109044790268, 0.12140928208827972, 0.09672951698303223, -0.1295360028743744, -0.08639039844274521, 0.0020937323570251465, -0.08160637319087982, -0.04993496462702751, 0.0067801279947161674, -0.08845019340515137, 0.043375711888074875, -0.010422627441585064, -0.08836885541677475, -0.00017110507178585976, 0.11528205871582031, 0.06912662833929062, -0.008043686859309673, -0.028157969936728477, -0.04123846814036369, -0.03318192809820175, 0.045160651206970215, -0.10120471566915512, -0.035611629486083984, 0.15274958312511444, -0.1651066392660141, -0.05772324651479721, 0.15698616206645966, -0.11026611179113388, 0.005494058132171631, 0.07168015092611313, 0.054573338478803635, -0.15172764658927917, 0.0013377070426940918, -0.0358610562980175, -0.12854287028312683, -0.02399488352239132, -0.08608752489089966, -0.13657128810882568, 0.02030569314956665, -0.08283718675374985, 0.02338532730937004, -0.006949623581022024, -0.07437115907669067, 0.1287585198879242, -0.101296566426754, 0.06822310388088226, -0.09316907823085785, 0.06940281391143799, 0.1355469822883606, 0.003457923885434866, -0.15963688492774963, 0.15578868985176086, 0.12256644666194916, 0.1170932874083519, 0.02265113592147827, 0.07198741286993027, -0.06818187236785889, 0.07457717508077621, 0.11650218814611435, 0.12597543001174927, 0.10516007989645004, 0.1158236712217331, 0.05698243901133537, -0.057369332760572433, -0.13417235016822815, -0.0966891273856163, 0.16313716769218445, -0.08592621982097626, 0.13557247817516327, 0.004591067787259817, 0.1656877100467682, -0.10234930366277695, -0.07705557346343994, -0.014548301696777344, 0.09298932552337646, -0.04875147342681885, 0.09905022382736206, -0.14747487008571625, -0.06850165128707886, 0.16577163338661194, -0.04435034841299057, 0.08550280332565308, 0.08207659423351288, 0.044989608228206635, -0.14462438225746155, 0.04342655465006828, 0.13374684751033783, -0.04346819967031479, 0.13553063571453094, 0.06601178646087646, 0.010520180687308311, -0.028117021545767784, 0.07610323280096054, 0.02845476195216179, -0.10277184098958969, -0.1420835256576538, -0.1296214461326599, 0.060203276574611664, -0.13849368691444397, -0.15283094346523285, 0.12105607986450195, -0.06875938177108765, 0.008311113342642784, -0.04371603578329086, 0.08320828527212143, 0.13437429070472717, -0.154459148645401, -0.09466499090194702, -0.03728044033050537, -0.1284189224243164, 0.09002654254436493, -0.041669152677059174, 0.14743934571743011, -0.07591001689434052, -0.14613652229309082, -0.00802578590810299, -0.12329908460378647, -0.0615185908973217, -0.007082879543304443, 0.11479449272155762, 0.0352051667869091, -0.06628604978322983, -0.09444426000118256, -0.1390334665775299, -0.1246512159705162, -0.048686783760786057, 0.11806490272283554, 0.007855555042624474, 0.03660845756530762, 0.052466511726379395, -0.09197632968425751, 0.11170750856399536, -0.0682496652007103, 0.14721368253231049, -0.10902576148509979, 0.13723145425319672, -0.13313478231430054, 0.004562298767268658, -0.004986207000911236, 0.0975721925497055, 0.16124281287193298, -0.035071514546871185, -0.14989027380943298, 0.034533899277448654, 0.07845340669155121, 0.06804977357387543, -0.004458705894649029, 0.1497078239917755, 0.1482754796743393, 0.05165370553731918, -0.08512550592422485, 0.0363665446639061, -0.1392979621887207, -0.1565970778465271, 0.05328625440597534, -0.04087366908788681, 0.12584370374679565, -0.08837734162807465, -0.02924390695989132, 0.07832586765289307, -0.114638552069664, 0.1074562519788742, 0.09142947196960449, -0.03903383016586304, 0.07132691144943237, -0.015234689228236675, 0.1420566886663437, -0.10128812491893768, 0.15379780530929565, 0.12579624354839325, -0.14657288789749146, 0.005735655780881643, -0.15136772394180298, 0.02410713955760002, -0.0225105881690979, 0.0967278927564621, 0.16646842658519745, 0.0018432538490742445, 0.08188001811504364, -0.07331453263759613, -0.022850632667541504, 0.058726608753204346, -0.02684199810028076, 0.021126311272382736, -0.014362892135977745, -0.014364421367645264, 0.08362334966659546, 0.08674182742834091, -0.11451196670532227, 0.002190887928009033, -0.09484881162643433, 0.024551451206207275, 0.10930067300796509, -0.09784315526485443, -0.01727650687098503, -0.09140394628047943, 0.15969619154930115, 0.15187519788742065, -0.15864473581314087, -0.0627378448843956, 0.16538995504379272, -0.11006375402212143, -0.07593725621700287, -0.15030024945735931, 0.023756127804517746, 0.006584823131561279, 0.03770267963409424, 0.11101925373077393, 0.0136019391939044, 0.08400257676839828, -0.06970445811748505, 0.11169455945491791, -0.14032986760139465, 0.06552737951278687, -0.15129677951335907, -0.00935353897511959, 0.0848790854215622, 0.05566056817770004, -0.023875217884778976, -0.027194678783416748, 0.031909309327602386, 0.12065868079662323, 0.13183633983135223, 0.11748325824737549, 0.038246989250183105, 0.07351893186569214, -0.06352254003286362, 0.06095787137746811, -0.09187155961990356, 0.04840698093175888, 0.13215747475624084, -0.03475368022918701, 0.12621818482875824, -0.11126875877380371, -0.15203320980072021, 0.13639327883720398, -0.06983356177806854, 0.08736234903335571, 0.0009767413139343262, -0.032845836132764816, -0.14339950680732727, 0.03764937445521355, 0.03732109069824219, -0.002768834587186575, 0.11011207103729248, 0.13097462058067322, -0.141092449426651, -0.00019925832748413086, -0.10489746183156967, 0.0023698012810200453, -0.11106391996145248, 0.14085569977760315, 0.16391927003860474, 0.012745658867061138, -0.12946346402168274, -0.11627956479787827, 0.10389970242977142, -0.00959932804107666, 0.011324604973196983, 0.10171209275722504, 0.0865408405661583, -0.09728352725505829, -0.1184486597776413, 0.15637537837028503, -0.03293347358703613, -0.12471020221710205, -0.0855485200881958, 0.1267814338207245, 0.006352524273097515, 0.0019134085159748793, -0.14918451011180878, -0.1257290244102478, -0.1203339546918869, 0.039874594658613205, -0.011912405490875244, -0.09438105672597885, 0.09333662688732147, -0.010807454586029053, 0.04911714792251587, 0.06670866906642914, 0.0397198423743248, 0.1497831642627716, -0.14691774547100067, -0.04984760284423828, 0.02656225487589836, -0.1020820140838623, -0.14459431171417236, 0.10273274034261703, 0.11213730275630951, 0.043482523411512375, 0.15014658868312836, 0.1254575252532959, -0.03816177695989609, 0.12388187646865845, -0.022531073540449142, -0.09835591167211533, 0.14155003428459167, -0.10669052600860596, -0.12109055370092392, 0.006643255706876516, 0.11294257640838623, -0.02543785236775875, -0.02083389088511467, 0.04980289936065674, 0.00558161735534668, -0.042742710560560226, -0.06365031003952026, 0.03230593726038933, 0.020286044105887413, -0.07380574941635132, -0.02982419729232788, 0.05613478273153305, 0.0396333746612072, 0.01480114459991455, -0.16348373889923096, -0.15209999680519104, 0.11688711494207382, -0.12771311402320862, -0.1321878731250763, 0.1561383605003357, -0.06789269298315048, 0.0253220796585083, -0.14189569652080536, 0.0858582854270935, 0.00552763557061553, 0.08760178089141846, 0.007903973571956158, 0.13317768275737762, 0.1228204220533371, 0.015258988365530968, 0.024738213047385216, 0.027957558631896973, 0.16271424293518066, -0.05782989785075188, -0.1572248935699463, 0.10354940593242645, -0.1588774025440216, -0.002045373199507594, -0.03004302643239498, 0.07232122123241425, -0.12554042041301727, -0.11748693883419037, 0.05858910083770752, -0.03110726736485958, 0.06112849712371826, 0.1534762978553772, 0.057724855840206146, 0.029229383915662766, -0.0783953070640564, -0.08476182073354721, 0.037488799542188644, -0.019861161708831787, 0.036133527755737305, -0.04981201887130737, -0.08266846835613251, -0.03354313224554062, 0.026154717430472374, -0.09026050567626953, -0.055618129670619965, 0.03954392671585083, 0.1410692036151886, 0.1191779375076294, 0.07038901746273041, -0.044589877128601074, 0.12235613912343979, 0.14417096972465515, 0.12853485345840454, -0.00950688123703003, 0.07087980210781097, -0.10642890632152557, 0.1075318455696106, -0.08075278997421265, -0.09281443059444427, -0.11858081817626953, 0.06984462589025497, 0.14267542958259583, 0.11118721961975098, -0.1083226203918457, 0.12114185094833374, -0.09426625818014145, -0.037275951355695724, -0.03488777205348015, -0.11634550988674164, 0.007744729518890381, -0.1094149574637413, 0.07593052089214325, 0.057979028671979904, -0.035197995603084564, -0.13966664671897888, -0.09334832429885864, 0.14906828105449677, 0.09381143748760223, 0.0635523796081543, 0.062244217842817307, -0.12333862483501434, -0.1297510713338852, 0.12053102254867554, 0.05420482158660889, -0.0730825662612915, 0.018904685974121094, -0.1546662449836731, -0.12750649452209473, 0.09227029979228973, 0.021026432514190674, 0.138569638133049, -0.08453276008367538, -0.0019285480957478285, -0.13165831565856934, 0.1171504482626915, 0.10283055156469345, -0.042508386075496674, 0.1348353922367096, -0.05015745013952255, -0.07618671655654907, 0.08220738172531128, -0.15926823019981384, -0.004129867069423199, 0.05619802325963974, -0.07178550958633423, -0.06673566997051239, 0.1512385606765747, 0.1528225839138031, 0.10964398086071014, -0.11434262990951538, -0.07197074592113495, -0.049417417496442795, -0.02945522591471672, -0.08009956777095795, 0.15689539909362793, 0.011927902698516846, 0.0669080838561058, 0.15263067185878754, 0.11455011367797852, -0.020883183926343918, 0.08907856792211533, 0.13797295093536377, 0.0959491953253746, 0.005399505607783794, -0.08531129360198975, -0.11696936935186386, -0.1536373794078827, 0.1149500235915184, -0.07706596702337265, 0.0470237135887146, 0.021879395470023155, 0.14373940229415894, 0.0664631575345993, 0.030468543991446495, -0.119382344186306, -0.003541231155395508, -0.1040416806936264, -0.03637685626745224, 0.16118966042995453, -0.05952970311045647, -0.053661148995161057, 0.08298736810684204, 0.1562959849834442, 0.007672290317714214, 0.019223690032958984, 0.03675717115402222, -0.0487833246588707, 0.10309728235006332, 0.11635981500148773, -0.0745134949684143, -0.034527819603681564, 0.08760277926921844, 0.07738755643367767, 0.11256599426269531, 0.12244373559951782, -0.10395302623510361, 0.046282850205898285, -0.06696389615535736, -0.1279679536819458, -0.057312510907649994, 0.14320795238018036, 0.12617892026901245, 0.15655885636806488, 0.1450580656528473, 0.08833452314138412, -0.13912491500377655, -0.002668758388608694, 0.02217189595103264, 0.09574377536773682, -0.05196484178304672, -0.03339090198278427, 0.14236944913864136, -0.039176784455776215, -0.045647382736206055, -0.04599674791097641, 0.1220342367887497, -0.09077563136816025, -0.06081575155258179, 0.04178103059530258, -0.07474350929260254, -0.006885012146085501, 0.07928083837032318, -0.04960310459136963, -0.007988314144313335, -0.0982561931014061, -0.022969882935285568, -0.10554908215999603, 0.000845452188514173, 0.07351845502853394, 0.05370019003748894, -0.08431164920330048, 0.040983401238918304, -0.15013447403907776, -0.0003478527069091797, -0.08459862321615219, -0.13900715112686157, 0.03926130384206772, 0.009924451820552349, -0.03089507482945919, 0.0957508310675621, -0.0072419047355651855, -0.07294593751430511, 0.08561482280492783, -0.07302038371562958, -0.10747455060482025, 0.07638951390981674, 0.036357581615448, 0.06378807872533798, 0.10098253190517426, -0.0015020966529846191, -0.033300042152404785, -0.15463107824325562, -0.07588893175125122, 0.00735733937472105, 0.1325869858264923, 0.0414617657661438, -0.13805852830410004, -0.11840751022100449, 0.06369750201702118, -0.08550439774990082, 0.14983385801315308, 0.05593883991241455, -0.14915305376052856, 0.026577293872833252, 0.1315566599369049, 0.1553635448217392, 0.12073028087615967, -0.16501182317733765, -0.04249610751867294, -0.02627376839518547, -0.021533628925681114, 0.09313815832138062, 0.1105695366859436, 0.09584908187389374, -0.108116015791893, 0.0031208794098347425, 0.029449423775076866, -0.009194294922053814, 0.019445082172751427, -0.1217004656791687, 0.15399086475372314, -0.09226765483617783, -0.15365469455718994, -0.13996808230876923, -0.1461222767829895, -0.01126541756093502, -0.1503763198852539, -0.0037124953232705593, 0.044377826154232025, 0.10347557067871094, 0.029500525444746017, 0.03203584998846054, -0.13588982820510864, -0.06709393113851547, -0.03423589468002319, 0.09072262048721313, 0.16019867360591888, 0.04706686735153198, -0.14937317371368408, 0.019700568169355392, 0.14397281408309937, 0.11577717959880829, 0.04401854798197746, -0.16136561334133148, 0.022154133766889572, -0.04014422744512558, -0.1574667990207672, 0.033406876027584076, -0.02847941778600216, -0.09262675046920776, -0.13484829664230347, 0.15902207791805267, -0.16624170541763306, 0.1330227553844452, 0.011301537975668907, 0.0716843232512474, -0.13463763892650604, 0.08080895990133286, -0.02963145636022091, -0.11609385907649994, -0.09659014642238617, -0.09641812741756439, 0.03885795921087265, -0.12863342463970184, 0.1136280745267868, 0.12120984494686127, 0.0279096569865942, 0.14099781215190887, 0.14092683792114258, -0.10307978093624115, 0.13776426017284393, 0.1300242394208908, 0.08647555112838745, -0.08083673566579819, 0.09933154284954071, -0.1363941878080368, -0.11952068656682968, 0.07363605499267578, -0.00691308593377471, 0.1406095325946808, 0.07427027076482773, 0.11442510783672333, -0.07560988515615463, -0.01565011404454708, -0.02340499684214592, -0.14115241169929504, 0.03356357663869858, 0.15766207873821259, 0.03659111261367798, 0.123698890209198, 0.06223386526107788, 0.1038055270910263, -0.011049489490687847, 0.1096516102552414, 0.08619960397481918, 0.114652618765831, -0.08901836723089218, 0.09161549806594849, 0.13903892040252686, 0.1302160918712616, 0.0610455684363842, -0.06625300645828247, 0.04582510516047478, 0.08573289960622787, 0.030756473541259766, -0.1305835247039795, 0.09124146401882172, 0.07681713998317719, 0.10069072246551514, -0.03368419408798218, -0.10068833827972412, 0.08712941408157349, -0.03316807746887207, -0.14323577284812927, -0.16583251953125, 0.1322709321975708, -0.03774430602788925, 0.06445380300283432, 0.0683165043592453, -0.12077349424362183, -0.07014302909374237, -0.14505676925182343, 0.11695021390914917, -0.1283457726240158, -0.07589155435562134, -0.11768321692943573, -0.13854168355464935, -0.13340744376182556, 0.11296763271093369, -0.07411354780197144, 0.013683319091796875, 0.04573545977473259, -0.05404168367385864, -0.12784823775291443, 0.07543891668319702, -0.03537172079086304, -0.1129223108291626, 0.10368313640356064, -0.012135128490626812, -0.13685880601406097, -0.019889255985617638, -0.049667637795209885, -0.12149324268102646, -0.04551313444972038, 0.028061091899871826, -0.0688248723745346, -0.029240429401397705, -0.14917044341564178, -0.12843886017799377, -0.08515294641256332, -0.08791357278823853, -0.10660587251186371, -0.016653617843985558, -0.14716953039169312, -0.04921102523803711, -0.09976387023925781, 0.043363057076931, 0.06344982236623764, -0.10992400348186493, -0.053374987095594406, 0.016883036121726036, -0.12190189212560654, -0.15018747746944427, 0.06205493211746216, 0.08717720210552216, -0.15140697360038757, 0.15232686698436737, -0.0011190971126779914, -0.12942753732204437, 0.10588960349559784, 0.06048564240336418, -0.1135014146566391, -0.0446610264480114, 0.11835285276174545, 0.08073478937149048, -0.06139189004898071, 0.14770273864269257, 0.12008639425039291, -0.06090941280126572, 0.06781657785177231, -0.15401411056518555, -0.08003433793783188, 0.13417187333106995, -0.1161481961607933, 0.004756351467221975, -0.09459410607814789, -0.08639006316661835, -0.03746744245290756, -0.14734378457069397, 0.12314709275960922, -0.0263390950858593, -0.013648192398250103, -0.0997949093580246, 0.11730404943227768, -0.12239768356084824, 0.13419155776500702, -0.021265169605612755, -0.055254917591810226, 0.1132282242178917, -0.026300808414816856, -0.05538058280944824, 0.09253925085067749, 0.03540947288274765, -0.01703965663909912, -0.06254565715789795, -0.14676140248775482, 0.119645856320858, -0.03669949620962143, 0.14288926124572754, -0.15608149766921997, -0.030215462669730186, 0.051965098828077316, -0.10254546254873276, -0.06565012782812119, 0.011544525623321533, -0.031537216156721115, 0.12381758540868759, -0.02132018469274044, 0.15889185667037964, -0.09608893096446991, -0.16583773493766785, 0.09083764255046844, -0.1559251844882965, 0.07761534303426743, -0.12912452220916748, 0.048430901020765305, -0.06379898637533188, -0.1441737860441208, -0.13864240050315857, 0.042159318923950195, 0.019805749878287315, -0.10577844083309174, -0.041551850736141205, 0.1429702639579773, 0.13251839578151703, 0.14327174425125122, 0.01822330616414547, 0.026228150352835655, 0.012776672840118408, -0.16088193655014038, 0.09647487103939056, -0.13170836865901947, -0.05758281797170639, 0.03492816537618637, 0.11910019814968109, -0.01995984837412834, -0.14131829142570496, 0.14736950397491455, -0.03524957224726677, -0.1440877616405487, 0.05338533967733383, -0.03614377975463867, 0.0698910802602768, 0.13926075398921967, -0.05577465146780014, 0.13135004043579102, 0.01936352252960205, 0.16538602113723755, 0.15336990356445312, 0.1301797330379486, 0.04076699540019035, 0.02523924969136715, -0.10360795259475708, -0.139072448015213, -0.04755334183573723, -0.008516907691955566, 0.02983568236231804, -0.03909868001937866, 0.04958939552307129, 0.019913196563720703, 0.14639070630073547, -0.1165875643491745, -0.07834281772375107, -0.09510811418294907, 0.14033997058868408, 0.06332963705062866, -0.13596366345882416, -0.03670865297317505, 0.15566664934158325, 0.14258089661598206, 0.10674669593572617, 0.005712847225368023, 0.06739282608032227, 0.00023804108786862344, -0.0705704316496849, -0.0725032314658165, -0.01572549343109131, 0.08270611613988876, -0.004027664661407471, -0.096513532102108, -0.12783794105052948, -0.04710811376571655, -0.16657179594039917, 0.1617709994316101, -0.12919077277183533, 0.06567921489477158, 0.04735972732305527, 0.13689276576042175, 0.02434031292796135, -0.10719005763530731, 0.09588460624217987, 0.018301349133253098, -0.01805168390274048, -0.03145802021026611, -0.06373324245214462, 0.002225518226623535, -0.05864894390106201, 0.14595633745193481, -0.03838583081960678, -0.0037607750855386257, -0.12532594799995422, -0.12801778316497803, 0.11329840123653412, -0.08098016679286957, -0.016069253906607628, 0.032234352082014084, -0.14981147646903992, -0.06502481549978256, -0.03761178255081177, 0.14092294871807098, 0.0706687793135643, -0.11930567026138306, -0.13794837892055511, 0.021610300987958908, 0.0056653618812561035, -0.0022101006470620632, -0.0024820964317768812, -0.06698481738567352, -0.12132835388183594, 0.13431131839752197, 0.0221468023955822, 0.05572231858968735, 0.13481055200099945, -0.066811703145504, -0.040094178169965744, -0.07040554285049438, -0.05133497714996338, 0.006419937126338482, 0.011737247928977013, 0.13276784121990204, 0.13268330693244934, 0.10638954490423203, -0.1349768042564392, -0.044477008283138275, 0.12865740060806274, 0.14264163374900818, -0.15824684500694275, 0.06735589355230331, -0.11922822892665863, -0.008417010307312012, -0.12072138488292694, 0.08917170763015747, 0.11419093608856201, 0.05438343808054924, 0.1279526948928833, -0.06426471471786499, 0.14735810458660126, -0.030945559963583946, 0.1567116230726242, 0.16325780749320984, 0.05836024135351181, -0.021266698837280273, 0.03196132183074951, -0.16209076344966888, 0.002421140670776367, -0.020143231377005577, -0.020825287327170372, -0.07550595700740814, 0.0472278818488121, 0.06719772517681122, -0.12490588426589966, 0.13378006219863892, 0.033013761043548584, -0.07878230512142181, 0.06455487012863159, 0.15317204594612122, 0.014024059288203716, -0.12853360176086426, -0.09823235124349594, -0.09791737794876099, 0.11422719806432724, 0.08047960698604584, -0.04693945497274399, -0.13879528641700745, 0.021272679790854454, 0.13098369538784027, -0.06276381015777588, -0.13204799592494965, -0.11164520680904388, 0.06912408769130707, -0.13659259676933289, -0.13515621423721313, -0.1377415955066681, -0.11447679996490479, 0.018442075699567795, 0.05950617790222168, 0.07583733648061752, -0.048532307147979736, -0.05017292499542236, 0.08755068480968475, 0.13751745223999023, 0.05880328267812729, 0.05703020095825195, 0.024029236286878586, -0.12610189616680145, 0.160545215010643, 0.1266186535358429, 0.06841697543859482, 0.053059082478284836, -0.13989722728729248, -0.12164531648159027, 0.03067260980606079, -0.08243068307638168, -0.0953332781791687, 0.10624673217535019, 0.10312648862600327, 0.06924369186162949, -0.15923383831977844, -0.12204724550247192, 0.011546095833182335, 0.13665714859962463, 0.03664485737681389, 0.0529329776763916, -0.026759743690490723, -0.06330307573080063, 0.05914422124624252, -0.12351372092962265, -0.09581726789474487, -0.0064375801011919975, 0.09423428773880005, 0.13811008632183075, -0.16040655970573425, 0.12311524152755737, -0.09488807618618011, 0.08580899238586426, -0.12019350379705429, 0.06452769041061401, -0.1234578937292099, 0.07968699932098389, -0.16393063962459564, 0.011477927677333355, 0.0797606110572815, 0.15523657202720642, -0.08229833841323853, 0.008092324249446392, 0.1596466600894928, -0.05758681148290634, 0.0009199182386510074]\n"
     ]
    }
   ],
   "source": [
    "print(len(conv_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "max_val = 0\n",
    "min_val = -10000\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in [0,2,3,11,12]:\n",
    "    plt.hist(conv_weights[i], bins=100, histtype='step', label=f\"conv{i}\")\n",
    "    max_val = max(max_val, conv_weights[i].max())\n",
    "    min_val = min(min_val, conv_weights[i].min())\n",
    "plt.xlim(-0.2,0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "max_val = 0\n",
    "min_val = -10000\n",
    "for i in range(len(linear_weights),0,-1):\n",
    "    plt.hist(linear_weights[i], bins=100, histtype='step', label=f\"linear{i}\")\n",
    "    max_val = max(max_val, linear_weights[i].max())\n",
    "    min_val = min(min_val, linear_weights[i].min())\n",
    "    break\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
