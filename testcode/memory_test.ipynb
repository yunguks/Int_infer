{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import vgg\n",
    "import torch.utils.benchmark as benchmark\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "      Layer (type)            Input Shape         Param #     Tr. Param #\n",
      "==========================================================================\n",
      "          Conv2d-1       [1, 4, 224, 224]           2,368           2,368\n",
      "            ReLU-2      [1, 64, 224, 224]               0               0\n",
      "          Conv2d-3      [1, 64, 224, 224]          36,928          36,928\n",
      "            ReLU-4      [1, 64, 224, 224]               0               0\n",
      "       MaxPool2d-5      [1, 64, 224, 224]               0               0\n",
      "          Conv2d-6      [1, 64, 112, 112]          73,856          73,856\n",
      "            ReLU-7     [1, 128, 112, 112]               0               0\n",
      "          Conv2d-8     [1, 128, 112, 112]         147,584         147,584\n",
      "            ReLU-9     [1, 128, 112, 112]               0               0\n",
      "      MaxPool2d-10     [1, 128, 112, 112]               0               0\n",
      "         Conv2d-11       [1, 128, 56, 56]         295,168         295,168\n",
      "           ReLU-12       [1, 256, 56, 56]               0               0\n",
      "         Conv2d-13       [1, 256, 56, 56]         590,080         590,080\n",
      "           ReLU-14       [1, 256, 56, 56]               0               0\n",
      "         Conv2d-15       [1, 256, 56, 56]         590,080         590,080\n",
      "           ReLU-16       [1, 256, 56, 56]               0               0\n",
      "      MaxPool2d-17       [1, 256, 56, 56]               0               0\n",
      "         Conv2d-18       [1, 256, 28, 28]       1,180,160       1,180,160\n",
      "           ReLU-19       [1, 512, 28, 28]               0               0\n",
      "         Conv2d-20       [1, 512, 28, 28]       2,359,808       2,359,808\n",
      "           ReLU-21       [1, 512, 28, 28]               0               0\n",
      "         Conv2d-22       [1, 512, 28, 28]       2,359,808       2,359,808\n",
      "           ReLU-23       [1, 512, 28, 28]               0               0\n",
      "      MaxPool2d-24       [1, 512, 28, 28]               0               0\n",
      "         Conv2d-25       [1, 512, 14, 14]       2,359,808       2,359,808\n",
      "           ReLU-26       [1, 512, 14, 14]               0               0\n",
      "         Conv2d-27       [1, 512, 14, 14]       2,359,808       2,359,808\n",
      "           ReLU-28       [1, 512, 14, 14]               0               0\n",
      "         Conv2d-29       [1, 512, 14, 14]       2,359,808       2,359,808\n",
      "           ReLU-30       [1, 512, 14, 14]               0               0\n",
      "      MaxPool2d-31       [1, 512, 14, 14]               0               0\n",
      "         Linear-32             [1, 25088]     102,760,448     102,760,448\n",
      "           ReLU-33              [1, 4096]               0               0\n",
      "        Dropout-34              [1, 4096]               0               0\n",
      "         Linear-35              [1, 4096]      16,777,216      16,777,216\n",
      "           ReLU-36              [1, 4096]               0               0\n",
      "        Dropout-37              [1, 4096]               0               0\n",
      "         Linear-38              [1, 4096]         409,600         409,600\n",
      "==========================================================================\n",
      "Total params: 134,662,528\n",
      "Trainable params: 134,662,528\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pytorch_model_summary import summary\n",
    "\n",
    "model = vgg.vgg16()\n",
    "tensor = torch.rand((1,4, 224,224))\n",
    "print(summary(model,torch.zeros((1,4,224,224)),show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg.float_vgg16()\n",
    "tensor = torch.rand((1,224,224,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-25 23:41:18 2141010:2141010 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-11-25 23:41:20 2141010:2141010 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-11-25 23:41:20 2141010:2141010 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "with profile(activities=[ProfilerActivity.CUDA], record_shapes=True, with_stack=True,with_modules=True, with_flops=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model.cuda()\n",
    "        tensor = tensor.cuda()\n",
    "        model(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     cudaGetDeviceCount         0.08%       1.131ms         0.08%       1.131ms     377.000us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                cudaGetDeviceProperties         0.01%     112.000us         0.01%     112.000us      56.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                  cudaStreamIsCapturing        43.34%     640.403ms        43.34%     640.403ms      20.658ms       0.000us         0.00%       0.000us       0.000us            31  \n",
      "                                             cudaMalloc         0.30%       4.423ms         0.30%       4.423ms     245.722us       0.000us         0.00%       0.000us       0.000us            18  \n",
      "                                        cudaMemcpyAsync         3.06%      45.282ms         3.06%      45.282ms       2.664ms       0.000us         0.00%       0.000us       0.000us            17  \n",
      "                                  cudaStreamSynchronize         0.04%     572.000us         0.04%     572.000us      33.647us       0.000us         0.00%       0.000us       0.000us            17  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      44.427ms        88.22%      44.427ms       2.613ms            17  \n",
      "                                   cudaDriverGetVersion         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                 cudaDeviceGetAttribute         0.00%       1.000us         0.00%       1.000us       0.031us       0.000us         0.00%       0.000us       0.000us            32  \n",
      "                              cudaStreamCreateWithFlags         4.36%      64.439ms         4.36%      64.439ms       4.027ms       0.000us         0.00%       0.000us       0.000us            16  \n",
      "                                        cudaMemsetAsync         0.00%      57.000us         0.00%      57.000us      14.250us       0.000us         0.00%       0.000us       0.000us             4  \n",
      "                                          cudaHostAlloc         0.06%     921.000us         0.06%     921.000us     921.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.00%       2.000us       0.500us             4  \n",
      "                               cudaHostGetDevicePointer         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               cudaFree        32.09%     474.148ms        32.09%     474.148ms     118.537ms       0.000us         0.00%       0.000us       0.000us             4  \n",
      "                                   cudaGetSymbolAddress         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaStreamGetPriority         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us            18  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us            18  \n",
      "                                       cudaLaunchKernel        16.40%     242.363ms        16.40%     242.363ms       3.564ms       0.000us         0.00%       0.000us       0.000us            68  \n",
      "void implicit_convolve_sgemm<float, float, 1024, 5, ...         0.00%       0.000us         0.00%       0.000us       0.000us      32.000us         0.06%      32.000us      32.000us             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     139.000us         0.28%     139.000us       9.267us            15  \n",
      "                                  cudaFuncGetAttributes         0.02%     309.000us         0.02%     309.000us       5.518us       0.000us         0.00%       0.000us       0.000us            56  \n",
      "                                   cudaFuncSetAttribute         0.01%     104.000us         0.01%     104.000us       1.793us       0.000us         0.00%       0.000us       0.000us            58  \n",
      "void cudnn::ops::convertTensor_kernel<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us     139.000us         0.28%     139.000us      11.583us            12  \n",
      "void cudnn::ops::nchwToNhwcKernel<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     186.000us         0.37%     186.000us      15.500us            12  \n",
      "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fpr...         0.00%       0.000us         0.00%       0.000us       0.000us     277.000us         0.55%     277.000us     138.500us             2  \n",
      "void pooling_fw_kernel_max_nhwc<float, float, 0, (cu...         0.00%       0.000us         0.00%       0.000us       0.000us      48.000us         0.10%      48.000us       9.600us             5  \n",
      "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us     105.000us         0.21%     105.000us     105.000us             1  \n",
      "void cudnn::ops::nchwToNhwcKernel<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us      16.000us         0.03%      16.000us      16.000us             1  \n",
      "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fpr...         0.00%       0.000us         0.00%       0.000us       0.000us     635.000us         1.26%     635.000us     105.833us             6  \n",
      "sm80_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f3...         0.00%       0.000us         0.00%       0.000us       0.000us     479.000us         0.95%     479.000us     159.667us             3  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.220ms         6.39%       3.220ms       1.073ms             3  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.00%      53.000us         0.00%      53.000us      17.667us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                  cudaDeviceSynchronize         0.22%       3.185ms         0.22%       3.185ms       3.185ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "std::enable_if<true, void>::type internal::gemvx::ke...         0.00%       0.000us         0.00%       0.000us       0.000us     546.000us         1.08%     546.000us     546.000us             1  \n",
      "void splitKreduce_kernel<32, 16, int, float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us       9.000us         0.02%       9.000us       4.500us             2  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.01%       6.000us       3.000us             2  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us      85.000us         0.17%      85.000us      85.000us             1  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us       7.000us         0.01%       7.000us       7.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.478s\n",
      "Self CUDA time total: 50.358ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_memory_usage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24226 1040 523 517\n"
     ]
    }
   ],
   "source": [
    "MB = 1024 * 1024\n",
    "t = torch.cuda.get_device_properties(0).total_memory // MB\n",
    "r = torch.cuda.memory_reserved(0) // MB\n",
    "a = torch.cuda.memory_allocated(0) // MB\n",
    "f = r-a  # free inside reserved\n",
    "print(t,r,a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "907\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      | 536329 KiB |    915 MiB |   3186 MiB |   2662 MiB |\n",
      "|       from large pool | 534528 KiB |    914 MiB |   3175 MiB |   2653 MiB |\n",
      "|       from small pool |   1801 KiB |      2 MiB |     10 MiB |      9 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         | 536329 KiB |    915 MiB |   3186 MiB |   2662 MiB |\n",
      "|       from large pool | 534528 KiB |    914 MiB |   3175 MiB |   2653 MiB |\n",
      "|       from small pool |   1801 KiB |      2 MiB |     10 MiB |      9 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      | 535113 KiB |    914 MiB |   3179 MiB |   2656 MiB |\n",
      "|       from large pool | 533312 KiB |    912 MiB |   3168 MiB |   2647 MiB |\n",
      "|       from small pool |   1801 KiB |      2 MiB |     10 MiB |      9 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   1040 MiB |   1040 MiB |   1040 MiB |      0 B   |\n",
      "|       from large pool |   1036 MiB |   1036 MiB |   1036 MiB |      0 B   |\n",
      "|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   2294 KiB | 400566 KiB |   2171 MiB |   2168 MiB |\n",
      "|       from large pool |   2048 KiB | 400319 KiB |   2155 MiB |   2153 MiB |\n",
      "|       from small pool |    246 KiB |   2039 KiB |     15 MiB |     15 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      19    |      22    |     145    |     126    |\n",
      "|       from large pool |      13    |      16    |      99    |      86    |\n",
      "|       from small pool |       6    |       9    |      46    |      40    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      19    |      22    |     145    |     126    |\n",
      "|       from large pool |      13    |      16    |      99    |      86    |\n",
      "|       from small pool |       6    |       9    |      46    |      40    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      11    |      11    |      11    |       0    |\n",
      "|       from large pool |       9    |       9    |       9    |       0    |\n",
      "|       from small pool |       2    |       2    |       2    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       3    |       5    |      93    |      90    |\n",
      "|       from large pool |       1    |       4    |      74    |      73    |\n",
      "|       from small pool |       2    |       3    |      19    |      17    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MB = 1024 * 1024\n",
    "model = vgg.float_vgg16()\n",
    "tensor = torch.rand((1,224,224,4))\n",
    "reset = torch.cuda.reset_max_memory_allocated()\n",
    "print(reset)\n",
    "memory_before = torch.cuda.max_memory_allocated(device=0) // MB\n",
    "model.cuda()\n",
    "tensor = tensor.cuda()\n",
    "with torch.no_grad():\n",
    "    y = model(tensor)\n",
    "memory_after = torch.cuda.max_memory_allocated(device=0) // MB\n",
    "peak_momery = memory_after -memory_before\n",
    "print(peak_momery)\n",
    "print(torch.cuda.memory_summary(device=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
